{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Text Classification - Hard Tasks\n",
    "\n",
    "This notebook tackles advanced classification challenges. You'll implement hierarchical multi-level classifiers for complex taxonomies, use active learning to minimize labeling costs, build ensemble classifiers to improve robustness, and apply transfer learning across domains. These techniques are essential for production-level NLP systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run all cells in this section to set up the environment and load necessary data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LGW2SD-c864"
   },
   "source": [
    "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
    "\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
    "\n",
    "---\n",
    "\n",
    " **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N-PxmOIhc865"
   },
   "outputs": [],
   "source": [
    " %%capture\n",
    "!pip install transformers sentence-transformers openai\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784,
     "referenced_widgets": [
      "169816892c8646e3888f213295349f00",
      "4a590f6ceb104873b97b9620d6107017",
      "2d14e5528bbd446e8a34c235201f88ac",
      "f4c9e362c7ff40559a1a5632a8b6e907",
      "3c4c633f0af84d099ffc74bac8901b07",
      "35226b53943b4db8a5d46aae09720818",
      "1a6faf9a5ed748f0809834cc52435b3d",
      "4fe179f7fab44513aeaa33cedf44f1bb",
      "5befa9362a09459695f4489c7173c34d",
      "458ad67bb385497889eab5bbdd977de5",
      "027a7c3f8a9e4114ac6d4e64fb62d440",
      "0cce924a44f94cbfaa69a78735ece1d5",
      "28ac2aeffcb6424f97fb47bfaee8e66f",
      "ab02cefe39774db3844d914b65a48790",
      "6bf6e7d710eb4924a3144e6e5d0679ca",
      "b7b774839b134ee687d9d89a0e15d166",
      "c583fda17dd44217875e86209fbad80a",
      "cd4eeedee4fc4f28acf650785bbaa5f3",
      "e5138fd5028f48f9ad8eea2b41b1592a",
      "82f4409e3f854415a871e3da31e9393e",
      "aeb337caa109443a9fc4f93e9f92753d",
      "e7e6399dec234052b7f30e3135a21b00",
      "44a764c1267042259b2c9597a69f6f76",
      "05e8f57e23ff47f0be24d3f9c18554d4",
      "616321e6e87a4d8589d9ed939e19c7b2",
      "8d7284d945004b98b28b6c631a2c4726",
      "97d864e9c07149aeb22a844ced3909d5",
      "dbadb6dfe23141ec8f38ffb747ea882e",
      "82d0c0a18606421f92ed77d8d4c61e10",
      "0c64a3bc4d4d461cbdc3c3c0acae2f94",
      "cf707e36593b4071b8253fd33d18b665",
      "079412e5345a4a09875ed0c86dde93e3",
      "1e2ffd31336946cf952abb5f62651c16",
      "8466edc3103c45d8a5d3fe8166508648",
      "f8d0d8f24551457e862d2e041f3699ab",
      "426852cccf704c58bdc7decbb1c583e6",
      "6b2663befc574a8e8154631c3ac95ff3",
      "091bd22cb6d94ae5b7c962d18e528ca2",
      "5ba5883cc2144929b9d7ddd980e4508d",
      "971d17ca015446b4bbf8a908835295cd",
      "c7086b545eae4b09af3b2d77b78af4b9",
      "5f47aeddde3449a5b5ed280d0ec9bc18",
      "43791444ad3e49f993d17887e6c15dbf",
      "c2c3403eb38b420cba7390d385f325be",
      "9097dd47971f445ea0fd55e7c42c15a0",
      "18cbf6cbaa4c436d9074224f83472863",
      "831180b810da4b549a8ca75536607e31",
      "d9779ccf530e49b1ac52172252ec5ef4",
      "78d69219fad44722a9bad3a12a3ccb61",
      "f08fa19e07644f4d9fff30d02040e315",
      "e1a2a1e765f042a7b9b081688688dab5",
      "76d299a97ab54dbe96f4525095afedcb",
      "73ac94bdcaf8427bbbcdd808f1428dff",
      "6f9a5d0dfe2f4aa49c57e942b927521b",
      "2d7810d299f649a2ac84541e7215d29a",
      "40dc8a185cf34e99a427f7c81bc76540",
      "bcac3e31740e4a2894b4e8bc9656a0c5",
      "87f29bce5b5d4df08b5337d62ffa9568",
      "3129b232f1e3411ead0d913654a11eaa",
      "4e7c3e87552640018f89c6cf9e070642",
      "01ccc633ad5d4350ad04651e360cc478",
      "735737e7c1eb477fae9d06d7324e81e8",
      "882b69fb84034d2dace625ef267f51cb",
      "8c77be8e5b74452bb028b97fd9edba36",
      "55a6296e28394f41b2a6d1f3d76e5944",
      "8f6c7a732bb6498db1de4d66f4b3c623",
      "22541d211626493e87c168143671e5ce",
      "111b9c6182994e2e85a323d07980b1ab",
      "3c53665ac233434fa899399da13650f0",
      "c4867626e6eb41bfaade350790de9f40",
      "a11866f208c4411dbc3d627ef6dbd74f",
      "3485c0ebc7f24965a0fadd3a6570d51e",
      "d111b1f753554eeda57cdbe420335fda",
      "8fb77e0530e946d38c007c9012c37a79",
      "8d669f0719d04980a6f04ffc2f65cf7c",
      "d79a649275a14fdeb2cb01e5ab75021f",
      "14186c7dd75e43d99183d5c8b308c0de"
     ]
    },
    "id": "5phRS_z2U_3T",
    "outputId": "e51c9c23-a48a-4c61-e7ee-cd0ef03915a4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "169816892c8646e3888f213295349f00"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cce924a44f94cbfaa69a78735ece1d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44a764c1267042259b2c9597a69f6f76"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8466edc3103c45d8a5d3fe8166508648"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9097dd47971f445ea0fd55e7c42c15a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40dc8a185cf34e99a427f7c81bc76540"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22541d211626493e87c168143671e5ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load our data\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X0KyKHtqyjn3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your Turn - Text Classification Experiments\n",
    "\n",
    "Run each task first to see the baseline results. Follow the instructions to modify and experiment."
   ],
   "metadata": {
    "id": "NKYNfoaVC4hU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section is divided into EASY, MEDIUM, & HARD."
   ],
   "metadata": {
    "id": "hHVONn85DElL"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hard Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hard Tasks - Advanced Classification Challenges\n",
    "\n",
    "These tasks require significant modifications and deeper understanding. Take your time and experiment"
   ],
   "metadata": {
    "id": "sOcbrBwdGZbi"
   }
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": "#### Hard Task 1: Hierarchical Multi-Level Classifier\n\nRun the 2-level classifier first. Then try adding a 3rd level.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "#### Hard Task 1: Hierarchical Multi-Level Classifier\n\nInstead of flat classification (choosing from all categories at once), hierarchical classification makes decisions in steps: first broad categories, then fine-grained ones. This mirrors how humans often reason.\n\n**What to do:**\n1. Run the 2-level classifier (Sentiment → Specific Aspect)\n2. Compare with flat classification to see confidence differences\n3. Try adding a 3rd level by uncommenting the code\n4. Analyze whether breaking decisions into steps helps or hurts"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14c",
   "metadata": {},
   "outputs": [],
   "source": "# Level 1: Broad sentiment\nlevel1_labels = [\n    \"negative sentiment review\",\n    \"positive sentiment review\"\n]\n\n# Level 2: Specific aspects (conditional on Level 1)\nlevel2_negative = [\n    \"review criticizing entertainment value and pacing\",\n    \"review criticizing technical quality and production\"\n]\n\nlevel2_positive = [\n    \"review praising technical quality and artistry\",\n    \"review praising entertainment value and enjoyment\"\n]\n\n# TODO: Add Level 3 for even finer granularity\n# level3_positive_quality = [...]\n# level3_positive_entertainment = [...]"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14d",
   "metadata": {},
   "source": "Classification function:\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14e",
   "metadata": {},
   "outputs": [],
   "source": "#### Hard Task 2: Active Learning to Minimize Labeling Costs\n\nLabeling data is expensive. Active learning strategically selects the most informative samples to label, potentially saving 50%+ of labeling effort compared to random selection. Run the simulation to see active learning vs random sampling, observe which samples the model finds \"uncertain\", and track how many samples each approach needs to reach F1=0.85. Try implementing the alternative selection strategy (margin sampling) and compare labeling cost savings."
  },
  {
   "cell_type": "markdown",
   "id": "cell-14f",
   "metadata": {},
   "source": "Classify the reviews:\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14g",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*80)\nprint(\"HIERARCHICAL CLASSIFICATION (2 LEVELS)\")\nprint(\"=\"*80)\n\nfor i, review in enumerate(test_reviews):\n    result = hierarchical_classify_2level(review)\n\n    print(f\"\\nReview {i+1}: '{review}'\")\n    print(f\"\\n  Level 1 (Sentiment):\")\n    print(f\"     {result['level1_label']}\")\n    print(f\"     Confidence: {result['level1_conf']:.3f}\")\n\n    print(f\"\\n  Level 2 (Specific Aspect):\")\n    print(f\"     {result['level2_label']}\")\n    print(f\"     Confidence: {result['level2_conf']:.3f}\")\n\n    print(f\"\\n  Final Classification Path:\")\n    print(f\"     {result['path']}\")\n    print(\"-\"*80)\n\n# Compare with flat classification\nprint(\"\\n\" + \"=\"*80)\nprint(\"COMPARISON: Hierarchical vs Flat Classification\")\nprint(\"=\"*80)\n\n# Flat: All 4 categories at once\nflat_labels = [\n    \"review criticizing entertainment value and pacing\",      # 0\n    \"review criticizing technical quality and production\",    # 1\n    \"review praising technical quality and artistry\",         # 2\n    \"review praising entertainment value and enjoyment\"       # 3\n]\n\nflat_embeddings = model.encode(flat_labels)\nreview_embeddings = model.encode(test_reviews)\nflat_sim = cosine_similarity(review_embeddings, flat_embeddings)\n\nprint(\"\\nShowing first 3 reviews:\")\nfor i in range(min(3, len(test_reviews))):\n    hier_result = hierarchical_classify_2level(test_reviews[i])\n    flat_pred = np.argmax(flat_sim[i])\n    flat_conf = flat_sim[i][flat_pred]\n\n    print(f\"\\nReview: '{test_reviews[i][:50]}...'\")\n    print(f\"  Hierarchical: {hier_result['level2_label']}\")\n    print(f\"     Confidence: {hier_result['level2_conf']:.3f}\")\n    print(f\"  Flat:         {flat_labels[flat_pred]}\")\n    print(f\"     Confidence: {flat_conf:.3f}\")\n    print(f\"  Confidence Diff: {hier_result['level2_conf'] - flat_conf:+.3f}\")\n\n# TODO: After implementing 3-level, uncomment to test it:\n# print(\"\\n\" + \"=\"*80)\n# print(\"TESTING 3-LEVEL HIERARCHICAL CLASSIFICATION\")\n# print(\"=\"*80)\n#\n# for i, review in enumerate(test_reviews):\n#     result = hierarchical_classify_3level(review)\n#     print(f\"\\n{i+1}. '{review[:60]}...'\")\n#     print(f\"   Path: {result['path']}\")\n#     print(f\"   Level 3 confidence: {result['level3_conf']:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "source": "**As you can see,** the hierarchical approach makes decisions in stages:\n1. **Level 1:** Determines if the review is positive or negative\n2. **Level 2:** Based on that sentiment, classifies the specific aspect\n\nNotice the **confidence scores** at each level. The hierarchical classifier's final confidence is often higher than flat classification because it's making simpler decisions at each step.\n\n**Looking at the comparison** between hierarchical and flat approaches, you may notice:\n- Hierarchical often has higher confidence (makes easier per-step decisions)\n- But if Level 1 is wrong, Level 2 has no chance to correct it\n- Flat classification considers all options at once but may be less confident",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "As you can see, the hierarchical approach makes decisions in stages. The Level 1 determines if the review is positive or negative, then Level 2 classifies the specific aspect. The final confidence is often higher than flat classification because it's making simpler decisions at each step, but if Level 1 is wrong, Level 2 has no chance to correct it."
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "#### Hard Task 2: Active Learning to Minimize Labeling\n\nCompare active learning (picking uncertain samples) vs random selection.\n"
  },
  {
   "cell_type": "markdown",
   "source": "**As you can see,** active learning iteratively:\n1. Trains on currently labeled data\n2. Finds the most uncertain unlabeled samples  \n3. \"Labels\" those samples (adds them to training set)\n4. Repeats\n\nNotice the **uncertain samples** being selected - they typically have prediction probabilities close to 50-50. These are the most informative because they lie near the decision boundary.\n\n**Looking at the learning curves,** compare how quickly each approach improves. Active learning often reaches target performance with fewer labeled samples, saving significant labeling costs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "The results show active learning iteratively trains on labeled data, finds uncertain samples, labels them, and repeats. The uncertain samples typically have prediction probabilities close to 50-50 - these are the most informative because they lie near the decision boundary. Compare the learning curves to see how quickly each approach improves.",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "31e52c083fbd45de8bc39eef296bfd2b",
      "19ff4554c5c04b7f8e4f921005ccdd9e",
      "27bb8412e000498295babac8fbe52c3f",
      "f49402608ba44a6e9518f44bcbbdf1e5",
      "3333b0243467411ea154c5f5696008a2",
      "3a6373e168304156ba0ed95c4a641fdb",
      "04f978025bf34d2ba1f5fe98c69f33f5",
      "9de9769d6370464199eed6489432614c",
      "bf33dc78e48d4cbfb6bc9c4793e9b179",
      "33d4750e1b904615ab015b7c940601b8",
      "00e048491fce4d10836ef45f0f307dee"
     ]
    },
    "id": "VSP2ei_2G4hH",
    "outputId": "746d8713-a669-465b-eb65-c1fb471f86a0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Hard Task 3: Ensemble Classifier for Improved Robustness\n\n**Ensemble methods** combine multiple models to reduce individual biases and improve reliability. The wisdom of crowds principle: multiple imperfect models together often beat any single model.\n\n**What to do:**\n1. Run to see 3 individual models compared to ensemble methods\n2. Compare simple majority voting vs confidence-weighted voting\n3. Examine disagreement cases - when models disagree, which is usually right?\n4. Optionally add a 4th model and performance-weighted voting\n5. Determine if the ensemble beats the best individual model",
   "metadata": {
    "id": "yzYVwXTBHOrA"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Hard Task 3: Ensemble Classifier for Improved Robustness\n\nEnsemble methods combine multiple models to reduce individual biases and improve reliability. The wisdom of crowds principle: multiple imperfect models together often beat any single model.\n\nTry this:\n- Run to see 3 individual models compared to ensemble methods\n- Compare simple majority voting vs confidence-weighted voting\n- Examine disagreement cases - when models disagree, which is usually right?\n- Optionally add a 4th model and performance-weighted voting"
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": "#### Hard Task 3: Ensemble Classifier\n\nCompare 3 different models individually vs combined as an ensemble.\n"
  },
  {
   "cell_type": "code",
   "source": "Looking at the voting patterns, most samples have unanimous agreement (all models concur) - these are easy cases. The interesting cases are disagreements where models learned different patterns. Notice the ensemble performance: sometimes it beats all individual models by leveraging their diverse strengths.",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e90e7c8a9ae641f9a5f2c9ab66248dbc",
      "e3af2532ddea450095ef34e3c7890344",
      "220d3bb538d84e23ba45bdb1ef20e68c",
      "be25c443c44c428eb271c02c2e34578a",
      "beb2fb51e5714276808eba4b576907e3",
      "8522a39f750149109702719a81a46bb0",
      "9d04edae2e034fb39a681ea8db1f79d8",
      "e97f097bfe454537b714d50cc3e1923e",
      "6fd1de03fef54dffba7b998edeac0776",
      "2d7a4067755849cd9cb94accfed4d9c0",
      "eb3cbb80ef9a42a8b31bf282cc426aeb"
     ]
    },
    "id": "kWDdM6kBHHr9",
    "outputId": "2f7082bc-801f-4d8d-9f17-78ae80b0cdce"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "**As you can see,** the classifier trained on movies transfers to other domains with varying success:\n\n**Zero-shot transfer results** show how well the model generalizes without any target domain examples. Domains closer to movies (like books) often transfer better than very different domains.\n\n**Few-shot adaptation** demonstrates the power of adding just a handful of target domain examples. Even 4 labeled samples can significantly improve performance.\n\n**Looking at the domain similarity analysis,** embedding distance correlates with transfer performance. Domains with smaller embedding distance from movies tend to have better zero-shot performance. This helps you predict which domains will transfer well before running experiments.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": "#### Hard Task 4: Cross-Domain Transfer Learning\n\nCan a classifier trained on movie reviews work on restaurant, product, or book reviews? Observe zero-shot transfer (no adaptation) performance on each domain, see which domains transfer well and which don't, then try few-shot adaptation (adding just 4 examples from target domain). Analyze domain similarity using embedding distances and optionally add your own custom domain to test."
  },
  {
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Source domain: Movie reviews\n",
    "movie_data = load_dataset(\"rotten_tomatoes\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "movie_train = movie_data[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "movie_test = movie_data[\"test\"].shuffle(seed=42).select(range(200))\n",
    "\n",
    "# Target domains with labeled examples\n",
    "restaurant_reviews = {\n",
    "    'text': [\n",
    "        \"Amazing food and excellent service!\",\n",
    "        \"Best restaurant in town, highly recommend\",\n",
    "        \"Delicious meals and great atmosphere\",\n",
    "        \"Outstanding cuisine and friendly staff\",\n",
    "        \"Terrible food, very disappointing\",\n",
    "        \"Awful service and poor quality\",\n",
    "        \"Not worth the money, mediocre at best\",\n",
    "        \"Disgusting food and rude waiters\",\n",
    "        \"The pasta was okay but nothing special\",\n",
    "        \"Decent place for a quick meal\"\n",
    "    ],\n",
    "    'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "product_reviews = {\n",
    "    'text': [\n",
    "        \"This product is amazing! Works perfectly\",\n",
    "        \"Excellent quality, very satisfied\",\n",
    "        \"Great value for money, highly recommend\",\n",
    "        \"Perfect! Exactly what I needed\",\n",
    "        \"Terrible product, broke immediately\",\n",
    "        \"Waste of money, very poor quality\",\n",
    "        \"Doesn't work as advertised, disappointed\",\n",
    "        \"Awful, don't buy this\",\n",
    "        \"It's okay, does the job\",\n",
    "        \"Average product, nothing special\"\n",
    "    ],\n",
    "    'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "book_reviews = {\n",
    "    'text': [\n",
    "        \"Brilliant book! Couldn't put it down\",\n",
    "        \"Masterfully written, highly engaging\",\n",
    "        \"One of the best books I've read\",\n",
    "        \"Fantastic story and great characters\",\n",
    "        \"Boring and poorly written\",\n",
    "        \"Terrible book, waste of time\",\n",
    "        \"Disappointing, not worth reading\",\n",
    "        \"Awful plot and weak characters\",\n",
    "        \"Decent read but nothing groundbreaking\",\n",
    "        \"It was fine, not great not terrible\"\n",
    "    ],\n",
    "    'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "# TODO: Add your own domain - try something different!\n",
    "# YOUR_DOMAIN_reviews = {\n",
    "#     'text': [\n",
    "#         \"Positive example 1\",\n",
    "#         \"Positive example 2\",\n",
    "#         \"Positive example 3\",\n",
    "#         \"Positive example 4\",\n",
    "#         \"Negative example 1\",\n",
    "#         \"Negative example 2\",\n",
    "#         \"Negative example 3\",\n",
    "#         \"Negative example 4\",\n",
    "#         \"Neutral example 1\",\n",
    "#         \"Neutral example 2\",\n",
    "#     ],\n",
    "#     'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "# }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-DOMAIN TRANSFER LEARNING EXPERIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train on source domain (movies)\n",
    "print(\"\\nTraining classifier on MOVIE REVIEWS (source domain)...\")\n",
    "train_embeddings = model.encode(movie_train[\"text\"], show_progress_bar=True)\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(train_embeddings, movie_train[\"label\"])\n",
    "\n",
    "# Test on source domain (baseline)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BASELINE: Performance on Source Domain (Movies)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "movie_test_embeddings = model.encode(movie_test[\"text\"], show_progress_bar=False)\n",
    "movie_test_pred = clf.predict(movie_test_embeddings)\n",
    "source_f1 = f1_score(movie_test[\"label\"], movie_test_pred, average='weighted')\n",
    "\n",
    "print(f\"Source Domain F1: {source_f1:.4f}\")\n",
    "print(\"This is how well the classifier does on its training domain\")\n",
    "\n",
    "# Zero-shot transfer to target domains\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ZERO-SHOT TRANSFER TO TARGET DOMAINS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_domains = {\n",
    "    \"Restaurant Reviews\": restaurant_reviews,\n",
    "    \"Product Reviews\": product_reviews,\n",
    "    \"Book Reviews\": book_reviews,\n",
    "}\n",
    "\n",
    "# TODO: Add your domain if created\n",
    "# target_domains[\"YOUR DOMAIN\"] = YOUR_DOMAIN_reviews\n",
    "\n",
    "transfer_results = {}\n",
    "\n",
    "for domain_name, domain_data in target_domains.items():\n",
    "    print(f\"\\n{domain_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Test without adaptation\n",
    "    domain_embeddings = model.encode(domain_data['text'])\n",
    "    domain_pred = clf.predict(domain_embeddings)\n",
    "\n",
    "    domain_f1 = f1_score(domain_data['label'], domain_pred, average='weighted')\n",
    "    domain_acc = accuracy_score(domain_data['label'], domain_pred)\n",
    "\n",
    "    print(f\"F1 Score: {domain_f1:.4f}\")\n",
    "    print(f\"Accuracy: {domain_acc:.4f}\")\n",
    "    print(f\"Performance Drop: {source_f1 - domain_f1:.4f} ({(source_f1-domain_f1)/source_f1*100:.1f}%)\")\n",
    "\n",
    "    # Show some predictions\n",
    "    print(f\"\\nExample predictions:\")\n",
    "    for i in range(3):\n",
    "        true_label = \"Positive\" if domain_data['label'][i] == 1 else \"Negative\"\n",
    "        pred_label = \"Positive\" if domain_pred[i] == 1 else \"Negative\"\n",
    "        correct = \"\" if domain_pred[i] == domain_data['label'][i] else \"\"\n",
    "\n",
    "        print(f\"  '{domain_data['text'][i][:50]}...'\")\n",
    "        print(f\"  True: {true_label} | Pred: {pred_label} {correct}\")\n",
    "\n",
    "    transfer_results[domain_name] = {\n",
    "        'zero_shot_f1': domain_f1,\n",
    "        'zero_shot_acc': domain_acc,\n",
    "        'embeddings': domain_embeddings,\n",
    "        'predictions': domain_pred\n",
    "    }\n",
    "\n",
    "# TODO: Uncomment to implement few-shot domain adaptation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEW-SHOT DOMAIN ADAPTATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Strategy: Add first 4 examples from each target domain to training set\")\n",
    "\n",
    "adaptation_size = 4\n",
    "\n",
    "for domain_name, domain_data in target_domains.items():\n",
    "    print(f\"\\n{domain_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Split domain data\n",
    "    adapt_texts = domain_data['text'][:adaptation_size]\n",
    "    adapt_labels = domain_data['label'][:adaptation_size]\n",
    "\n",
    "    test_texts = domain_data['text'][adaptation_size:]\n",
    "    test_labels = domain_data['label'][adaptation_size:]\n",
    "\n",
    "    # Combine source + adaptation examples\n",
    "    adapt_embeddings = model.encode(adapt_texts)\n",
    "    combined_embeddings = np.vstack([train_embeddings, adapt_embeddings])\n",
    "    combined_labels = list(movie_train[\"label\"]) + adapt_labels\n",
    "\n",
    "    # Retrain\n",
    "    clf_adapted = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    clf_adapted.fit(combined_embeddings, combined_labels)\n",
    "\n",
    "    # Test\n",
    "    test_embeddings = model.encode(test_texts)\n",
    "    adapted_pred = clf_adapted.predict(test_embeddings)\n",
    "    adapted_f1 = f1_score(test_labels, adapted_pred, average='weighted')\n",
    "\n",
    "    zero_shot_f1 = transfer_results[domain_name]['zero_shot_f1']\n",
    "    improvement = adapted_f1 - zero_shot_f1\n",
    "\n",
    "    print(f\"Zero-shot F1:  {zero_shot_f1:.4f}\")\n",
    "    print(f\"Adapted F1:    {adapted_f1:.4f}\")\n",
    "    print(f\"Improvement:   {improvement:+.4f}\")\n",
    "\n",
    "    if improvement > 0.05:\n",
    "        print(f\" Significant improvement! Domain adaptation helped a lot\")\n",
    "    elif improvement > 0:\n",
    "        print(f\" Slight improvement from adaptation\")\n",
    "    else:\n",
    "        print(f\" No improvement or slight degradation\")\n",
    "\n",
    "    transfer_results[domain_name]['adapted_f1'] = adapted_f1\n",
    "    transfer_results[domain_name]['improvement'] = improvement\n",
    "\n",
    "# Analyze domain similarity\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DOMAIN SIMILARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate domain centroids (average embedding)\n",
    "source_centroid = np.mean(train_embeddings, axis=0)\n",
    "\n",
    "print(\"\\nDomain distances from source (movie reviews):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "domain_distances = []\n",
    "for domain_name, domain_data in target_domains.items():\n",
    "    domain_embeddings = transfer_results[domain_name]['embeddings']\n",
    "    domain_centroid = np.mean(domain_embeddings, axis=0)\n",
    "\n",
    "    distance = np.linalg.norm(source_centroid - domain_centroid)\n",
    "    zero_shot_f1 = transfer_results[domain_name]['zero_shot_f1']\n",
    "    drop = source_f1 - zero_shot_f1\n",
    "\n",
    "    domain_distances.append((domain_name, distance, drop))\n",
    "\n",
    "    print(f\"\\n{domain_name}:\")\n",
    "    print(f\"  Embedding distance: {distance:.4f}\")\n",
    "    print(f\"  Performance drop:   {drop:.4f}\")\n",
    "    print(f\"  Zero-shot F1:       {zero_shot_f1:.4f}\")\n",
    "\n",
    "    if 'improvement' in transfer_results[domain_name]:\n",
    "        improvement = transfer_results[domain_name]['improvement']\n",
    "        print(f\"  Adaptation gain:    {improvement:+.4f}\")\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Correlation: Distance vs Performance\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "domain_distances.sort(key=lambda x: x[1])\n",
    "print(\"\\nRanked by distance to source:\")\n",
    "for name, dist, drop in domain_distances:\n",
    "    print(f\"  {name:20s}: distance={dist:.3f}, drop={drop:.3f}\")\n",
    "\n",
    "print(\"\\nObservation:\")\n",
    "print(\"   Domains closer to movies in embedding space tend to transfer better\")\n",
    "print(\"   Larger embedding distance correlates with larger performance drop\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFER LEARNING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Domain':<20s} {'Zero-Shot F1':<15s} {'Adapted F1':<15s} {'Improvement':<12s}\")\n",
    "print(\"-\"*65)\n",
    "for domain_name in target_domains.keys():\n",
    "    zero_f1 = transfer_results[domain_name]['zero_shot_f1']\n",
    "    adapted_f1 = transfer_results[domain_name].get('adapted_f1', 0)\n",
    "    improvement = transfer_results[domain_name].get('improvement', 0)\n",
    "\n",
    "    marker = \"\" if improvement > 0.05 else \"\"\n",
    "    print(f\"{domain_name:<20s} {zero_f1:.4f}          {adapted_f1:.4f}          {improvement:+.4f}     {marker}\")\n",
    "\n",
    "print(f\"\\nSource (Movies):      {source_f1:.4f}          N/A             N/A\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fa4e26da49ab490391057153659fe544",
      "199c9d5da4bf47baba405bc6555d9aba",
      "8a74df22f6e641f4812f2cc0f219039d",
      "0b2925cbaf3443758b52afbe41abd2f1",
      "aeda2644bfdd451198ea472fe8e7cf78",
      "86237397fec642049ff500bfa6cba51c",
      "ab5f53b292cd45f792ba5a717fa4720a",
      "318a40cb79bd49cc8c0a4b99cd9fe81b",
      "1582e826db4d4eecb28283bdbb088806",
      "cc5281d351a74d1db6f7a1c6845d61df",
      "593f99ba62cf4a2c980a706f21f6c4cf"
     ]
    },
    "id": "NWvx0lRMHmAv",
    "outputId": "434846c2-b49b-4a10-bb3e-d9d71c3b6761"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================================================================\n",
      "CROSS-DOMAIN TRANSFER LEARNING EXPERIMENT\n",
      "================================================================================\n",
      "\n",
      "Training classifier on MOVIE REVIEWS (source domain)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa4e26da49ab490391057153659fe544"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BASELINE: Performance on Source Domain (Movies)\n",
      "--------------------------------------------------------------------------------\n",
      "Source Domain F1: 0.8497\n",
      "This is how well the classifier does on its training domain\n",
      "\n",
      "================================================================================\n",
      "ZERO-SHOT TRANSFER TO TARGET DOMAINS\n",
      "================================================================================\n",
      "\n",
      "Restaurant Reviews:\n",
      "------------------------------------------------------------\n",
      "F1 Score: 0.9010\n",
      "Accuracy: 0.9000\n",
      "Performance Drop: -0.0513 (-6.0%)\n",
      "\n",
      "Example predictions:\n",
      "  'Amazing food and excellent service!...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'Best restaurant in town, highly recommend...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'Delicious meals and great atmosphere...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "\n",
      "Product Reviews:\n",
      "------------------------------------------------------------\n",
      "F1 Score: 1.0000\n",
      "Accuracy: 1.0000\n",
      "Performance Drop: -0.1503 (-17.7%)\n",
      "\n",
      "Example predictions:\n",
      "  'This product is amazing! Works perfectly...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'Excellent quality, very satisfied...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'Great value for money, highly recommend...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "\n",
      "Book Reviews:\n",
      "------------------------------------------------------------\n",
      "F1 Score: 0.9010\n",
      "Accuracy: 0.9000\n",
      "Performance Drop: -0.0513 (-6.0%)\n",
      "\n",
      "Example predictions:\n",
      "  'Brilliant book! Couldn't put it down...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'Masterfully written, highly engaging...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "  'One of the best books I've read...'\n",
      "  True: Positive | Pred: Positive ✓\n",
      "\n",
      "================================================================================\n",
      "FEW-SHOT DOMAIN ADAPTATION\n",
      "================================================================================\n",
      "Strategy: Add first 4 examples from each target domain to training set\n",
      "\n",
      "Restaurant Reviews:\n",
      "------------------------------------------------------------\n",
      "Zero-shot F1:  0.9010\n",
      "Adapted F1:    0.9091\n",
      "Improvement:   +0.0081\n",
      "→ Slight improvement from adaptation\n",
      "\n",
      "Product Reviews:\n",
      "------------------------------------------------------------\n",
      "Zero-shot F1:  1.0000\n",
      "Adapted F1:    1.0000\n",
      "Improvement:   +0.0000\n",
      "→ No improvement or slight degradation\n",
      "\n",
      "Book Reviews:\n",
      "------------------------------------------------------------\n",
      "Zero-shot F1:  0.9010\n",
      "Adapted F1:    0.9091\n",
      "Improvement:   +0.0081\n",
      "→ Slight improvement from adaptation\n",
      "\n",
      "================================================================================\n",
      "DOMAIN SIMILARITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Domain distances from source (movie reviews):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Restaurant Reviews:\n",
      "  Embedding distance: 0.7160\n",
      "  Performance drop:   -0.0513\n",
      "  Zero-shot F1:       0.9010\n",
      "  Adaptation gain:    +0.0081\n",
      "\n",
      "Product Reviews:\n",
      "  Embedding distance: 0.6779\n",
      "  Performance drop:   -0.1503\n",
      "  Zero-shot F1:       1.0000\n",
      "  Adaptation gain:    +0.0000\n",
      "\n",
      "Book Reviews:\n",
      "  Embedding distance: 0.5339\n",
      "  Performance drop:   -0.0513\n",
      "  Zero-shot F1:       0.9010\n",
      "  Adaptation gain:    +0.0081\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation: Distance vs Performance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Ranked by distance to source:\n",
      "  Book Reviews        : distance=0.534, drop=-0.051\n",
      "  Product Reviews     : distance=0.678, drop=-0.150\n",
      "  Restaurant Reviews  : distance=0.716, drop=-0.051\n",
      "\n",
      "Observation:\n",
      "  → Domains closer to movies in embedding space tend to transfer better\n",
      "  → Larger embedding distance correlates with larger performance drop\n",
      "\n",
      "================================================================================\n",
      "TRANSFER LEARNING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Domain               Zero-Shot F1    Adapted F1      Improvement \n",
      "-----------------------------------------------------------------\n",
      "Restaurant Reviews   0.9010          0.9091          +0.0081     \n",
      "Product Reviews      1.0000          1.0000          +0.0000     \n",
      "Book Reviews         0.9010          0.9091          +0.0081     \n",
      "\n",
      "Source (Movies):      0.8497          N/A             N/A\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": "### Questions\n\n1. Which domain transferred best from movies? Which worst?\n\n2. Do you see patterns in what transfers well vs what fails?\n\n3. After few-shot adaptation: Which domains benefited most from just 4 examples?\n"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "yZLqm3S4IP2e"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}