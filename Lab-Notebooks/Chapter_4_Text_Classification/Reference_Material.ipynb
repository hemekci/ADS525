{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_a9QvUFVCUR"
   },
   "source": [
    "<h1>Chapter 4 - Text Classification</h1>\n",
    "<i>Classifying text with both representative and generative models</i>\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
    "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter04/Chapter%204%20-%20Text%20Classification.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is for Chapter 4 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
    "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LGW2SD-c864"
   },
   "source": [
    "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
    "\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
    "\n",
    "---\n",
    "\n",
    "\ud83d\udca1 **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N-PxmOIhc865"
   },
   "outputs": [],
   "source": [
    " %%capture\n",
    "!pip install transformers sentence-transformers openai\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBeVnXxQWy7-"
   },
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784,
     "referenced_widgets": [
      "169816892c8646e3888f213295349f00",
      "4a590f6ceb104873b97b9620d6107017",
      "2d14e5528bbd446e8a34c235201f88ac",
      "f4c9e362c7ff40559a1a5632a8b6e907",
      "3c4c633f0af84d099ffc74bac8901b07",
      "35226b53943b4db8a5d46aae09720818",
      "1a6faf9a5ed748f0809834cc52435b3d",
      "4fe179f7fab44513aeaa33cedf44f1bb",
      "5befa9362a09459695f4489c7173c34d",
      "458ad67bb385497889eab5bbdd977de5",
      "027a7c3f8a9e4114ac6d4e64fb62d440",
      "0cce924a44f94cbfaa69a78735ece1d5",
      "28ac2aeffcb6424f97fb47bfaee8e66f",
      "ab02cefe39774db3844d914b65a48790",
      "6bf6e7d710eb4924a3144e6e5d0679ca",
      "b7b774839b134ee687d9d89a0e15d166",
      "c583fda17dd44217875e86209fbad80a",
      "cd4eeedee4fc4f28acf650785bbaa5f3",
      "e5138fd5028f48f9ad8eea2b41b1592a",
      "82f4409e3f854415a871e3da31e9393e",
      "aeb337caa109443a9fc4f93e9f92753d",
      "e7e6399dec234052b7f30e3135a21b00",
      "44a764c1267042259b2c9597a69f6f76",
      "05e8f57e23ff47f0be24d3f9c18554d4",
      "616321e6e87a4d8589d9ed939e19c7b2",
      "8d7284d945004b98b28b6c631a2c4726",
      "97d864e9c07149aeb22a844ced3909d5",
      "dbadb6dfe23141ec8f38ffb747ea882e",
      "82d0c0a18606421f92ed77d8d4c61e10",
      "0c64a3bc4d4d461cbdc3c3c0acae2f94",
      "cf707e36593b4071b8253fd33d18b665",
      "079412e5345a4a09875ed0c86dde93e3",
      "1e2ffd31336946cf952abb5f62651c16",
      "8466edc3103c45d8a5d3fe8166508648",
      "f8d0d8f24551457e862d2e041f3699ab",
      "426852cccf704c58bdc7decbb1c583e6",
      "6b2663befc574a8e8154631c3ac95ff3",
      "091bd22cb6d94ae5b7c962d18e528ca2",
      "5ba5883cc2144929b9d7ddd980e4508d",
      "971d17ca015446b4bbf8a908835295cd",
      "c7086b545eae4b09af3b2d77b78af4b9",
      "5f47aeddde3449a5b5ed280d0ec9bc18",
      "43791444ad3e49f993d17887e6c15dbf",
      "c2c3403eb38b420cba7390d385f325be",
      "9097dd47971f445ea0fd55e7c42c15a0",
      "18cbf6cbaa4c436d9074224f83472863",
      "831180b810da4b549a8ca75536607e31",
      "d9779ccf530e49b1ac52172252ec5ef4",
      "78d69219fad44722a9bad3a12a3ccb61",
      "f08fa19e07644f4d9fff30d02040e315",
      "e1a2a1e765f042a7b9b081688688dab5",
      "76d299a97ab54dbe96f4525095afedcb",
      "73ac94bdcaf8427bbbcdd808f1428dff",
      "6f9a5d0dfe2f4aa49c57e942b927521b",
      "2d7810d299f649a2ac84541e7215d29a",
      "40dc8a185cf34e99a427f7c81bc76540",
      "bcac3e31740e4a2894b4e8bc9656a0c5",
      "87f29bce5b5d4df08b5337d62ffa9568",
      "3129b232f1e3411ead0d913654a11eaa",
      "4e7c3e87552640018f89c6cf9e070642",
      "01ccc633ad5d4350ad04651e360cc478",
      "735737e7c1eb477fae9d06d7324e81e8",
      "882b69fb84034d2dace625ef267f51cb",
      "8c77be8e5b74452bb028b97fd9edba36",
      "55a6296e28394f41b2a6d1f3d76e5944",
      "8f6c7a732bb6498db1de4d66f4b3c623",
      "22541d211626493e87c168143671e5ce",
      "111b9c6182994e2e85a323d07980b1ab",
      "3c53665ac233434fa899399da13650f0",
      "c4867626e6eb41bfaade350790de9f40",
      "a11866f208c4411dbc3d627ef6dbd74f",
      "3485c0ebc7f24965a0fadd3a6570d51e",
      "d111b1f753554eeda57cdbe420335fda",
      "8fb77e0530e946d38c007c9012c37a79",
      "8d669f0719d04980a6f04ffc2f65cf7c",
      "d79a649275a14fdeb2cb01e5ab75021f",
      "14186c7dd75e43d99183d5c8b308c0de"
     ]
    },
    "id": "5phRS_z2U_3T",
    "outputId": "e51c9c23-a48a-4c61-e7ee-cd0ef03915a4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "169816892c8646e3888f213295349f00"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cce924a44f94cbfaa69a78735ece1d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44a764c1267042259b2c9597a69f6f76"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8466edc3103c45d8a5d3fe8166508648"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9097dd47971f445ea0fd55e7c42c15a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40dc8a185cf34e99a427f7c81bc76540"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22541d211626493e87c168143671e5ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load our data\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJJmaJzHDLZv",
    "outputId": "fd2ef721-8635-466b-d787-515fc8e4dffd"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       "  'things really get weird , though not particularly scary : the movie is all portent and no content .'],\n",
       " 'label': [1, 0]}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data[\"train\"][0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xya5dfmVoR1R"
   },
   "source": [
    "# **Text Classification with Representation Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co68g-Eloknf"
   },
   "source": [
    "## **Using a Task-specific Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448,
     "referenced_widgets": [
      "1fb504f12d6e4b40937b0ef9db1b2644",
      "7b89f8211c56444f82518264593156dd",
      "a4a66adab7f641a9bdb6496e0401881f",
      "bd8c5ad9440742bcb4779705379b98fc",
      "ba257dbbadc742bcaa34780cc1fd7db5",
      "9e2e1629f04643fb893e0a1bb99589ae",
      "925169e5d07c4d229b342fe4b41b2544",
      "0dc110695d3943a5afbaabc2ccb74bce",
      "92249295eebb4dcfbb17b2eb348bcfc6",
      "11b59aee3f1c43bc821a8b2abba4d9a6",
      "7e4bfde8cc0f41409e5703b50ca951ae",
      "a52864b4ba6f443e95be535dfa78bd81",
      "b79bbe20431c4eaa8ab39e71c682a4a5",
      "e3128b82fd3442d39afed90fc9ef77b7",
      "a72769becce048b6b2d5fd92a7b7e105",
      "e4c4c6616a5d458499fb035f8c96a72b",
      "4e741246929d40fa93a0d4bd178dad14",
      "207aa57d2b224b9fb42fdecb67864c7a",
      "4527a8a8f8e945c5b1e289fa84aa2dd9",
      "0aeaac43201c41328a4f009378893889",
      "8d378ae5d43d484abe48e3d84e9ede8e",
      "83051aac1ae6471cace09a99e3e48d78",
      "1c69a7234956470dae17b814673702c1",
      "53a98f00da5b4373bfc55dc68338e33b",
      "b8a04b7c0a0942b58c906b2742613aed",
      "b481591887bd4b4aa7796fa1f08db48d",
      "13f95d964fca4ebfb805883f914ac552",
      "f342b12a14bc4679af668aacdc56e755",
      "2eeb334e09d848fdba87cd8e9763b55e",
      "87016c44c90147a591311e9122b990ab",
      "eda4d37856194c1da4ae1b1166857222",
      "8f7d09967c32447bad6b421af147a499",
      "dbda5498ffdf48c2970f7b80e3bd3981",
      "6cdfde3fe9e947609ac08516e75402b5",
      "a22a276031104274b9ae00ae0d492f05",
      "299b4336b07743d2904424f31adf6088",
      "abb5d0a0710d464e938bc080687ec765",
      "ff8c599d1975469e89c4b0c255c28dba",
      "569e6c83aef24232a4b37207418fde55",
      "cb917089e8894de9a97199092a924527",
      "c439af89c3814f5abf12f422e5eacd60",
      "a70c2a858aab45f28a118da4d0a2816e",
      "7afc0a026ff54a658bd608bd18e03fd8",
      "763bef1d422b436ba1bcc959016c1417",
      "80f655a52a2b4f269889f0fa0db922f1",
      "4924034b3042401ca21c0c0229262267",
      "c9c3b424188b49a39ef396a501aa7b51",
      "5a0e9e8e59704764b93adb898325e0ff",
      "66ef85a159ae4abf8deb5710a49b3bf5",
      "87e8a8450bda49f9918213b9808beffe",
      "a9693c19e60344a8b5d246571fe65cde",
      "7bcfaa94e7af4c0ab5dd1353b36982f6",
      "53a7294ac44e49eaa2bf5ba46b78496e",
      "365e12fd2f3a4f9e817163e571ced1f0",
      "45d9ba9b2c36424bbf4b38d814ee95a2",
      "209836d671e548f7a126c95a6ea4f039",
      "abe9c4abaf204c5fb54d074d43a4a0e3",
      "ede9f93cc7064bfcb27331753580651c",
      "e9d028695e614841912c29586f6aa0ed",
      "cd8c7e3ed61b4c18820a1eac523c2ec8",
      "051b04994a2a44e98a0456ec7fcc4364",
      "403f3c6a21e84992b9a1715c61611919",
      "b192ab52b45a463cbd8ec4fa2be30e93",
      "d82f5d2fd051445291e7efef43b0e07a",
      "4fedc855d66a408b8ef6be24e0f126cc",
      "df6477cd708245fcaf89ed3a0243426d"
     ]
    },
    "id": "ph-3T3XJopdN",
    "outputId": "bba715ac-9776-4816-fb43-d72a1b915fb6"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fb504f12d6e4b40937b0ef9db1b2644"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a52864b4ba6f443e95be535dfa78bd81"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c69a7234956470dae17b814673702c1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cdfde3fe9e947609ac08516e75402b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80f655a52a2b4f269889f0fa0db922f1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "209836d671e548f7a126c95a6ea4f039"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Path to our HF model\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Load model into pipeline\n",
    "pipe = pipeline(\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    return_all_scores=True,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2gbnL5Q69Y5",
    "outputId": "b51721d2-df8f-4e0d-8066-127b9ca1beac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1066/1066 [00:10<00:00, 103.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "# Run inference\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
    "    negative_score = output[0][\"score\"]\n",
    "    positive_score = output[2][\"score\"]\n",
    "    assignment = np.argmax([negative_score, positive_score])\n",
    "    y_pred.append(assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X0KyKHtqyjn3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fum3MTSyymlW",
    "outputId": "d7cbdbbb-91be-48b4-da8e-1aae9936dd08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.76      0.88      0.81       533\n",
      "Positive Review       0.86      0.72      0.78       533\n",
      "\n",
      "       accuracy                           0.80      1066\n",
      "      macro avg       0.81      0.80      0.80      1066\n",
      "   weighted avg       0.81      0.80      0.80      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr3WT4jzoNZE"
   },
   "source": [
    "## **Classification Tasks that Leverage Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8yuSP3heMzT"
   },
   "source": [
    "### Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685,
     "referenced_widgets": [
      "4e81be8e5ffc43099d1768f2b379c2ce",
      "dcc81d53b875455885c741b3af3a5b0a",
      "be43233653e14ef99a9fe4d307c831df",
      "c7a2b1dc071c40f4bfb7bdf23d46628d",
      "5a93e11d2d4c400492a77216349bd690",
      "e5612408eb3547a881b5bbc976f1fe29",
      "9b8c5d6b959e4e03b4d29ad32986b659",
      "1ca82d860d0344cb856382534a6bfefc",
      "022fed1441914a0ca352a734940836fd",
      "42349dbbd1534a1bb309353b2d642c1b",
      "86ee3f61b6c443e7b0cc14ccacb8d93c",
      "0962ea3d1fa34efcace74c949a3f636a",
      "18ade018745d429680f5f6d6b2a12217",
      "5ff845b3c271455eb7de17b621c4f8da",
      "2f46c4961c1941f68bd6744d910c4951",
      "aab906d02f894947a7a939919112c82d",
      "0607d79940504e49a9c404192b9f0ab5",
      "57d43902023d4014bd0662e730b4185e",
      "31c0895f9513498ca76c57e3826f7816",
      "60aed70d6d1d46d0846c6f8953316176",
      "0a343810af264b8d9218f78c1425358a",
      "cf1a3a0460a54b738b3a4fbce9595efc",
      "ff44125d52054f29ba06ceae0a6821b1",
      "83cf3e9f22764776826ba9916361fa1d",
      "57eabd446bb642a0ac6ffcd48b51bf20",
      "3adb5f1d06d44efb937aa60d4dc6b590",
      "d054cd84029042478bf37a80a5afca2d",
      "cacef97c29894887b41e3ff709a6212d",
      "24c5e567304f4f708e00a0232bf74bc7",
      "bfed59c1582b4524a7fc2273de2bb03f",
      "c3e8bb57d7b3464f9faf0ac08778ef68",
      "4a6134d8cebb474192acc22bcaafcd95",
      "ec4bdfc264144ac9a3ddff215370e2c9",
      "cf7e368bd70e479bb003b8688deb27d5",
      "af4541b7787a40dfa185badaad4fc7d9",
      "bbe7a95510a24ebf99a8df491fc59d1a",
      "3261ae1c6fdb45cf96b4a4552a45626c",
      "1debcc698a0843e1a879beb195930aff",
      "a69251a68dd34672a0a336e140663e2f",
      "dec830ff5c8f49d9ba5fba56eb2e9071",
      "08e8167e9ca74af7aa71f83249cf47e1",
      "4ad52778626948618e3f025cf018dcf0",
      "6318fa44715a42bca4c84a92c19c3dea",
      "d47538747b4c4c2ba233610bf0564134",
      "4e256742aed947089df526b210c16290",
      "5f70584f9eb84ba3b460ba9ac76ee453",
      "f37ca89700644feba278d17b4c6aeaed",
      "140e5095c3d3461ead6ee0be72b00f5d",
      "25cd477eadfb483fb8d8574a22b8c6ea",
      "daa4ca445a37481587114eaa8cf4ee76",
      "fc2ad0c3efcc4fdea1a4e6e51e3252e2",
      "79fbb1c65d374f49a96940ad9433e29b",
      "02f96098408e4b7e96fe30c01edec74f",
      "afec417c406e44e8864a7d91fcab9c70",
      "06720654f3d8410da53c7d47d60e5e48",
      "3a2239bbac764e18a6d3e54bd8e24385",
      "78e8da5c28724c2592b94ad087fb447f",
      "55853935d9da448e9f65708aefbb433a",
      "3e614baa3e1d4501838b59fc0c8be5b8",
      "e0a029527cdc44f2a2bd79c2adc2c948",
      "f1dd73af95b446cbbb626badb15dedee",
      "ef459535fd044f02b738551eb3202ab7",
      "5d8475a83bc249d5915bd436657b2138",
      "472eb71cf8cd4e6cabda9324530b1a88",
      "71258f3809544398958756a56b939501",
      "eb517a787a5242d1b899029a064dc729",
      "66d1c59207bd4b579b17f91a173b64d3",
      "45b88debf5bd44fab095277825c5a61d",
      "85cf17b86a404041a4357d114ee31380",
      "028cc741e4ad48158c9f7bafef680816",
      "b23100f08efe4daa97201b09d1cb589d",
      "123308249ab74cad8f04383520f57ea2",
      "f9694cb1ee8f4dd1b48f3eee91faa0fc",
      "278c539dd782455f80eb7d28b11596b3",
      "ebceb670f6324a69b417a65dde28844c",
      "852ab216c2cd448bbcda88ba4516dfc7",
      "9ba5975196e441538f7d27cc7ad8d5c3",
      "9b9b1d35635e453e9dc7be625b5e22ab",
      "8c6be67889bb45548d17945ea1c7748b",
      "a3db156c5ae4456490622f69d9d7a419",
      "48e1e45ee4514353b66a5ede013c4126",
      "85d46881181c4a409ae830f2e8d8bc0a",
      "63f2725708e942759ee5f97d0ba543d5",
      "76e69a4aba9a44f6804ba2f5b31987c5",
      "6bbd2f542b5f4509bc701a8f3eca85d4",
      "c8f79a7929234d25af837a9accf1c7c6",
      "f4020fe822374f6d931ec3156f5f8290",
      "d49d651103c647deb11a79c9a8594720",
      "0ec62022b7f14c17aaf7ec388bf7a35f",
      "9905cf8fecd74170823db01f048d6c18",
      "5257ebdade3347bab07ed3592c388644",
      "2d6ca74dc7f547d19f4ccc7e2c344ba6",
      "52b07ec3bf20486f968697aac159e3ec",
      "57ce50bb57d843f68aa6502d87cbb39c",
      "bbebb6d8b43d4d97abf04701510aa678",
      "15e435cf2f174a36aa154847da606f89",
      "e476841f60734793bd50fe0803d2ff5a",
      "f33cf0e51acd4f0285ea91b9c697125a",
      "8bb620a2b07145b4b201c6d016e5183c",
      "8165eeff3f4b453fa6236e8fab4f6fcb",
      "e7dd7f4a1c9d46ef92faa9839d6206f5",
      "76630bfcf6c740f99f23e654a5c78e93",
      "c2fd1cb6aabb4d2ba1abdba8dde381a1",
      "2c3095624df04d638a1b5b6c76e1739c",
      "0c61efba3db24edf93e0ad5eadfbfe94",
      "e22ce558f5fc4787bd7d13d5001cd0b4",
      "3ebe369233fa44b4a0a5d42d081b4e81",
      "6a44d72ebb0c4ea8b63474895e9a678c",
      "1d6324eb9d034df2973a75d0aba93224",
      "f32e93567eb74ce8a26f2f935674f522",
      "da6359244454407c847ec5af84461ff4",
      "d1252bef4d2647b5ae41d30fb25dfcb3",
      "f81f8b2ee6e34ae89231077455703fb1",
      "791836d8a7b34eabb236e60320d319f4",
      "588504b532aa43deb77e717cd191cc7c",
      "54824268dc954706b1e460b741f103c2",
      "1492d718e5884b6cb3dbfd12a1dba7e9",
      "740baaf426be416a9fc2c0707fbaff92",
      "cbeb5b778ba34bc6b1a744ad95739f84",
      "22f0c566b1e84415a4df68ce85ba2940",
      "fae11149bf684ef0803fbcd0fa4ce6f0",
      "2dcd3d5224cf42dc9d46b00eb1f84c59",
      "fb5ef3cfc0e143caa20a81824a3f7596",
      "1ebbf46483864b0080e5ffee82bb5f8c",
      "e142cbdfa66941fba47fbb93c36d6776",
      "25c8b5c5ef38486f94ffa3af6ab4674e",
      "ba56a8a3e951454ea17717b754a60383",
      "b2761db375ed401b99d1a59fef5dcc57",
      "3b67c923023944b8a306190719df4c93",
      "01e53b31eebd4a1ca26d11040bcdedbf",
      "26809486bea84d8bad34827ba420c316",
      "0072cd435347438c842245818f9a5ec6",
      "9786eefbd37b4c92b77e878216a10ac0",
      "662ba5d6c58047cb99a58f4e6ed92f00",
      "4ebf212b49604116ba04bfb42d090199",
      "42e594681a844633a8fc13977f695539",
      "5709e500046240938a7c4fc83deb6f83",
      "8f6f96b4ea33432dafbfd1197eea0f28",
      "aa752f8c13e543f8a1d228a7f7fd7aec",
      "132d3c773337426fa8cfe56ec177f2af",
      "c7b6a57e5818487fb100d89d84f40ea4",
      "a4f3f29846074639a369b57b28ccfbd4",
      "8a4c41494ed54c6797c6dab0b8dd676d"
     ]
    },
    "id": "jGV9VS4bhq7f",
    "outputId": "f585566a-d8c7-4abc-d93b-a40933470a86"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e81be8e5ffc43099d1768f2b379c2ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0962ea3d1fa34efcace74c949a3f636a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff44125d52054f29ba06ceae0a6821b1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf7e368bd70e479bb003b8688deb27d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e256742aed947089df526b210c16290"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a2239bbac764e18a6d3e54bd8e24385"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66d1c59207bd4b579b17f91a173b64d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b9b1d35635e453e9dc7be625b5e22ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ec62022b7f14c17aaf7ec388bf7a35f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8165eeff3f4b453fa6236e8fab4f6fcb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da6359244454407c847ec5af84461ff4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/267 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dcd3d5224cf42dc9d46b00eb1f84c59"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9786eefbd37b4c92b77e878216a10ac0"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Convert text to embeddings\n",
    "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
    "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5L5CLcOxIeA",
    "outputId": "8df2014c-4d1e-41b8-e686-30f539c22b08"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8530, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "8A7oTxoph6bn",
    "outputId": "87cff4c5-f6f7-4cc2-c226-d0bed2eb5ab5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\u25b8\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\u25be\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression on our train embeddings\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFvO9KhMokF7",
    "outputId": "e615b92d-b487-4ed0-f7e0-d313d55fe093"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.85      0.86      0.85       533\n",
      "Positive Review       0.86      0.85      0.85       533\n",
      "\n",
      "       accuracy                           0.85      1066\n",
      "      macro avg       0.85      0.85      0.85      1066\n",
      "   weighted avg       0.85      0.85      0.85      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict previously unseen instances\n",
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGIHxXpJgrC"
   },
   "source": [
    "**Tip!**  \n",
    "\n",
    "What would happen if we would not use a classifier at all? Instead, we can average the embeddings per class and apply cosine similarity to predict which classes match the documents best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f_DnG1uJ7Sk",
    "outputId": "fc8fb382-b6e9-481a-9c70-8ac1a1a5c96a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.85      0.84      0.84       533\n",
      "Positive Review       0.84      0.85      0.84       533\n",
      "\n",
      "       accuracy                           0.84      1066\n",
      "      macro avg       0.84      0.84      0.84      1066\n",
      "   weighted avg       0.84      0.84      0.84      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Average the embeddings of all documents in each target label\n",
    "df = pd.DataFrame(np.hstack([train_embeddings, np.array(data[\"train\"][\"label\"]).reshape(-1, 1)]))\n",
    "averaged_target_embeddings = df.groupby(768).mean().values\n",
    "\n",
    "# Find the best matching embeddings between evaluation documents and target embeddings\n",
    "sim_matrix = cosine_similarity(test_embeddings, averaged_target_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCWdzjMIjzx0"
   },
   "source": [
    "### Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YSj6CdAetsNp"
   },
   "outputs": [],
   "source": [
    "# Create embeddings for our labels\n",
    "label_embeddings = model.encode([\"A negative review\",  \"A positive review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZEIN7XnbtsQJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Find the best matching label for each document\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6LyeuEUxIbW",
    "outputId": "97ecffce-64bc-406e-c4a1-e339d5d38661"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.78      0.77      0.78       533\n",
      "Positive Review       0.77      0.79      0.78       533\n",
      "\n",
      "       accuracy                           0.78      1066\n",
      "      macro avg       0.78      0.78      0.78      1066\n",
      "   weighted avg       0.78      0.78      0.78      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox27Rg71zclg"
   },
   "source": [
    "**Tip!**  \n",
    "\n",
    "What would happen if you were to use different descriptions? Use **\"A very negative movie review\"** and **\"A very positive movie review\"** to see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CC9iEGcuUit"
   },
   "source": [
    "## **Classification with Generative Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFPPzUHoEESB"
   },
   "source": [
    "### Encoder-decoder Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nVbTUMktEfJ3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "referenced_widgets": [
      "e3c53af41c05458b91c8cb4cb69fba8a",
      "32f800b9e8804e979cbd8aadd4571254",
      "ae1b8719376041f0a458c2d7b0f99408",
      "a11cebfe657841c5b8024e6d52b0063a",
      "5565c64a2fe24d7ca9cf3d661cce5bb4",
      "fc6d796c33d945e69401032520bef25d",
      "1910b69faa9447ffbfb5e198ef2d01d0",
      "b78c4127c28947d0a15059dbc3948862",
      "c5044f7398254708bea7f0125768c60d",
      "a08f96a06fd1441481350d4f48f09dc6",
      "2f4dec3cf6db49eb97cb2a346f1f7782",
      "1f82b98231d744f6ad34b4fed6384f7d",
      "313e7d753b70480c94f60f75213dfeda",
      "5e816195da1a4fcdb9c72aa605fd3956",
      "f310ebc9821f49ae8096313253bd423a",
      "d4e2e5fb626941d5becad8f1262cd047",
      "ace3ace81d844f8dbb57c249e4471551",
      "4a62f65d928e49ef997855445372a6ea",
      "97a4a4526cc84972bae0bd0ef45803b7",
      "202e73910ddd437a818ff575ebfffc5e",
      "3be66085a1a541fc94f026ce4d5f1dc1",
      "7b4175623f7f450fb9c13142fa5df589",
      "98cfd3afaec74253bfb56598bc537d60",
      "f1aef66b2467475bb60851c07f9fd03d",
      "cca8f5e8f43d4a9ca8b2a301350499e4",
      "f282524923ba40c283e35eaa8d8973a6",
      "b7f204ddbb0a4ef493b448640140827f",
      "b5461053b1374b60aff966cb0c26ebf6",
      "0395d66d89cb47ed85b69b2bce090e40",
      "70130491fbc9424cb5eb9b728d03ccf3",
      "fb805f536d3347e2961f7543ad3b03e0",
      "dd0547a8c7f84d36b2be515b136ca497",
      "7b00da40af594ae19147c74b3e37b8b4",
      "446e7f92920940908ba16181855828aa",
      "f968e67ffcea4ef3943ccd6fefc11b1a",
      "cec59a1dba4444548e19015cbe4255f3",
      "306647e5f13b4c15a2d7710549f7fc3f",
      "dab122cefd714332b80bfea6bb7d1d2c",
      "3756a087647b4c45913ea4b3fbd71cda",
      "4b360fd029ae416e9417898f6c43dcf1",
      "ebd2071e9c054e9dafc323f9ffa69f56",
      "721e7b44907b4b5e8c7d015b8906db79",
      "ed0483749d114f15bf37b844739a9234",
      "ede8e21ca6814d36b4bd5bdb847f70dc",
      "e9c027409c9e49368d0cc36b5d62c52c",
      "4bff2a2a0bf0472abe011c2b1ded9d4b",
      "5c88c245bc244c12aae4898400f7a053",
      "4b633b7133b34d1ba5ba62c8916003ed",
      "358e7cef13554483a708050d45396f72",
      "f668805e6b094b3f9a205e697dd4f6c4",
      "4fc88a1f6e6543e19d0aea370bab49f6",
      "4a3a23c9ff1742be896976e832bd83ac",
      "d02b9e66f5304c089c7beaa1af709816",
      "1fd40b5711174c999dedc1624ee9cf68",
      "30119dd2b3e74e3e9eaf7e82a25613bb",
      "2348e8f1a3634ab0a21512ecd3d00a71",
      "e659fc84b605407c8698f6046295b6d2",
      "99445d5215b14415b1213a8553ef67f8",
      "5fafa1e845a040e085902c32e0a6d8f1",
      "4aee19ea1fb248fca3c22f75f775f128",
      "72eb81a28e98419697a3a4250a0f33ee",
      "70759d5046d148c7a7414ee7ac4182aa",
      "18a56bfe25994f78b2e9a713138ece21",
      "11d379e1c59d45949df0a98e3c38088e",
      "9c22d0584a1d4156a92807c930b22447",
      "b9e3266f8ef241e18ee2ab60acc1368f",
      "7066c85998e54a0585eb7319941aee51",
      "2a097c1ea6f04e0297ab1f405495d2e6",
      "174a0595415448f7ad17ba019fc31170",
      "d7bf9447859049859be60fe1323d66c2",
      "6c9700179b1c4c638be98c7d62716ae8",
      "e335b820cc0a4c27a1d5343b3e91e06a",
      "1c4968d9f46e442eb6889b2f9338adc2",
      "872814d874304911b8263611db91ef5b",
      "660a831c47a94a41866f689cc876e049",
      "bf466d43270441aca764f96766a16573",
      "eaea684194e048b395dd2cb94dd84bf0"
     ]
    },
    "outputId": "0211e7cc-0836-4b0d-d526-05d3ee92b661"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3c53af41c05458b91c8cb4cb69fba8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f82b98231d744f6ad34b4fed6384f7d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98cfd3afaec74253bfb56598bc537d60"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "446e7f92920940908ba16181855828aa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9c027409c9e49368d0cc36b5d62c52c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2348e8f1a3634ab0a21512ecd3d00a71"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7066c85998e54a0585eb7319941aee51"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load our model\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446,
     "referenced_widgets": [
      "f371013970fa447199a0672409ca70d9",
      "f2ce79614eb240c9b2eb96a71ac3f532",
      "e96ac2968930406c895c0203b8b92dd2",
      "db31757768e447b5b87635793fd94496",
      "d074df2d615344e8a8e4569fc8fe5ff7",
      "1d0ad5f0de564c289aa20c650e6adfcc",
      "0526f08248534ce080105dbfb6c901fa",
      "bcbc5ea6342a4fd6b2da578ed9258092",
      "69cddc90c5eb420d9ba3e369fa63b112",
      "9398d573b052468daeb05caa4255b30f",
      "6bee68353c6f431180a1064057b42360",
      "589e03f4c1644a73a4771fb39ad0e87e",
      "1944ae02aec34fd3878e2da29a95679b",
      "25f3517569744349b1c511808ca5becc",
      "d9102e55ed214a6a8d7f2959b31be319",
      "2cde42e7d54c46849aac2bbaeeec93c7",
      "5dcee430ce99434e9fc6b1cb315cd5d8",
      "657ff7ae6829438d90b9c976e2245630",
      "3c94bf0d5f8e43f0a35763d1a68d2e9c",
      "c1d3b184bdcb44fcbdc5b0a086c36194",
      "e79ae4f58417440c9633cbcfc3fb6b39",
      "d91225a41d3b4c899195ff79a10b3e79",
      "e6200d97c09e4ae181d95717fbf8b0ab",
      "8cc5f640bf3f45229b211df862d56bfa",
      "9af77df882c04a938c5121acc1f474cb",
      "b84801470689411181a7bddcdcf9d9b3",
      "3a8aba383ca442cfb37c889a01ec7c56",
      "86df831bdf7e46f09014d61edfdb43ae",
      "a84a781fe2bd4ae68261b3da62633766",
      "6e2d1a2fc4834dd6a3e0279082c329d6",
      "1e17a5653e0340e9afbc37b952ea55f9",
      "0877cc0218f04641a1f00787cd20f6e5",
      "4cc3afb2051c465cbca05af9dd76f098"
     ]
    },
    "id": "o5nWQORcFlNn",
    "outputId": "22e0ed41-c2fc-4d27-f9c2-429368f19415"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f371013970fa447199a0672409ca70d9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "589e03f4c1644a73a4771fb39ad0e87e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6200d97c09e4ae181d95717fbf8b0ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 't5'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Prepare our data\n",
    "prompt = \"Is the following sentence positive or negative? \"\n",
    "data = data.map(lambda example: {\"t5\": prompt + example['text']})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nas574KFFSvR",
    "outputId": "43d00d4d-6ac1-4bb3-8ade-e6d650d170e5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1066/1066 [00:55<00:00, 19.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data[\"test\"])):\n",
    "    text = output[0][\"generated_text\"]\n",
    "    y_pred.append(0 if text == \"negative\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Wk2i856GnCv",
    "outputId": "27546e63-a211-4a39-bd01-f0a9588220bb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.83      0.85      0.84       533\n",
      "Positive Review       0.85      0.83      0.84       533\n",
      "\n",
      "       accuracy                           0.84      1066\n",
      "      macro avg       0.84      0.84      0.84      1066\n",
      "   weighted avg       0.84      0.84      0.84      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4V9iq_EELWx"
   },
   "source": [
    "### ChatGPT for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tES6HFOwNjF6"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Create client\n",
    "client = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dGiovm3wyCOz"
   },
   "outputs": [],
   "source": [
    "def chatgpt_generation(prompt, document, model=\"gpt-3.5-turbo-0125\"):\n",
    "    \"\"\"Generate an output based on a prompt and an input document.\"\"\"\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":   prompt.replace(\"[DOCUMENT]\", document)\n",
    "            }\n",
    "    ]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "      messages=messages,\n",
    "      model=model,\n",
    "      temperature=0\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "qL_kMwQEvMcd",
    "outputId": "c4d38322-4195-4f81-b055-eab69e17607d"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2321951056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predict the target using GPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unpretentious , charming , quirky , original\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mchatgpt_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-1298530805.py\u001b[0m in \u001b[0;36mchatgpt_generation\u001b[0;34m(prompt, document, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m             }\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[0;32m---> 13\u001b[0;31m     chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "# Define a prompt template as a base\n",
    "prompt = \"\"\"Predict whether the following document is a positive or negative movie review:\n",
    "\n",
    "[DOCUMENT]\n",
    "\n",
    "If it is positive return 1 and if it is negative return 0. Do not give any other answers.\n",
    "\"\"\"\n",
    "\n",
    "# Predict the target using GPT\n",
    "document = \"unpretentious , charming , quirky , original\"\n",
    "chatgpt_generation(prompt, document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ea-8XYpY3jp6"
   },
   "source": [
    "The next step would be to run one of OpenAI's model against the entire evaluation dataset. However, only run this when you have sufficient tokens as this will call the API for the entire test dataset (1066 records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "gEyGElIv25Aq",
    "outputId": "f6e758d6-b807-472a-8a1f-4be01d6c1ac9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1066 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1878078064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can skip this if you want to save your (free) credits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchatgpt_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-1298530805.py\u001b[0m in \u001b[0;36mchatgpt_generation\u001b[0;34m(prompt, document, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m             }\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[0;32m---> 13\u001b[0;31m     chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "# You can skip this if you want to save your (free) credits\n",
    "predictions = [chatgpt_generation(prompt, doc) for doc in tqdm(data[\"test\"][\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B07O8wtZ05x1",
    "outputId": "48ab3146-85e7-4d92-e550-04bd98e39cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.87      0.97      0.92       533\n",
      "Positive Review       0.96      0.86      0.91       533\n",
      "\n",
      "       accuracy                           0.91      1066\n",
      "      macro avg       0.92      0.91      0.91      1066\n",
      "   weighted avg       0.92      0.91      0.91      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract predictions\n",
    "y_pred = [int(pred) for pred in predictions]\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Student Exercises\n",
    "\n",
    "The hands-on exercises for this chapter have been organized by difficulty level into separate notebooks:\n",
    "\n",
    "### \ud83d\udcc1 Exercise Notebooks\n",
    "\n",
    "1. **Easy_Tasks.ipynb** - Foundational concepts and exploration\n",
    "   - Zero-shot classification\n",
    "   - Classifier strategies\n",
    "   - Temperature effects\n",
    "   - Embedding similarity\n",
    "\n",
    "2. **Medium_Tasks.ipynb** - Application and comparison\n",
    "   - Multi-class sentiment classification\n",
    "   - Performance with limited data\n",
    "   - Confidence-based classification\n",
    "   - Failure analysis\n",
    "\n",
    "3. **Hard_Tasks.ipynb** - Advanced techniques\n",
    "   - Hierarchical classification\n",
    "   - Active learning\n",
    "   - Ensemble methods\n",
    "   - Cross-domain transfer learning\n",
    "\n",
    "**Instructions:** Open the appropriate notebook based on your comfort level. Each notebook is self-contained with all necessary setup code."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}