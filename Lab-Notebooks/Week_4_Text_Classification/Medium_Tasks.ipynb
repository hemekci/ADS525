{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 4: Text Classification - Medium Tasks\n",
        "\n",
        "This notebook focuses on building practical text classifiers. You'll create custom multi-class sentiment classifiers, evaluate performance with limited training data, implement confidence-based classification with uncertainty handling, and perform systematic failure analysis. These skills are crucial for real-world NLP applications where data and perfect accuracy are often limited.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "Run all cells in this section to set up the environment and load necessary data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGW2SD-c864"
      },
      "source": [
        "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "\n",
        "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
        "\n",
        "---\n",
        "\n",
        "\ud83d\udca1 **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N-PxmOIhc865"
      },
      "outputs": [],
      "source": [
        " %%capture\n",
        "!pip install transformers sentence-transformers openai\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBeVnXxQWy7-"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784,
          "referenced_widgets": [
            "169816892c8646e3888f213295349f00",
            "4a590f6ceb104873b97b9620d6107017",
            "2d14e5528bbd446e8a34c235201f88ac",
            "f4c9e362c7ff40559a1a5632a8b6e907",
            "3c4c633f0af84d099ffc74bac8901b07",
            "35226b53943b4db8a5d46aae09720818",
            "1a6faf9a5ed748f0809834cc52435b3d",
            "4fe179f7fab44513aeaa33cedf44f1bb",
            "5befa9362a09459695f4489c7173c34d",
            "458ad67bb385497889eab5bbdd977de5",
            "027a7c3f8a9e4114ac6d4e64fb62d440",
            "0cce924a44f94cbfaa69a78735ece1d5",
            "28ac2aeffcb6424f97fb47bfaee8e66f",
            "ab02cefe39774db3844d914b65a48790",
            "6bf6e7d710eb4924a3144e6e5d0679ca",
            "b7b774839b134ee687d9d89a0e15d166",
            "c583fda17dd44217875e86209fbad80a",
            "cd4eeedee4fc4f28acf650785bbaa5f3",
            "e5138fd5028f48f9ad8eea2b41b1592a",
            "82f4409e3f854415a871e3da31e9393e",
            "aeb337caa109443a9fc4f93e9f92753d",
            "e7e6399dec234052b7f30e3135a21b00",
            "44a764c1267042259b2c9597a69f6f76",
            "05e8f57e23ff47f0be24d3f9c18554d4",
            "616321e6e87a4d8589d9ed939e19c7b2",
            "8d7284d945004b98b28b6c631a2c4726",
            "97d864e9c07149aeb22a844ced3909d5",
            "dbadb6dfe23141ec8f38ffb747ea882e",
            "82d0c0a18606421f92ed77d8d4c61e10",
            "0c64a3bc4d4d461cbdc3c3c0acae2f94",
            "cf707e36593b4071b8253fd33d18b665",
            "079412e5345a4a09875ed0c86dde93e3",
            "1e2ffd31336946cf952abb5f62651c16",
            "8466edc3103c45d8a5d3fe8166508648",
            "f8d0d8f24551457e862d2e041f3699ab",
            "426852cccf704c58bdc7decbb1c583e6",
            "6b2663befc574a8e8154631c3ac95ff3",
            "091bd22cb6d94ae5b7c962d18e528ca2",
            "5ba5883cc2144929b9d7ddd980e4508d",
            "971d17ca015446b4bbf8a908835295cd",
            "c7086b545eae4b09af3b2d77b78af4b9",
            "5f47aeddde3449a5b5ed280d0ec9bc18",
            "43791444ad3e49f993d17887e6c15dbf",
            "c2c3403eb38b420cba7390d385f325be",
            "9097dd47971f445ea0fd55e7c42c15a0",
            "18cbf6cbaa4c436d9074224f83472863",
            "831180b810da4b549a8ca75536607e31",
            "d9779ccf530e49b1ac52172252ec5ef4",
            "78d69219fad44722a9bad3a12a3ccb61",
            "f08fa19e07644f4d9fff30d02040e315",
            "e1a2a1e765f042a7b9b081688688dab5",
            "76d299a97ab54dbe96f4525095afedcb",
            "73ac94bdcaf8427bbbcdd808f1428dff",
            "6f9a5d0dfe2f4aa49c57e942b927521b",
            "2d7810d299f649a2ac84541e7215d29a",
            "40dc8a185cf34e99a427f7c81bc76540",
            "bcac3e31740e4a2894b4e8bc9656a0c5",
            "87f29bce5b5d4df08b5337d62ffa9568",
            "3129b232f1e3411ead0d913654a11eaa",
            "4e7c3e87552640018f89c6cf9e070642",
            "01ccc633ad5d4350ad04651e360cc478",
            "735737e7c1eb477fae9d06d7324e81e8",
            "882b69fb84034d2dace625ef267f51cb",
            "8c77be8e5b74452bb028b97fd9edba36",
            "55a6296e28394f41b2a6d1f3d76e5944",
            "8f6c7a732bb6498db1de4d66f4b3c623",
            "22541d211626493e87c168143671e5ce",
            "111b9c6182994e2e85a323d07980b1ab",
            "3c53665ac233434fa899399da13650f0",
            "c4867626e6eb41bfaade350790de9f40",
            "a11866f208c4411dbc3d627ef6dbd74f",
            "3485c0ebc7f24965a0fadd3a6570d51e",
            "d111b1f753554eeda57cdbe420335fda",
            "8fb77e0530e946d38c007c9012c37a79",
            "8d669f0719d04980a6f04ffc2f65cf7c",
            "d79a649275a14fdeb2cb01e5ab75021f",
            "14186c7dd75e43d99183d5c8b308c0de"
          ]
        },
        "id": "5phRS_z2U_3T",
        "outputId": "e51c9c23-a48a-4c61-e7ee-cd0ef03915a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169816892c8646e3888f213295349f00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cce924a44f94cbfaa69a78735ece1d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44a764c1267042259b2c9597a69f6f76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8466edc3103c45d8a5d3fe8166508648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9097dd47971f445ea0fd55e7c42c15a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40dc8a185cf34e99a427f7c81bc76540"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22541d211626493e87c168143671e5ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load our data\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJJmaJzHDLZv",
        "outputId": "fd2ef721-8635-466b-d787-515fc8e4dffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
              "  'things really get weird , though not particularly scary : the movie is all portent and no content .'],\n",
              " 'label': [1, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data[\"train\"][0, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xya5dfmVoR1R"
      },
      "source": [
        "# **Text Classification with Representation Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co68g-Eloknf"
      },
      "source": [
        "## **Using a Task-specific Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "1fb504f12d6e4b40937b0ef9db1b2644",
            "7b89f8211c56444f82518264593156dd",
            "a4a66adab7f641a9bdb6496e0401881f",
            "bd8c5ad9440742bcb4779705379b98fc",
            "ba257dbbadc742bcaa34780cc1fd7db5",
            "9e2e1629f04643fb893e0a1bb99589ae",
            "925169e5d07c4d229b342fe4b41b2544",
            "0dc110695d3943a5afbaabc2ccb74bce",
            "92249295eebb4dcfbb17b2eb348bcfc6",
            "11b59aee3f1c43bc821a8b2abba4d9a6",
            "7e4bfde8cc0f41409e5703b50ca951ae",
            "a52864b4ba6f443e95be535dfa78bd81",
            "b79bbe20431c4eaa8ab39e71c682a4a5",
            "e3128b82fd3442d39afed90fc9ef77b7",
            "a72769becce048b6b2d5fd92a7b7e105",
            "e4c4c6616a5d458499fb035f8c96a72b",
            "4e741246929d40fa93a0d4bd178dad14",
            "207aa57d2b224b9fb42fdecb67864c7a",
            "4527a8a8f8e945c5b1e289fa84aa2dd9",
            "0aeaac43201c41328a4f009378893889",
            "8d378ae5d43d484abe48e3d84e9ede8e",
            "83051aac1ae6471cace09a99e3e48d78",
            "1c69a7234956470dae17b814673702c1",
            "53a98f00da5b4373bfc55dc68338e33b",
            "b8a04b7c0a0942b58c906b2742613aed",
            "b481591887bd4b4aa7796fa1f08db48d",
            "13f95d964fca4ebfb805883f914ac552",
            "f342b12a14bc4679af668aacdc56e755",
            "2eeb334e09d848fdba87cd8e9763b55e",
            "87016c44c90147a591311e9122b990ab",
            "eda4d37856194c1da4ae1b1166857222",
            "8f7d09967c32447bad6b421af147a499",
            "dbda5498ffdf48c2970f7b80e3bd3981",
            "6cdfde3fe9e947609ac08516e75402b5",
            "a22a276031104274b9ae00ae0d492f05",
            "299b4336b07743d2904424f31adf6088",
            "abb5d0a0710d464e938bc080687ec765",
            "ff8c599d1975469e89c4b0c255c28dba",
            "569e6c83aef24232a4b37207418fde55",
            "cb917089e8894de9a97199092a924527",
            "c439af89c3814f5abf12f422e5eacd60",
            "a70c2a858aab45f28a118da4d0a2816e",
            "7afc0a026ff54a658bd608bd18e03fd8",
            "763bef1d422b436ba1bcc959016c1417",
            "80f655a52a2b4f269889f0fa0db922f1",
            "4924034b3042401ca21c0c0229262267",
            "c9c3b424188b49a39ef396a501aa7b51",
            "5a0e9e8e59704764b93adb898325e0ff",
            "66ef85a159ae4abf8deb5710a49b3bf5",
            "87e8a8450bda49f9918213b9808beffe",
            "a9693c19e60344a8b5d246571fe65cde",
            "7bcfaa94e7af4c0ab5dd1353b36982f6",
            "53a7294ac44e49eaa2bf5ba46b78496e",
            "365e12fd2f3a4f9e817163e571ced1f0",
            "45d9ba9b2c36424bbf4b38d814ee95a2",
            "209836d671e548f7a126c95a6ea4f039",
            "abe9c4abaf204c5fb54d074d43a4a0e3",
            "ede9f93cc7064bfcb27331753580651c",
            "e9d028695e614841912c29586f6aa0ed",
            "cd8c7e3ed61b4c18820a1eac523c2ec8",
            "051b04994a2a44e98a0456ec7fcc4364",
            "403f3c6a21e84992b9a1715c61611919",
            "b192ab52b45a463cbd8ec4fa2be30e93",
            "d82f5d2fd051445291e7efef43b0e07a",
            "4fedc855d66a408b8ef6be24e0f126cc",
            "df6477cd708245fcaf89ed3a0243426d"
          ]
        },
        "id": "ph-3T3XJopdN",
        "outputId": "bba715ac-9776-4816-fb43-d72a1b915fb6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fb504f12d6e4b40937b0ef9db1b2644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a52864b4ba6f443e95be535dfa78bd81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c69a7234956470dae17b814673702c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cdfde3fe9e947609ac08516e75402b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80f655a52a2b4f269889f0fa0db922f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "209836d671e548f7a126c95a6ea4f039"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Path to our HF model\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "# Load model into pipeline\n",
        "pipe = pipeline(\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    return_all_scores=True,\n",
        "    device=\"cuda:0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2gbnL5Q69Y5",
        "outputId": "b51721d2-df8f-4e0d-8066-127b9ca1beac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1066/1066 [00:10<00:00, 103.45it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "# Run inference\n",
        "y_pred = []\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
        "    negative_score = output[0][\"score\"]\n",
        "    positive_score = output[2][\"score\"]\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X0KyKHtqyjn3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print the classification report\"\"\"\n",
        "    performance = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fum3MTSyymlW",
        "outputId": "d7cbdbbb-91be-48b4-da8e-1aae9936dd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.76      0.88      0.81       533\n",
            "Positive Review       0.86      0.72      0.78       533\n",
            "\n",
            "       accuracy                           0.80      1066\n",
            "      macro avg       0.81      0.80      0.80      1066\n",
            "   weighted avg       0.81      0.80      0.80      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr3WT4jzoNZE"
      },
      "source": [
        "## **Classification Tasks that Leverage Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yuSP3heMzT"
      },
      "source": [
        "### Supervised Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685,
          "referenced_widgets": [
            "4e81be8e5ffc43099d1768f2b379c2ce",
            "dcc81d53b875455885c741b3af3a5b0a",
            "be43233653e14ef99a9fe4d307c831df",
            "c7a2b1dc071c40f4bfb7bdf23d46628d",
            "5a93e11d2d4c400492a77216349bd690",
            "e5612408eb3547a881b5bbc976f1fe29",
            "9b8c5d6b959e4e03b4d29ad32986b659",
            "1ca82d860d0344cb856382534a6bfefc",
            "022fed1441914a0ca352a734940836fd",
            "42349dbbd1534a1bb309353b2d642c1b",
            "86ee3f61b6c443e7b0cc14ccacb8d93c",
            "0962ea3d1fa34efcace74c949a3f636a",
            "18ade018745d429680f5f6d6b2a12217",
            "5ff845b3c271455eb7de17b621c4f8da",
            "2f46c4961c1941f68bd6744d910c4951",
            "aab906d02f894947a7a939919112c82d",
            "0607d79940504e49a9c404192b9f0ab5",
            "57d43902023d4014bd0662e730b4185e",
            "31c0895f9513498ca76c57e3826f7816",
            "60aed70d6d1d46d0846c6f8953316176",
            "0a343810af264b8d9218f78c1425358a",
            "cf1a3a0460a54b738b3a4fbce9595efc",
            "ff44125d52054f29ba06ceae0a6821b1",
            "83cf3e9f22764776826ba9916361fa1d",
            "57eabd446bb642a0ac6ffcd48b51bf20",
            "3adb5f1d06d44efb937aa60d4dc6b590",
            "d054cd84029042478bf37a80a5afca2d",
            "cacef97c29894887b41e3ff709a6212d",
            "24c5e567304f4f708e00a0232bf74bc7",
            "bfed59c1582b4524a7fc2273de2bb03f",
            "c3e8bb57d7b3464f9faf0ac08778ef68",
            "4a6134d8cebb474192acc22bcaafcd95",
            "ec4bdfc264144ac9a3ddff215370e2c9",
            "cf7e368bd70e479bb003b8688deb27d5",
            "af4541b7787a40dfa185badaad4fc7d9",
            "bbe7a95510a24ebf99a8df491fc59d1a",
            "3261ae1c6fdb45cf96b4a4552a45626c",
            "1debcc698a0843e1a879beb195930aff",
            "a69251a68dd34672a0a336e140663e2f",
            "dec830ff5c8f49d9ba5fba56eb2e9071",
            "08e8167e9ca74af7aa71f83249cf47e1",
            "4ad52778626948618e3f025cf018dcf0",
            "6318fa44715a42bca4c84a92c19c3dea",
            "d47538747b4c4c2ba233610bf0564134",
            "4e256742aed947089df526b210c16290",
            "5f70584f9eb84ba3b460ba9ac76ee453",
            "f37ca89700644feba278d17b4c6aeaed",
            "140e5095c3d3461ead6ee0be72b00f5d",
            "25cd477eadfb483fb8d8574a22b8c6ea",
            "daa4ca445a37481587114eaa8cf4ee76",
            "fc2ad0c3efcc4fdea1a4e6e51e3252e2",
            "79fbb1c65d374f49a96940ad9433e29b",
            "02f96098408e4b7e96fe30c01edec74f",
            "afec417c406e44e8864a7d91fcab9c70",
            "06720654f3d8410da53c7d47d60e5e48",
            "3a2239bbac764e18a6d3e54bd8e24385",
            "78e8da5c28724c2592b94ad087fb447f",
            "55853935d9da448e9f65708aefbb433a",
            "3e614baa3e1d4501838b59fc0c8be5b8",
            "e0a029527cdc44f2a2bd79c2adc2c948",
            "f1dd73af95b446cbbb626badb15dedee",
            "ef459535fd044f02b738551eb3202ab7",
            "5d8475a83bc249d5915bd436657b2138",
            "472eb71cf8cd4e6cabda9324530b1a88",
            "71258f3809544398958756a56b939501",
            "eb517a787a5242d1b899029a064dc729",
            "66d1c59207bd4b579b17f91a173b64d3",
            "45b88debf5bd44fab095277825c5a61d",
            "85cf17b86a404041a4357d114ee31380",
            "028cc741e4ad48158c9f7bafef680816",
            "b23100f08efe4daa97201b09d1cb589d",
            "123308249ab74cad8f04383520f57ea2",
            "f9694cb1ee8f4dd1b48f3eee91faa0fc",
            "278c539dd782455f80eb7d28b11596b3",
            "ebceb670f6324a69b417a65dde28844c",
            "852ab216c2cd448bbcda88ba4516dfc7",
            "9ba5975196e441538f7d27cc7ad8d5c3",
            "9b9b1d35635e453e9dc7be625b5e22ab",
            "8c6be67889bb45548d17945ea1c7748b",
            "a3db156c5ae4456490622f69d9d7a419",
            "48e1e45ee4514353b66a5ede013c4126",
            "85d46881181c4a409ae830f2e8d8bc0a",
            "63f2725708e942759ee5f97d0ba543d5",
            "76e69a4aba9a44f6804ba2f5b31987c5",
            "6bbd2f542b5f4509bc701a8f3eca85d4",
            "c8f79a7929234d25af837a9accf1c7c6",
            "f4020fe822374f6d931ec3156f5f8290",
            "d49d651103c647deb11a79c9a8594720",
            "0ec62022b7f14c17aaf7ec388bf7a35f",
            "9905cf8fecd74170823db01f048d6c18",
            "5257ebdade3347bab07ed3592c388644",
            "2d6ca74dc7f547d19f4ccc7e2c344ba6",
            "52b07ec3bf20486f968697aac159e3ec",
            "57ce50bb57d843f68aa6502d87cbb39c",
            "bbebb6d8b43d4d97abf04701510aa678",
            "15e435cf2f174a36aa154847da606f89",
            "e476841f60734793bd50fe0803d2ff5a",
            "f33cf0e51acd4f0285ea91b9c697125a",
            "8bb620a2b07145b4b201c6d016e5183c",
            "8165eeff3f4b453fa6236e8fab4f6fcb",
            "e7dd7f4a1c9d46ef92faa9839d6206f5",
            "76630bfcf6c740f99f23e654a5c78e93",
            "c2fd1cb6aabb4d2ba1abdba8dde381a1",
            "2c3095624df04d638a1b5b6c76e1739c",
            "0c61efba3db24edf93e0ad5eadfbfe94",
            "e22ce558f5fc4787bd7d13d5001cd0b4",
            "3ebe369233fa44b4a0a5d42d081b4e81",
            "6a44d72ebb0c4ea8b63474895e9a678c",
            "1d6324eb9d034df2973a75d0aba93224",
            "f32e93567eb74ce8a26f2f935674f522",
            "da6359244454407c847ec5af84461ff4",
            "d1252bef4d2647b5ae41d30fb25dfcb3",
            "f81f8b2ee6e34ae89231077455703fb1",
            "791836d8a7b34eabb236e60320d319f4",
            "588504b532aa43deb77e717cd191cc7c",
            "54824268dc954706b1e460b741f103c2",
            "1492d718e5884b6cb3dbfd12a1dba7e9",
            "740baaf426be416a9fc2c0707fbaff92",
            "cbeb5b778ba34bc6b1a744ad95739f84",
            "22f0c566b1e84415a4df68ce85ba2940",
            "fae11149bf684ef0803fbcd0fa4ce6f0",
            "2dcd3d5224cf42dc9d46b00eb1f84c59",
            "fb5ef3cfc0e143caa20a81824a3f7596",
            "1ebbf46483864b0080e5ffee82bb5f8c",
            "e142cbdfa66941fba47fbb93c36d6776",
            "25c8b5c5ef38486f94ffa3af6ab4674e",
            "ba56a8a3e951454ea17717b754a60383",
            "b2761db375ed401b99d1a59fef5dcc57",
            "3b67c923023944b8a306190719df4c93",
            "01e53b31eebd4a1ca26d11040bcdedbf",
            "26809486bea84d8bad34827ba420c316",
            "0072cd435347438c842245818f9a5ec6",
            "9786eefbd37b4c92b77e878216a10ac0",
            "662ba5d6c58047cb99a58f4e6ed92f00",
            "4ebf212b49604116ba04bfb42d090199",
            "42e594681a844633a8fc13977f695539",
            "5709e500046240938a7c4fc83deb6f83",
            "8f6f96b4ea33432dafbfd1197eea0f28",
            "aa752f8c13e543f8a1d228a7f7fd7aec",
            "132d3c773337426fa8cfe56ec177f2af",
            "c7b6a57e5818487fb100d89d84f40ea4",
            "a4f3f29846074639a369b57b28ccfbd4",
            "8a4c41494ed54c6797c6dab0b8dd676d"
          ]
        },
        "id": "jGV9VS4bhq7f",
        "outputId": "f585566a-d8c7-4abc-d93b-a40933470a86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e81be8e5ffc43099d1768f2b379c2ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0962ea3d1fa34efcace74c949a3f636a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff44125d52054f29ba06ceae0a6821b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf7e368bd70e479bb003b8688deb27d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e256742aed947089df526b210c16290"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a2239bbac764e18a6d3e54bd8e24385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66d1c59207bd4b579b17f91a173b64d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b9b1d35635e453e9dc7be625b5e22ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ec62022b7f14c17aaf7ec388bf7a35f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8165eeff3f4b453fa6236e8fab4f6fcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da6359244454407c847ec5af84461ff4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/267 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dcd3d5224cf42dc9d46b00eb1f84c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9786eefbd37b4c92b77e878216a10ac0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load model\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Convert text to embeddings\n",
        "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
        "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5L5CLcOxIeA",
        "outputId": "8df2014c-4d1e-41b8-e686-30f539c22b08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8530, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "8A7oTxoph6bn",
        "outputId": "87cff4c5-f6f7-4cc2-c226-d0bed2eb5ab5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\u25b8\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\u25be\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a Logistic Regression on our train embeddings\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFvO9KhMokF7",
        "outputId": "e615b92d-b487-4ed0-f7e0-d313d55fe093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.85      0.86      0.85       533\n",
            "Positive Review       0.86      0.85      0.85       533\n",
            "\n",
            "       accuracy                           0.85      1066\n",
            "      macro avg       0.85      0.85      0.85      1066\n",
            "   weighted avg       0.85      0.85      0.85      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict previously unseen instances\n",
        "y_pred = clf.predict(test_embeddings)\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwGIHxXpJgrC"
      },
      "source": [
        "**Tip!**  \n",
        "\n",
        "What would happen if we would not use a classifier at all? Instead, we can average the embeddings per class and apply cosine similarity to predict which classes match the documents best:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f_DnG1uJ7Sk",
        "outputId": "fc8fb382-b6e9-481a-9c70-8ac1a1a5c96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.85      0.84      0.84       533\n",
            "Positive Review       0.84      0.85      0.84       533\n",
            "\n",
            "       accuracy                           0.84      1066\n",
            "      macro avg       0.84      0.84      0.84      1066\n",
            "   weighted avg       0.84      0.84      0.84      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Average the embeddings of all documents in each target label\n",
        "df = pd.DataFrame(np.hstack([train_embeddings, np.array(data[\"train\"][\"label\"]).reshape(-1, 1)]))\n",
        "averaged_target_embeddings = df.groupby(768).mean().values\n",
        "\n",
        "# Find the best matching embeddings between evaluation documents and target embeddings\n",
        "sim_matrix = cosine_similarity(test_embeddings, averaged_target_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCWdzjMIjzx0"
      },
      "source": [
        "### Zero-shot Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YSj6CdAetsNp"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for our labels\n",
        "label_embeddings = model.encode([\"A negative review\",  \"A positive review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZEIN7XnbtsQJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find the best matching label for each document\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6LyeuEUxIbW",
        "outputId": "97ecffce-64bc-406e-c4a1-e339d5d38661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.78      0.77      0.78       533\n",
            "Positive Review       0.77      0.79      0.78       533\n",
            "\n",
            "       accuracy                           0.78      1066\n",
            "      macro avg       0.78      0.78      0.78      1066\n",
            "   weighted avg       0.78      0.78      0.78      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox27Rg71zclg"
      },
      "source": [
        "**Tip!**  \n",
        "\n",
        "What would happen if you were to use different descriptions? Use **\"A very negative movie review\"** and **\"A very positive movie review\"** to see what happens!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CC9iEGcuUit"
      },
      "source": [
        "## **Classification with Generative Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFPPzUHoEESB"
      },
      "source": [
        "### Encoder-decoder Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nVbTUMktEfJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "e3c53af41c05458b91c8cb4cb69fba8a",
            "32f800b9e8804e979cbd8aadd4571254",
            "ae1b8719376041f0a458c2d7b0f99408",
            "a11cebfe657841c5b8024e6d52b0063a",
            "5565c64a2fe24d7ca9cf3d661cce5bb4",
            "fc6d796c33d945e69401032520bef25d",
            "1910b69faa9447ffbfb5e198ef2d01d0",
            "b78c4127c28947d0a15059dbc3948862",
            "c5044f7398254708bea7f0125768c60d",
            "a08f96a06fd1441481350d4f48f09dc6",
            "2f4dec3cf6db49eb97cb2a346f1f7782",
            "1f82b98231d744f6ad34b4fed6384f7d",
            "313e7d753b70480c94f60f75213dfeda",
            "5e816195da1a4fcdb9c72aa605fd3956",
            "f310ebc9821f49ae8096313253bd423a",
            "d4e2e5fb626941d5becad8f1262cd047",
            "ace3ace81d844f8dbb57c249e4471551",
            "4a62f65d928e49ef997855445372a6ea",
            "97a4a4526cc84972bae0bd0ef45803b7",
            "202e73910ddd437a818ff575ebfffc5e",
            "3be66085a1a541fc94f026ce4d5f1dc1",
            "7b4175623f7f450fb9c13142fa5df589",
            "98cfd3afaec74253bfb56598bc537d60",
            "f1aef66b2467475bb60851c07f9fd03d",
            "cca8f5e8f43d4a9ca8b2a301350499e4",
            "f282524923ba40c283e35eaa8d8973a6",
            "b7f204ddbb0a4ef493b448640140827f",
            "b5461053b1374b60aff966cb0c26ebf6",
            "0395d66d89cb47ed85b69b2bce090e40",
            "70130491fbc9424cb5eb9b728d03ccf3",
            "fb805f536d3347e2961f7543ad3b03e0",
            "dd0547a8c7f84d36b2be515b136ca497",
            "7b00da40af594ae19147c74b3e37b8b4",
            "446e7f92920940908ba16181855828aa",
            "f968e67ffcea4ef3943ccd6fefc11b1a",
            "cec59a1dba4444548e19015cbe4255f3",
            "306647e5f13b4c15a2d7710549f7fc3f",
            "dab122cefd714332b80bfea6bb7d1d2c",
            "3756a087647b4c45913ea4b3fbd71cda",
            "4b360fd029ae416e9417898f6c43dcf1",
            "ebd2071e9c054e9dafc323f9ffa69f56",
            "721e7b44907b4b5e8c7d015b8906db79",
            "ed0483749d114f15bf37b844739a9234",
            "ede8e21ca6814d36b4bd5bdb847f70dc",
            "e9c027409c9e49368d0cc36b5d62c52c",
            "4bff2a2a0bf0472abe011c2b1ded9d4b",
            "5c88c245bc244c12aae4898400f7a053",
            "4b633b7133b34d1ba5ba62c8916003ed",
            "358e7cef13554483a708050d45396f72",
            "f668805e6b094b3f9a205e697dd4f6c4",
            "4fc88a1f6e6543e19d0aea370bab49f6",
            "4a3a23c9ff1742be896976e832bd83ac",
            "d02b9e66f5304c089c7beaa1af709816",
            "1fd40b5711174c999dedc1624ee9cf68",
            "30119dd2b3e74e3e9eaf7e82a25613bb",
            "2348e8f1a3634ab0a21512ecd3d00a71",
            "e659fc84b605407c8698f6046295b6d2",
            "99445d5215b14415b1213a8553ef67f8",
            "5fafa1e845a040e085902c32e0a6d8f1",
            "4aee19ea1fb248fca3c22f75f775f128",
            "72eb81a28e98419697a3a4250a0f33ee",
            "70759d5046d148c7a7414ee7ac4182aa",
            "18a56bfe25994f78b2e9a713138ece21",
            "11d379e1c59d45949df0a98e3c38088e",
            "9c22d0584a1d4156a92807c930b22447",
            "b9e3266f8ef241e18ee2ab60acc1368f",
            "7066c85998e54a0585eb7319941aee51",
            "2a097c1ea6f04e0297ab1f405495d2e6",
            "174a0595415448f7ad17ba019fc31170",
            "d7bf9447859049859be60fe1323d66c2",
            "6c9700179b1c4c638be98c7d62716ae8",
            "e335b820cc0a4c27a1d5343b3e91e06a",
            "1c4968d9f46e442eb6889b2f9338adc2",
            "872814d874304911b8263611db91ef5b",
            "660a831c47a94a41866f689cc876e049",
            "bf466d43270441aca764f96766a16573",
            "eaea684194e048b395dd2cb94dd84bf0"
          ]
        },
        "outputId": "0211e7cc-0836-4b0d-d526-05d3ee92b661"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3c53af41c05458b91c8cb4cb69fba8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f82b98231d744f6ad34b4fed6384f7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98cfd3afaec74253bfb56598bc537d60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446e7f92920940908ba16181855828aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c027409c9e49368d0cc36b5d62c52c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2348e8f1a3634ab0a21512ecd3d00a71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7066c85998e54a0585eb7319941aee51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Load our model\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-small\",\n",
        "    device=\"cuda:0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "f371013970fa447199a0672409ca70d9",
            "f2ce79614eb240c9b2eb96a71ac3f532",
            "e96ac2968930406c895c0203b8b92dd2",
            "db31757768e447b5b87635793fd94496",
            "d074df2d615344e8a8e4569fc8fe5ff7",
            "1d0ad5f0de564c289aa20c650e6adfcc",
            "0526f08248534ce080105dbfb6c901fa",
            "bcbc5ea6342a4fd6b2da578ed9258092",
            "69cddc90c5eb420d9ba3e369fa63b112",
            "9398d573b052468daeb05caa4255b30f",
            "6bee68353c6f431180a1064057b42360",
            "589e03f4c1644a73a4771fb39ad0e87e",
            "1944ae02aec34fd3878e2da29a95679b",
            "25f3517569744349b1c511808ca5becc",
            "d9102e55ed214a6a8d7f2959b31be319",
            "2cde42e7d54c46849aac2bbaeeec93c7",
            "5dcee430ce99434e9fc6b1cb315cd5d8",
            "657ff7ae6829438d90b9c976e2245630",
            "3c94bf0d5f8e43f0a35763d1a68d2e9c",
            "c1d3b184bdcb44fcbdc5b0a086c36194",
            "e79ae4f58417440c9633cbcfc3fb6b39",
            "d91225a41d3b4c899195ff79a10b3e79",
            "e6200d97c09e4ae181d95717fbf8b0ab",
            "8cc5f640bf3f45229b211df862d56bfa",
            "9af77df882c04a938c5121acc1f474cb",
            "b84801470689411181a7bddcdcf9d9b3",
            "3a8aba383ca442cfb37c889a01ec7c56",
            "86df831bdf7e46f09014d61edfdb43ae",
            "a84a781fe2bd4ae68261b3da62633766",
            "6e2d1a2fc4834dd6a3e0279082c329d6",
            "1e17a5653e0340e9afbc37b952ea55f9",
            "0877cc0218f04641a1f00787cd20f6e5",
            "4cc3afb2051c465cbca05af9dd76f098"
          ]
        },
        "id": "o5nWQORcFlNn",
        "outputId": "22e0ed41-c2fc-4d27-f9c2-429368f19415"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f371013970fa447199a0672409ca70d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "589e03f4c1644a73a4771fb39ad0e87e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6200d97c09e4ae181d95717fbf8b0ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Prepare our data\n",
        "prompt = \"Is the following sentence positive or negative? \"\n",
        "data = data.map(lambda example: {\"t5\": prompt + example['text']})\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nas574KFFSvR",
        "outputId": "43d00d4d-6ac1-4bb3-8ade-e6d650d170e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1066/1066 [00:55<00:00, 19.05it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run inference\n",
        "y_pred = []\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data[\"test\"])):\n",
        "    text = output[0][\"generated_text\"]\n",
        "    y_pred.append(0 if text == \"negative\" else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wk2i856GnCv",
        "outputId": "27546e63-a211-4a39-bd01-f0a9588220bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.83      0.85      0.84       533\n",
            "Positive Review       0.85      0.83      0.84       533\n",
            "\n",
            "       accuracy                           0.84      1066\n",
            "      macro avg       0.84      0.84      0.84      1066\n",
            "   weighted avg       0.84      0.84      0.84      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4V9iq_EELWx"
      },
      "source": [
        "### ChatGPT for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tES6HFOwNjF6"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Create client\n",
        "client = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dGiovm3wyCOz"
      },
      "outputs": [],
      "source": [
        "def chatgpt_generation(prompt, document, model=\"gpt-3.5-turbo-0125\"):\n",
        "    \"\"\"Generate an output based on a prompt and an input document.\"\"\"\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "            },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\":   prompt.replace(\"[DOCUMENT]\", document)\n",
        "            }\n",
        "    ]\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      messages=messages,\n",
        "      model=model,\n",
        "      temperature=0\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "qL_kMwQEvMcd",
        "outputId": "c4d38322-4195-4f81-b055-eab69e17607d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2321951056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predict the target using GPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unpretentious , charming , quirky , original\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mchatgpt_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1298530805.py\u001b[0m in \u001b[0;36mchatgpt_generation\u001b[0;34m(prompt, document, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m             }\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[0;32m---> 13\u001b[0;31m     chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "# Define a prompt template as a base\n",
        "prompt = \"\"\"Predict whether the following document is a positive or negative movie review:\n",
        "\n",
        "[DOCUMENT]\n",
        "\n",
        "If it is positive return 1 and if it is negative return 0. Do not give any other answers.\n",
        "\"\"\"\n",
        "\n",
        "# Predict the target using GPT\n",
        "document = \"unpretentious , charming , quirky , original\"\n",
        "chatgpt_generation(prompt, document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea-8XYpY3jp6"
      },
      "source": [
        "The next step would be to run one of OpenAI's model against the entire evaluation dataset. However, only run this when you have sufficient tokens as this will call the API for the entire test dataset (1066 records)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "gEyGElIv25Aq",
        "outputId": "f6e758d6-b807-472a-8a1f-4be01d6c1ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1066 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1878078064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can skip this if you want to save your (free) credits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchatgpt_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1298530805.py\u001b[0m in \u001b[0;36mchatgpt_generation\u001b[0;34m(prompt, document, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m             }\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[0;32m---> 13\u001b[0;31m     chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_KEY*HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "# You can skip this if you want to save your (free) credits\n",
        "predictions = [chatgpt_generation(prompt, doc) for doc in tqdm(data[\"test\"][\"text\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B07O8wtZ05x1",
        "outputId": "48ab3146-85e7-4d92-e550-04bd98e39cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.87      0.97      0.92       533\n",
            "Positive Review       0.96      0.86      0.91       533\n",
            "\n",
            "       accuracy                           0.91      1066\n",
            "      macro avg       0.92      0.91      0.91      1066\n",
            "   weighted avg       0.92      0.91      0.91      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract predictions\n",
        "y_pred = [int(pred) for pred in predictions]\n",
        "\n",
        "# Evaluate performance\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Turn - Text Classification Experiments\n",
        "\n",
        "Run each task first to see the baseline results. Follow the instructions to modify and experiment."
      ],
      "metadata": {
        "id": "NKYNfoaVC4hU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is divided into EASY, MEDIUM, & HARD."
      ],
      "metadata": {
        "id": "hHVONn85DElL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Medium Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medium Tasks - Building Real Classifiers\n",
        "\n",
        "These tasks require more modification and experimentation. You'll build complete classification systems."
      ],
      "metadata": {
        "id": "2ipz0pJYEne6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**About This Task:**\n\n",
        "Custom sentiment categories allow you to tailor classification to specific domains beyond generic positive/negative labels. This is critical for domain-specific applications like product reviews, medical feedback, or financial sentiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Medium Task 1: Multi-Class Sentiment Classifier with Custom Categories\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Execute code to see how the 5-level sentiment classifier works\n",
        "2. Analyze confusion matrix to identify which categories get confused\n",
        "3. Uncomment TODO to add a 6th sentiment level\n",
        "4. Write 3 reviews specifically for your new category\n",
        "5. Compare performance before and after adding the category"
      ],
      "metadata": {
        "id": "ddr-_SRIEtH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Test reviews covering different sentiment intensities\n",
        "test_reviews = [\n",
        "    \"This is the best movie I've ever seen! Absolute masterpiece!\",\n",
        "    \"Pretty good movie, I enjoyed it\",\n",
        "    \"It was okay, nothing special\",\n",
        "    \"Not great, pretty disappointing\",\n",
        "    \"Absolutely terrible, worst movie ever\",\n",
        "    \"Amazing performances and stunning visuals!\",\n",
        "    \"Mediocre at best\",\n",
        "    \"Quite bad, wouldn't recommend\",\n",
        "]\n",
        "\n",
        "# TODO: After first run, add 3 reviews that should fit your new category:\n",
        "# test_reviews.extend([\n",
        "#     \"Your review 1 here\",\n",
        "#     \"Your review 2 here\",\n",
        "#     \"Your review 3 here\",\n",
        "# ])\n",
        "\n",
        "# 5-level sentiment classification\n",
        "sentiment_labels = [\n",
        "    \"extremely negative sentiment\",\n",
        "    \"somewhat negative sentiment\",\n",
        "    \"neutral sentiment\",\n",
        "    \"somewhat positive sentiment\",\n",
        "    \"extremely positive sentiment\"\n",
        "]\n",
        "\n",
        "# TODO: After analyzing results, uncomment to add 6th category between somewhat and extremely positive:\n",
        "# sentiment_labels = [\n",
        "#     \"extremely negative sentiment\",\n",
        "#     \"somewhat negative sentiment\",\n",
        "#     \"neutral sentiment\",\n",
        "#     \"somewhat positive sentiment\",\n",
        "#     \"very positive sentiment\",  # NEW CATEGORY\n",
        "#     \"extremely positive sentiment\"\n",
        "# ]\n",
        "\n",
        "# Create embeddings\n",
        "label_embeddings = model.encode(sentiment_labels)\n",
        "review_embeddings = model.encode(test_reviews)\n",
        "sim_matrix = cosine_similarity(review_embeddings, label_embeddings)\n",
        "\n",
        "# Classify\n",
        "predictions = np.argmax(sim_matrix, axis=1)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"MULTI-CLASS CLASSIFICATION ({len(sentiment_labels)} categories)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, review in enumerate(test_reviews):\n",
        "    predicted_idx = predictions[i]\n",
        "    predicted_label = sentiment_labels[predicted_idx]\n",
        "    confidence = sim_matrix[i][predicted_idx]\n",
        "\n",
        "    # Get top 2 predictions to see confusion\n",
        "    top2_indices = np.argsort(sim_matrix[i])[-2:][::-1]\n",
        "    second_best_idx = top2_indices[1]\n",
        "    second_best_label = sentiment_labels[second_best_idx]\n",
        "    second_best_score = sim_matrix[i][second_best_idx]\n",
        "    margin = confidence - second_best_score\n",
        "\n",
        "    print(f\"\\nReview {i+1}: '{review[:60]}...'\")\n",
        "    print(f\"  1st: {predicted_label:30s} ({confidence:.3f})\")\n",
        "    print(f\"  2nd: {second_best_label:30s} ({second_best_score:.3f})\")\n",
        "    print(f\"  Margin: {margin:.3f}\", end=\"\")\n",
        "\n",
        "    if margin < 0.05:\n",
        "        print(\" \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\")\n",
        "    elif margin < 0.15:\n",
        "        print(\" \u26a0\ufe0f  Uncertain\")\n",
        "    else:\n",
        "        print(\" \u2713 Confident\")\n",
        "\n",
        "# Analyze category confusion\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CATEGORY CONFUSION ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(\"How similar are the category descriptions to each other?\")\n",
        "print(\"(High similarity = easy to confuse)\\n\")\n",
        "\n",
        "label_similarity = cosine_similarity(label_embeddings)\n",
        "\n",
        "print(f\"{'Category Pair':<60s} {'Similarity':<12s}\")\n",
        "print(\"-\"*75)\n",
        "\n",
        "confusions = []\n",
        "for i in range(len(sentiment_labels)):\n",
        "    for j in range(i+1, len(sentiment_labels)):\n",
        "        sim = label_similarity[i][j]\n",
        "        confusions.append((i, j, sim))\n",
        "\n",
        "# Sort by similarity (most confusing first)\n",
        "for i, j, sim in sorted(confusions, key=lambda x: x[2], reverse=True)[:10]:\n",
        "    pair_name = f\"{sentiment_labels[i]} <-> {sentiment_labels[j]}\"\n",
        "    marker = \"\u26a0\ufe0f \" if sim > 0.7 else \"\"\n",
        "    print(f\"{marker}{pair_name:<60s} {sim:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Zs_XkNEfiF",
        "outputId": "753f121d-3519-4b3f-e067-a89c0568986f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CLASS CLASSIFICATION (5 categories)\n",
            "================================================================================\n",
            "\n",
            "Review 1: 'This is the best movie I've ever seen! Absolute masterpiece!...'\n",
            "  1st: extremely positive sentiment   (0.221)\n",
            "  2nd: extremely negative sentiment   (0.119)\n",
            "  Margin: 0.102 \u26a0\ufe0f  Uncertain\n",
            "\n",
            "Review 2: 'Pretty good movie, I enjoyed it...'\n",
            "  1st: somewhat positive sentiment    (0.320)\n",
            "  2nd: extremely positive sentiment   (0.313)\n",
            "  Margin: 0.007 \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\n",
            "\n",
            "Review 3: 'It was okay, nothing special...'\n",
            "  1st: somewhat negative sentiment    (0.411)\n",
            "  2nd: somewhat positive sentiment    (0.395)\n",
            "  Margin: 0.016 \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\n",
            "\n",
            "Review 4: 'Not great, pretty disappointing...'\n",
            "  1st: somewhat negative sentiment    (0.451)\n",
            "  2nd: extremely negative sentiment   (0.443)\n",
            "  Margin: 0.008 \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\n",
            "\n",
            "Review 5: 'Absolutely terrible, worst movie ever...'\n",
            "  1st: extremely negative sentiment   (0.442)\n",
            "  2nd: somewhat negative sentiment    (0.354)\n",
            "  Margin: 0.087 \u26a0\ufe0f  Uncertain\n",
            "\n",
            "Review 6: 'Amazing performances and stunning visuals!...'\n",
            "  1st: extremely positive sentiment   (0.272)\n",
            "  2nd: extremely negative sentiment   (0.124)\n",
            "  Margin: 0.148 \u26a0\ufe0f  Uncertain\n",
            "\n",
            "Review 7: 'Mediocre at best...'\n",
            "  1st: somewhat negative sentiment    (0.428)\n",
            "  2nd: extremely negative sentiment   (0.418)\n",
            "  Margin: 0.010 \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\n",
            "\n",
            "Review 8: 'Quite bad, wouldn't recommend...'\n",
            "  1st: somewhat negative sentiment    (0.402)\n",
            "  2nd: extremely negative sentiment   (0.399)\n",
            "  Margin: 0.003 \u26a0\ufe0f  VERY UNCERTAIN - almost tied!\n",
            "\n",
            "================================================================================\n",
            "CATEGORY CONFUSION ANALYSIS\n",
            "================================================================================\n",
            "How similar are the category descriptions to each other?\n",
            "(High similarity = easy to confuse)\n",
            "\n",
            "Category Pair                                                Similarity  \n",
            "---------------------------------------------------------------------------\n",
            "\u26a0\ufe0f somewhat negative sentiment <-> somewhat positive sentiment  0.950\n",
            "\u26a0\ufe0f somewhat negative sentiment <-> neutral sentiment            0.866\n",
            "\u26a0\ufe0f neutral sentiment <-> somewhat positive sentiment            0.862\n",
            "\u26a0\ufe0f extremely negative sentiment <-> somewhat negative sentiment 0.847\n",
            "\u26a0\ufe0f somewhat positive sentiment <-> extremely positive sentiment 0.808\n",
            "\u26a0\ufe0f extremely negative sentiment <-> extremely positive sentiment 0.788\n",
            "\u26a0\ufe0f extremely negative sentiment <-> neutral sentiment           0.786\n",
            "\u26a0\ufe0f somewhat negative sentiment <-> extremely positive sentiment 0.768\n",
            "\u26a0\ufe0f extremely negative sentiment <-> somewhat positive sentiment 0.759\n",
            "\u26a0\ufe0f neutral sentiment <-> extremely positive sentiment           0.710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. Which reviews have low margins (<0.10)? What linguistic features do they share? How does multi-class classification differ from binary?\n",
        "\n",
        "2. Which adjacent categories have highest similarity in the confusion analysis? How could you rewrite label descriptions to create clearer boundaries?\n",
        "\n",
        "3. After adding your 6th category: Did reviews switch to it? Did the new category create more uncertainty or resolve confusion?"
      ],
      "metadata": {
        "id": "8viLeEAdE4CB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**About This Task:**\n\n",
        "Real-world scenarios often have limited labeled data. Understanding how classifiers perform with small datasets and techniques to maximize their effectiveness (data augmentation, transfer learning) is essential for practical applications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Medium Task 2: Classifier Performance with Limited Training Data\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Execute code to see task-specific model vs embedding classifier with 1000 training samples\n",
        "2. Modify `train_size` to 100, then 2000, then 5000 - run after each change\n",
        "3. Fill in the results table in the TODO section\n",
        "4. Analyze at what point the embedding classifier matches the task-specific model"
      ],
      "metadata": {
        "id": "Lzba7C3rE_Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "\n",
        "# TODO: EXPERIMENT WITH THIS VALUE - Try: 100, 500, 1000, 2000, 5000\n",
        "train_size = 1000\n",
        "test_size = 300\n",
        "\n",
        "train_subset = data[\"train\"].shuffle(seed=42).select(range(min(train_size, len(data[\"train\"]))))\n",
        "test_subset = data[\"test\"].shuffle(seed=42).select(range(test_size))\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"EXPERIMENT: Training Size = {train_size}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Approach 1: Task-Specific Model (pre-trained for sentiment)\n",
        "print(\"\\n[1/2] Testing Task-Specific Model...\")\n",
        "print(\"Note: This model doesn't use our training data - it's already trained!\")\n",
        "\n",
        "task_model = pipeline(\n",
        "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    return_all_scores=True,\n",
        "    device=-1\n",
        ")\n",
        "\n",
        "y_pred_task = []\n",
        "for text in test_subset[\"text\"]:\n",
        "    output = task_model(text)[0]\n",
        "    neg_score = output[0][\"score\"]\n",
        "    pos_score = output[2][\"score\"]\n",
        "    y_pred_task.append(1 if pos_score > neg_score else 0)\n",
        "\n",
        "task_f1 = f1_score(test_subset[\"label\"], y_pred_task, average='weighted')\n",
        "\n",
        "print(f\"\u2713 Task-Specific Model F1: {task_f1:.4f}\")\n",
        "\n",
        "# Approach 2: Embedding + Classifier (uses our training data)\n",
        "print(f\"\\n[2/2] Training Embedding Classifier on {train_size} samples...\")\n",
        "\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "train_embeddings = embedding_model.encode(train_subset[\"text\"], show_progress_bar=False)\n",
        "test_embeddings = embedding_model.encode(test_subset[\"text\"], show_progress_bar=False)\n",
        "\n",
        "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf.fit(train_embeddings, train_subset[\"label\"])\n",
        "\n",
        "y_pred_embed = clf.predict(test_embeddings)\n",
        "embed_f1 = f1_score(test_subset[\"label\"], y_pred_embed, average='weighted')\n",
        "\n",
        "print(f\"\u2713 Embedding Classifier F1: {embed_f1:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training samples used: {train_size}\")\n",
        "print(f\"\\nTask-Specific (pre-trained):  F1 = {task_f1:.4f}\")\n",
        "print(f\"Embedding + Classifier:       F1 = {embed_f1:.4f}\")\n",
        "print(f\"Difference:                       {embed_f1 - task_f1:+.4f}\")\n",
        "\n",
        "if embed_f1 > task_f1:\n",
        "    print(f\"\\n\u2192 Embedding approach WINS with {train_size} samples!\")\n",
        "elif embed_f1 > task_f1 - 0.01:\n",
        "    print(f\"\\n\u2192 Essentially TIED - both perform similarly\")\n",
        "else:\n",
        "    print(f\"\\n\u2192 Task-specific model wins - embedding needs more data\")\n",
        "\n",
        "# Show some predictions\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXAMPLE PREDICTIONS (first 5 test samples)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i in range(5):\n",
        "    true_label = \"Positive\" if test_subset[\"label\"][i] == 1 else \"Negative\"\n",
        "    task_pred = \"Positive\" if y_pred_task[i] == 1 else \"Negative\"\n",
        "    embed_pred = \"Positive\" if y_pred_embed[i] == 1 else \"Negative\"\n",
        "\n",
        "    task_correct = \"\u2713\" if y_pred_task[i] == test_subset[\"label\"][i] else \"\u2717\"\n",
        "    embed_correct = \"\u2713\" if y_pred_embed[i] == test_subset[\"label\"][i] else \"\u2717\"\n",
        "\n",
        "    print(f\"\\n{i+1}. '{test_subset['text'][i][:60]}...'\")\n",
        "    print(f\"   True: {true_label}\")\n",
        "    print(f\"   Task-Specific: {task_pred} {task_correct}\")\n",
        "    print(f\"   Embedding:     {embed_pred} {embed_correct}\")\n",
        "\n",
        "# TODO: RECORD YOUR RESULTS HERE\n",
        "# After running with different train_size values, fill in this table:\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"YOUR EXPERIMENT RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Run the code multiple times with different train_size values and record:\")\n",
        "print()\n",
        "print(\"| Train Size | Task F1 | Embedding F1 | Winner      |\")\n",
        "print(\"|------------|---------|--------------|-------------|\")\n",
        "print(\"| 100        | ?.????  | ?.????       | ?           |\")\n",
        "print(\"| 500        | ?.????  | ?.????       | ?           |\")\n",
        "print(\"| 1000       | ?.????  | ?.????       | ?           |\")\n",
        "print(\"| 2000       | ?.????  | ?.????       | ?           |\")\n",
        "print(\"| 5000       | ?.????  | ?.????       | ?           |\")\n",
        "print()\n",
        "print(f\"Current run: | {train_size:<10} | {task_f1:.4f}  | {embed_f1:.4f}       | {'Embed' if embed_f1 > task_f1 else 'Task':<11} |\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHHauraaEyLb",
        "outputId": "44dd4a93-3ca0-48df-be6a-7541453e0d89"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXPERIMENT: Training Size = 1000\n",
            "================================================================================\n",
            "\n",
            "[1/2] Testing Task-Specific Model...\n",
            "Note: This model doesn't use our training data - it's already trained!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2713 Task-Specific Model F1: 0.7709\n",
            "\n",
            "[2/2] Training Embedding Classifier on 1000 samples...\n",
            "\u2713 Embedding Classifier F1: 0.8699\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "Training samples used: 1000\n",
            "\n",
            "Task-Specific (pre-trained):  F1 = 0.7709\n",
            "Embedding + Classifier:       F1 = 0.8699\n",
            "Difference:                       +0.0990\n",
            "\n",
            "\u2192 Embedding approach WINS with 1000 samples!\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE PREDICTIONS (first 5 test samples)\n",
            "================================================================================\n",
            "\n",
            "1. 'unpretentious , charming , quirky , original...'\n",
            "   True: Positive\n",
            "   Task-Specific: Positive \u2713\n",
            "   Embedding:     Positive \u2713\n",
            "\n",
            "2. 'a film really has to be exceptional to justify a three hour ...'\n",
            "   True: Negative\n",
            "   Task-Specific: Negative \u2713\n",
            "   Embedding:     Negative \u2713\n",
            "\n",
            "3. 'working from a surprisingly sensitive script co-written by g...'\n",
            "   True: Positive\n",
            "   Task-Specific: Positive \u2713\n",
            "   Embedding:     Positive \u2713\n",
            "\n",
            "4. 'it may not be particularly innovative , but the film's crisp...'\n",
            "   True: Positive\n",
            "   Task-Specific: Positive \u2713\n",
            "   Embedding:     Positive \u2713\n",
            "\n",
            "5. 'such a premise is ripe for all manner of lunacy , but kaufma...'\n",
            "   True: Negative\n",
            "   Task-Specific: Negative \u2713\n",
            "   Embedding:     Negative \u2713\n",
            "\n",
            "================================================================================\n",
            "YOUR EXPERIMENT RESULTS\n",
            "================================================================================\n",
            "Run the code multiple times with different train_size values and record:\n",
            "\n",
            "| Train Size | Task F1 | Embedding F1 | Winner      |\n",
            "|------------|---------|--------------|-------------|\n",
            "| 100        | ?.????  | ?.????       | ?           |\n",
            "| 500        | ?.????  | ?.????       | ?           |\n",
            "| 1000       | ?.????  | ?.????       | ?           |\n",
            "| 2000       | ?.????  | ?.????       | ?           |\n",
            "| 5000       | ?.????  | ?.????       | ?           |\n",
            "\n",
            "Current run: | 1000       | 0.7709  | 0.8699       | Embed       |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. At what training size did the embedding classifier match or beat the task-specific model? What does this reveal about data requirements?\n",
        "\n",
        "2. Were there cases where one model was correct and the other wrong? What characteristics did those reviews have?\n",
        "\n",
        "3. With train_size=100, is this enough labeled data? How does this compare to training models from scratch?"
      ],
      "metadata": {
        "id": "ZCgyzR_SFXCC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**About This Task:**\n\n",
        "Production classifiers must handle uncertainty gracefully. Confidence thresholds and uncertainty quantification prevent incorrect predictions and allow human-in-the-loop workflows for ambiguous cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Medium Task 3: Confidence-Based Classifier with Uncertainty Handling\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Execute code to see classifier handling uncertain predictions with threshold=0.15\n",
        "2. Analyze which reviews were marked as \"uncertain\" and why\n",
        "3. Change `confidence_threshold` to 0.05, then 0.30 to observe trade-offs\n",
        "4. Uncomment TODO to implement an alternative uncertainty measure\n",
        "5. Compare which uncertainty measure works better"
      ],
      "metadata": {
        "id": "poMISz4VFvWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Reviews with varying levels of clarity\n",
        "test_reviews = [\n",
        "    \"Absolutely fantastic! Best movie ever!\",           # Clear positive\n",
        "    \"Pretty good, I liked it\",                          # Weak positive\n",
        "    \"It was fine, nothing special\",                     # Ambiguous\n",
        "    \"Not bad but not great either\",                     # Very ambiguous\n",
        "    \"Quite disappointing\",                              # Weak negative\n",
        "    \"Terrible! Complete waste of time!\",                # Clear negative\n",
        "    \"The movie had some interesting moments\",           # Ambiguous positive\n",
        "    \"Outstanding performances all around!\",             # Clear positive\n",
        "]\n",
        "\n",
        "# True labels (for evaluation)\n",
        "y_true = [1, 1, 0, 0, 0, 0, 1, 1]  # 1=positive, 0=negative\n",
        "\n",
        "labels = [\"A negative movie review\", \"A positive movie review\"]\n",
        "\n",
        "# TODO: EXPERIMENT WITH THIS - Try: 0.05, 0.15, 0.30, 0.50\n",
        "confidence_threshold = 0.15\n",
        "\n",
        "label_embeddings = model.encode(labels)\n",
        "review_embeddings = model.encode(test_reviews)\n",
        "sim_matrix = cosine_similarity(review_embeddings, label_embeddings)\n",
        "\n",
        "def calculate_margin(similarities):\n",
        "    \"\"\"\n",
        "    Margin = difference between top two predictions\n",
        "    Small margin = uncertain (predictions are close)\n",
        "    \"\"\"\n",
        "    sorted_sims = np.sort(similarities)[::-1]\n",
        "    margin = sorted_sims[0] - sorted_sims[1]\n",
        "    return margin\n",
        "\n",
        "# TODO: After first run, uncomment this alternative uncertainty measure:\n",
        "# def calculate_margin(similarities):\n",
        "#     \"\"\"\n",
        "#     Alternative: Use absolute confidence in top prediction\n",
        "#     Low confidence = uncertain\n",
        "#     \"\"\"\n",
        "#     max_confidence = np.max(similarities)\n",
        "#     # Convert to margin-like score (higher = more certain)\n",
        "#     # If max is 0.6, margin = 0.6 - 0.5 = 0.1 (uncertain)\n",
        "#     # If max is 0.9, margin = 0.9 - 0.5 = 0.4 (certain)\n",
        "#     margin = max_confidence - 0.5\n",
        "#     return margin\n",
        "\n",
        "# Classify with confidence threshold\n",
        "results = []\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"CONFIDENCE-BASED CLASSIFICATION (threshold={confidence_threshold})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, review in enumerate(test_reviews):\n",
        "    similarities = sim_matrix[i]\n",
        "    predicted_idx = np.argmax(similarities)\n",
        "    top_confidence = similarities[predicted_idx]\n",
        "    margin = calculate_margin(similarities)\n",
        "\n",
        "    # Decision: predict only if confident enough\n",
        "    if margin >= confidence_threshold:\n",
        "        prediction = predicted_idx\n",
        "        status = \"PREDICTED\"\n",
        "        predictions.append(prediction)\n",
        "    else:\n",
        "        prediction = None\n",
        "        status = \"UNCERTAIN\"\n",
        "        predictions.append(None)\n",
        "\n",
        "    true_label = \"Positive\" if y_true[i] == 1 else \"Negative\"\n",
        "    pred_label = labels[predicted_idx] if prediction is not None else \"UNCERTAIN\"\n",
        "\n",
        "    print(f\"\\n{i+1}. '{review}'\")\n",
        "    print(f\"   True label: {true_label}\")\n",
        "    print(f\"   Prediction: {pred_label}\")\n",
        "    print(f\"   Top confidence: {top_confidence:.3f}\")\n",
        "    print(f\"   Margin: {margin:.3f} {'\u2713 Above threshold' if margin >= confidence_threshold else '\u2717 Below threshold'}\")\n",
        "    print(f\"   Status: {status}\", end=\"\")\n",
        "\n",
        "    if prediction is not None:\n",
        "        correct = prediction == y_true[i]\n",
        "        print(f\" - {'\u2713 CORRECT' if correct else '\u2717 INCORRECT'}\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "    results.append({\n",
        "        'review': review,\n",
        "        'true': y_true[i],\n",
        "        'pred': prediction,\n",
        "        'margin': margin,\n",
        "        'status': status\n",
        "    })\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "made_predictions = [r for r in results if r['pred'] is not None]\n",
        "uncertain_cases = [r for r in results if r['pred'] is None]\n",
        "correct_predictions = [r for r in made_predictions if r['pred'] == r['true']]\n",
        "\n",
        "total = len(results)\n",
        "n_predicted = len(made_predictions)\n",
        "n_uncertain = len(uncertain_cases)\n",
        "n_correct = len(correct_predictions)\n",
        "\n",
        "coverage = n_predicted / total\n",
        "accuracy = n_correct / n_predicted if n_predicted > 0 else 0\n",
        "\n",
        "print(f\"\\nCoverage: {n_predicted}/{total} = {coverage:.1%}\")\n",
        "print(f\"  \u2192 Made predictions for {n_predicted} reviews\")\n",
        "print(f\"  \u2192 Refused to predict on {n_uncertain} reviews\")\n",
        "\n",
        "print(f\"\\nAccuracy (on predictions made): {n_correct}/{n_predicted} = {accuracy:.1%}\")\n",
        "print(f\"  \u2192 Of the {n_predicted} predictions, {n_correct} were correct\")\n",
        "\n",
        "print(f\"\\nTrade-off Analysis:\")\n",
        "print(f\"  Threshold = {confidence_threshold}\")\n",
        "print(f\"  \u2192 Higher threshold = fewer predictions but higher accuracy\")\n",
        "print(f\"  \u2192 Lower threshold = more predictions but lower accuracy\")\n",
        "\n",
        "# Show which reviews were uncertain\n",
        "if n_uncertain > 0:\n",
        "    print(f\"\\n\" + \"-\"*80)\n",
        "    print(f\"UNCERTAIN CASES (margin < {confidence_threshold}):\")\n",
        "    print(\"-\"*80)\n",
        "    for r in uncertain_cases:\n",
        "        print(f\"  \u2022 '{r['review']}'\")\n",
        "        print(f\"    Margin: {r['margin']:.3f} (too close to call)\")\n",
        "\n",
        "# TODO: After experimenting with thresholds, analyze the trade-off\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT LOG - Fill this in as you try different thresholds:\")\n",
        "print(\"=\"*80)\n",
        "print(\"| Threshold | Coverage | Accuracy | Notes                    |\")\n",
        "print(\"|-----------|----------|----------|--------------------------|\")\n",
        "print(\"| 0.05      | ??.?%    | ??.?%    | ?                        |\")\n",
        "print(\"| 0.15      | ??.?%    | ??.?%    | ?                        |\")\n",
        "print(\"| 0.30      | ??.?%    | ??.?%    | ?                        |\")\n",
        "print(\"| 0.50      | ??.?%    | ??.?%    | ?                        |\")\n",
        "print()\n",
        "print(f\"Current:    | {confidence_threshold:<9.2f} | {coverage*100:>5.1f}%    | {accuracy*100:>5.1f}%    |\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpzBi9YBFZRi",
        "outputId": "28f21c01-c8d7-4c04-8256-6f0dd47f890c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CONFIDENCE-BASED CLASSIFICATION (threshold=0.15)\n",
            "================================================================================\n",
            "\n",
            "1. 'Absolutely fantastic! Best movie ever!'\n",
            "   True label: Positive\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.451\n",
            "   Margin: 0.092 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "2. 'Pretty good, I liked it'\n",
            "   True label: Positive\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.410\n",
            "   Margin: 0.018 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "3. 'It was fine, nothing special'\n",
            "   True label: Negative\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.418\n",
            "   Margin: 0.051 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "4. 'Not bad but not great either'\n",
            "   True label: Negative\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.414\n",
            "   Margin: 0.053 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "5. 'Quite disappointing'\n",
            "   True label: Negative\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.354\n",
            "   Margin: 0.080 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "6. 'Terrible! Complete waste of time!'\n",
            "   True label: Negative\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.397\n",
            "   Margin: 0.121 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "7. 'The movie had some interesting moments'\n",
            "   True label: Positive\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.506\n",
            "   Margin: 0.118 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "8. 'Outstanding performances all around!'\n",
            "   True label: Positive\n",
            "   Prediction: UNCERTAIN\n",
            "   Top confidence: 0.282\n",
            "   Margin: 0.098 \u2717 Below threshold\n",
            "   Status: UNCERTAIN\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Coverage: 0/8 = 0.0%\n",
            "  \u2192 Made predictions for 0 reviews\n",
            "  \u2192 Refused to predict on 8 reviews\n",
            "\n",
            "Accuracy (on predictions made): 0/0 = 0.0%\n",
            "  \u2192 Of the 0 predictions, 0 were correct\n",
            "\n",
            "Trade-off Analysis:\n",
            "  Threshold = 0.15\n",
            "  \u2192 Higher threshold = fewer predictions but higher accuracy\n",
            "  \u2192 Lower threshold = more predictions but lower accuracy\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "UNCERTAIN CASES (margin < 0.15):\n",
            "--------------------------------------------------------------------------------\n",
            "  \u2022 'Absolutely fantastic! Best movie ever!'\n",
            "    Margin: 0.092 (too close to call)\n",
            "  \u2022 'Pretty good, I liked it'\n",
            "    Margin: 0.018 (too close to call)\n",
            "  \u2022 'It was fine, nothing special'\n",
            "    Margin: 0.051 (too close to call)\n",
            "  \u2022 'Not bad but not great either'\n",
            "    Margin: 0.053 (too close to call)\n",
            "  \u2022 'Quite disappointing'\n",
            "    Margin: 0.080 (too close to call)\n",
            "  \u2022 'Terrible! Complete waste of time!'\n",
            "    Margin: 0.121 (too close to call)\n",
            "  \u2022 'The movie had some interesting moments'\n",
            "    Margin: 0.118 (too close to call)\n",
            "  \u2022 'Outstanding performances all around!'\n",
            "    Margin: 0.098 (too close to call)\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT LOG - Fill this in as you try different thresholds:\n",
            "================================================================================\n",
            "| Threshold | Coverage | Accuracy | Notes                    |\n",
            "|-----------|----------|----------|--------------------------|\n",
            "| 0.05      | ??.?%    | ??.?%    | ?                        |\n",
            "| 0.15      | ??.?%    | ??.?%    | ?                        |\n",
            "| 0.30      | ??.?%    | ??.?%    | ?                        |\n",
            "| 0.50      | ??.?%    | ??.?%    | ?                        |\n",
            "\n",
            "Current:    | 0.15      |   0.0%    |   0.0%    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. What do uncertain reviews have in common? Are they using hedging language like \"kind of\" or \"somewhat\"?\n",
        "\n",
        "2. Compare results at threshold=0.05 vs 0.30. Describe the coverage vs accuracy trade-off. When would you want high coverage vs high accuracy?\n",
        "\n",
        "3. How could you use confidence-based prediction in production? What should a system do when the model is uncertain?"
      ],
      "metadata": {
        "id": "H7-OE7H9F6vx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**About This Task:**\n\n",
        "Systematic failure analysis reveals model weaknesses and guides improvements. Understanding when and why classifiers fail is crucial for iterative model development and setting realistic performance expectations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Medium Task 4: Classifier Failure Analysis\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Train classifier and review overall error analysis\n",
        "2. Study error patterns to understand which reviews failed and why\n",
        "3. Uncomment TODO to add your own \"hard cases\" that you predict will fail\n",
        "4. Test hypotheses: Do sarcastic reviews fail? Short reviews? Mixed sentiment?\n",
        "5. Propose fixes based on your analysis"
      ],
      "metadata": {
        "id": "hfzp5dAmGF3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Use subset for faster experimentation\n",
        "train_subset = data[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "test_subset = data[\"test\"].shuffle(seed=42).select(range(200))\n",
        "\n",
        "# Train classifier\n",
        "print(\"Training classifier on 1000 movie reviews...\")\n",
        "train_embeddings = model.encode(train_subset[\"text\"], show_progress_bar=False)\n",
        "test_embeddings = model.encode(test_subset[\"text\"], show_progress_bar=False)\n",
        "\n",
        "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf.fit(train_embeddings, train_subset[\"label\"])\n",
        "\n",
        "# Get predictions\n",
        "predictions = clf.predict(test_embeddings)\n",
        "probabilities = clf.predict_proba(test_embeddings)\n",
        "\n",
        "# Analyze errors\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "errors = []\n",
        "for i in range(len(test_subset)):\n",
        "    if predictions[i] != test_subset[\"label\"][i]:\n",
        "        confidence = probabilities[i][predictions[i]]\n",
        "        errors.append({\n",
        "            'index': i,\n",
        "            'text': test_subset[\"text\"][i],\n",
        "            'true_label': test_subset[\"label\"][i],\n",
        "            'predicted_label': predictions[i],\n",
        "            'confidence': confidence,\n",
        "            'length': len(test_subset[\"text\"][i].split())\n",
        "        })\n",
        "\n",
        "total_errors = len(errors)\n",
        "total_samples = len(test_subset)\n",
        "accuracy = (total_samples - total_errors) / total_samples\n",
        "\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  Correct: {total_samples - total_errors}/{total_samples} ({accuracy:.1%})\")\n",
        "print(f\"  Errors:  {total_errors}/{total_samples} ({total_errors/total_samples:.1%})\")\n",
        "\n",
        "# Categorize errors\n",
        "false_positives = [e for e in errors if e['predicted_label'] == 1]\n",
        "false_negatives = [e for e in errors if e['predicted_label'] == 0]\n",
        "\n",
        "print(f\"\\nError Types:\")\n",
        "print(f\"  False Positives: {len(false_positives)} (predicted positive, actually negative)\")\n",
        "print(f\"  False Negatives: {len(false_negatives)} (predicted negative, actually positive)\")\n",
        "\n",
        "# Show high-confidence errors (most surprising)\n",
        "high_conf_errors = [e for e in errors if e['confidence'] > 0.7]\n",
        "\n",
        "print(f\"\\n\" + \"-\"*80)\n",
        "print(f\"HIGH-CONFIDENCE ERRORS (confidence > 0.7)\")\n",
        "print(f\"These are the most surprising mistakes:\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for i, error in enumerate(high_conf_errors[:5]):\n",
        "    true_sent = \"Positive\" if error['true_label'] == 1 else \"Negative\"\n",
        "    pred_sent = \"Positive\" if error['predicted_label'] == 1 else \"Negative\"\n",
        "\n",
        "    print(f\"\\n{i+1}. '{error['text']}'\")\n",
        "    print(f\"   True: {true_sent} | Predicted: {pred_sent} | Confidence: {error['confidence']:.3f}\")\n",
        "    print(f\"   Length: {error['length']} words\")\n",
        "\n",
        "# Analyze by text length\n",
        "print(f\"\\n\" + \"-\"*80)\n",
        "print(\"ERROR ANALYSIS BY TEXT LENGTH\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "error_lengths = [e['length'] for e in errors]\n",
        "correct_lengths = [len(test_subset[\"text\"][i].split())\n",
        "                   for i in range(len(test_subset))\n",
        "                   if predictions[i] == test_subset[\"label\"][i]]\n",
        "\n",
        "avg_error_length = np.mean(error_lengths) if error_lengths else 0\n",
        "avg_correct_length = np.mean(correct_lengths) if correct_lengths else 0\n",
        "\n",
        "print(f\"\\nAverage length of ERROR reviews: {avg_error_length:.1f} words\")\n",
        "print(f\"Average length of CORRECT reviews: {avg_correct_length:.1f} words\")\n",
        "\n",
        "if avg_error_length < avg_correct_length:\n",
        "    print(f\"\u2192 Observation: Errors tend to be SHORTER\")\n",
        "elif avg_error_length > avg_correct_length:\n",
        "    print(f\"\u2192 Observation: Errors tend to be LONGER\")\n",
        "else:\n",
        "    print(f\"\u2192 Observation: No clear length pattern\")\n",
        "\n",
        "# Test edge cases\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING EDGE CASES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "edge_cases = [\n",
        "    (\"Sarcastic\", \"Oh great, another masterpiece. NOT!\", 0),\n",
        "    (\"Mixed\", \"The acting was great but the plot was terrible\", 0),\n",
        "    (\"Backhanded\", \"Not as bad as I expected\", 1),\n",
        "    (\"Double negative\", \"Not unwatchable\", 1),\n",
        "    (\"Very short\", \"Boring\", 0),\n",
        "    (\"Ambiguous\", \"It was a movie\", 0),\n",
        "]\n",
        "\n",
        "# TODO: After analyzing above errors, add your own test cases:\n",
        "# edge_cases.extend([\n",
        "#     (\"Your category\", \"Your test review here\", expected_label_0_or_1),\n",
        "#     (\"Another category\", \"Another test review\", expected_label),\n",
        "# ])\n",
        "\n",
        "print(\"\\nTesting challenging cases that often fail:\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "edge_embeddings = model.encode([text for _, text, _ in edge_cases])\n",
        "edge_predictions = clf.predict(edge_embeddings)\n",
        "edge_probs = clf.predict_proba(edge_embeddings)\n",
        "\n",
        "correct_count = 0\n",
        "for i, (category, text, true_label) in enumerate(edge_cases):\n",
        "    pred = edge_predictions[i]\n",
        "    conf = edge_probs[i][pred]\n",
        "    correct = pred == true_label\n",
        "    if correct:\n",
        "        correct_count += 1\n",
        "\n",
        "    true_sent = \"Positive\" if true_label == 1 else \"Negative\"\n",
        "    pred_sent = \"Positive\" if pred == 1 else \"Negative\"\n",
        "\n",
        "    print(f\"\\n{category}: '{text}'\")\n",
        "    print(f\"  True: {true_sent} | Predicted: {pred_sent} | Confidence: {conf:.3f}\")\n",
        "    print(f\"  Result: {'\u2713 CORRECT' if correct else '\u2717 WRONG'}\")\n",
        "\n",
        "edge_accuracy = correct_count / len(edge_cases)\n",
        "print(f\"\\n\" + \"-\"*80)\n",
        "print(f\"Edge Case Accuracy: {correct_count}/{len(edge_cases)} ({edge_accuracy:.1%})\")\n",
        "print(f\"Regular Test Accuracy: {accuracy:.1%}\")\n",
        "print(f\"Difference: {accuracy - edge_accuracy:+.1%}\")\n",
        "\n",
        "# Summary and insights\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS FROM ERROR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. Error Distribution:\")\n",
        "print(f\"   - False Positives (predicted too optimistic): {len(false_positives)}\")\n",
        "print(f\"   - False Negatives (predicted too pessimistic): {len(false_negatives)}\")\n",
        "if len(false_positives) > len(false_negatives):\n",
        "    print(f\"   \u2192 Classifier has POSITIVE BIAS\")\n",
        "elif len(false_negatives) > len(false_positives):\n",
        "    print(f\"   \u2192 Classifier has NEGATIVE BIAS\")\n",
        "\n",
        "print(\"\\n2. Challenging Cases:\")\n",
        "failing_categories = [cat for cat, text, true in edge_cases\n",
        "                     if clf.predict(model.encode([text]))[0] != true]\n",
        "if failing_categories:\n",
        "    print(f\"   The classifier struggles with: {', '.join(failing_categories)}\")\n",
        "\n",
        "print(\"\\n3. Confidence Analysis:\")\n",
        "if high_conf_errors:\n",
        "    print(f\"   Found {len(high_conf_errors)} high-confidence errors\")\n",
        "    print(f\"   \u2192 The model is 'confidently wrong' on some cases\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TODO: Based on your error analysis, propose improvements:\")\n",
        "print(\"=\"*80)\n",
        "print(\"# Write your observations here:\")\n",
        "print(\"# 1. What patterns did you notice in the errors?\")\n",
        "print(\"# 2. Which edge cases failed most?\")\n",
        "print(\"# 3. How would you improve the classifier?\")\n",
        "print(\"#    - Better training data?\")\n",
        "print(\"#    - Different features?\")\n",
        "print(\"#    - Ensemble approach?\")\n",
        "print(\"#    - Confidence thresholds?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfz2qOmPGHWp",
        "outputId": "341250f6-c025-4e7a-ded8-de541c0ebc44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier on 1000 movie reviews...\n",
            "\n",
            "================================================================================\n",
            "ERROR ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Correct: 174/200 (87.0%)\n",
            "  Errors:  26/200 (13.0%)\n",
            "\n",
            "Error Types:\n",
            "  False Positives: 11 (predicted positive, actually negative)\n",
            "  False Negatives: 15 (predicted negative, actually positive)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "HIGH-CONFIDENCE ERRORS (confidence > 0.7)\n",
            "These are the most surprising mistakes:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1. 'an uneasy mix of run-of-the-mill raunchy humor and seemingly sincere personal reflection .'\n",
            "   True: Negative | Predicted: Positive | Confidence: 0.701\n",
            "   Length: 13 words\n",
            "\n",
            "2. 'the stunt work is top-notch ; the dialogue and drama often food-spittingly funny .'\n",
            "   True: Negative | Predicted: Positive | Confidence: 0.867\n",
            "   Length: 14 words\n",
            "\n",
            "3. 'goldmember is funny enough to justify the embarrassment of bringing a barf bag to the moviehouse .'\n",
            "   True: Positive | Predicted: Negative | Confidence: 0.710\n",
            "   Length: 17 words\n",
            "\n",
            "4. 'steven soderbergh doesn't remake andrei tarkovsky's solaris so much as distill it .'\n",
            "   True: Positive | Predicted: Negative | Confidence: 0.730\n",
            "   Length: 13 words\n",
            "\n",
            "5. '\" what really happened ? \" is a question for philosophers , not filmmakers ; all the filmmakers need to do is engage an audience .'\n",
            "   True: Positive | Predicted: Negative | Confidence: 0.717\n",
            "   Length: 26 words\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ERROR ANALYSIS BY TEXT LENGTH\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Average length of ERROR reviews: 19.8 words\n",
            "Average length of CORRECT reviews: 21.4 words\n",
            "\u2192 Observation: Errors tend to be SHORTER\n",
            "\n",
            "================================================================================\n",
            "TESTING EDGE CASES\n",
            "================================================================================\n",
            "\n",
            "Testing challenging cases that often fail:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sarcastic: 'Oh great, another masterpiece. NOT!'\n",
            "  True: Negative | Predicted: Positive | Confidence: 0.648\n",
            "  Result: \u2717 WRONG\n",
            "\n",
            "Mixed: 'The acting was great but the plot was terrible'\n",
            "  True: Negative | Predicted: Negative | Confidence: 0.920\n",
            "  Result: \u2713 CORRECT\n",
            "\n",
            "Backhanded: 'Not as bad as I expected'\n",
            "  True: Positive | Predicted: Negative | Confidence: 0.809\n",
            "  Result: \u2717 WRONG\n",
            "\n",
            "Double negative: 'Not unwatchable'\n",
            "  True: Positive | Predicted: Negative | Confidence: 0.902\n",
            "  Result: \u2717 WRONG\n",
            "\n",
            "Very short: 'Boring'\n",
            "  True: Negative | Predicted: Negative | Confidence: 0.949\n",
            "  Result: \u2713 CORRECT\n",
            "\n",
            "Ambiguous: 'It was a movie'\n",
            "  True: Negative | Predicted: Negative | Confidence: 0.709\n",
            "  Result: \u2713 CORRECT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Edge Case Accuracy: 3/6 (50.0%)\n",
            "Regular Test Accuracy: 87.0%\n",
            "Difference: +37.0%\n",
            "\n",
            "================================================================================\n",
            "KEY INSIGHTS FROM ERROR ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "1. Error Distribution:\n",
            "   - False Positives (predicted too optimistic): 11\n",
            "   - False Negatives (predicted too pessimistic): 15\n",
            "   \u2192 Classifier has NEGATIVE BIAS\n",
            "\n",
            "2. Challenging Cases:\n",
            "   The classifier struggles with: Sarcastic, Backhanded, Double negative\n",
            "\n",
            "3. Confidence Analysis:\n",
            "   Found 11 high-confidence errors\n",
            "   \u2192 The model is 'confidently wrong' on some cases\n",
            "\n",
            "================================================================================\n",
            "TODO: Based on your error analysis, propose improvements:\n",
            "================================================================================\n",
            "# Write your observations here:\n",
            "# 1. What patterns did you notice in the errors?\n",
            "# 2. Which edge cases failed most?\n",
            "# 3. How would you improve the classifier?\n",
            "#    - Better training data?\n",
            "#    - Different features?\n",
            "#    - Ensemble approach?\n",
            "#    - Confidence thresholds?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection Questions:**\n",
        "\n",
        "1. What do high-confidence errors have in common? How does model confidence relate to correctness?\n",
        "\n",
        "2. Do errors tend to be shorter, longer, or similar length compared to correct predictions? Why might text length affect classification?\n",
        "\n",
        "3. Which edge cases failed most - sarcasm, mixed sentiment, or double negatives? What aspects of language do embeddings not capture well?"
      ],
      "metadata": {
        "id": "M0kp8xwOGU70"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}