{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A2SZPmbD4Pk"
   },
   "source": [
    "<h1>Chapter 8 - Semantic Search and Retrieval-Augmented Generation</h1>\n",
    "<i>Exploring a vital part of LLMs, search.</i>\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
    "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is for Chapter 8 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
    "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
    "\n",
    "---\n",
    "\n",
    "üí° **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.2.5\n",
      "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting faiss-cpu==1.8.0\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting cohere==5.5.8\n",
      "  Downloading cohere-5.5.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain-community==0.2.5\n",
      "  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rank_bm25==0.2.2\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting sentence-transformers==3.0.1\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.2.5)\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.2.5)\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.2.5)\n",
      "  Using cached aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.2.5)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain==0.2.5)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.5)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.5)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.2.5)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain==0.2.5)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting requests<3,>=2 (from langchain==0.2.5)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.5)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere==5.5.8)\n",
      "  Downloading boto3-1.40.68-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere==5.5.8)\n",
      "  Downloading fastavro-1.12.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting httpx>=0.21.2 (from cohere==5.5.8)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere==5.5.8)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere==5.5.8)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tokenizers<1,>=0.15 (from cohere==5.5.8)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere==5.5.8)\n",
      "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from cohere==5.5.8) (4.15.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.2.5)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers==3.0.1)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers==3.0.1)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers==3.0.1)\n",
      "  Using cached torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers==3.0.1)\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers==3.0.1)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers==3.0.1)\n",
      "  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers==3.0.1)\n",
      "  Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5)\n",
      "  Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.68 (from boto3<2.0.0,>=1.34.0->cohere==5.5.8)\n",
      "  Downloading botocore-1.40.68-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere==5.5.8)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2.0.0,>=1.34.0->cohere==5.5.8)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.68->boto3<2.0.0,>=1.34.0->cohere==5.5.8) (2.9.0.post0)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore<1.41.0,>=1.40.68->boto3<2.0.0,>=1.34.0->cohere==5.5.8)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.5)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.5)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain==0.2.5)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.7->langchain==0.2.5)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain==0.2.5)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.5)\n",
      "  Downloading orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.5)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio (from httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1->langchain==0.2.5)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1->langchain==0.2.5)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1->langchain==0.2.5)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.68->boto3<2.0.0,>=1.34.0->cohere==5.5.8) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain==0.2.5)\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain==0.2.5)\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers==3.0.1)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.5)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere==5.5.8) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.21.2->cohere==5.5.8)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers==3.0.1)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==3.0.1)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub>=0.15.1->sentence-transformers==3.0.1)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.5.8-py3-none-any.whl (173 kB)\n",
      "Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading boto3-1.40.68-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.40.68-py3-none-any.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading fastavro-1.12.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Downloading orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Downloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m584.4/584.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m791.7/791.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, urllib3, typing-inspection, triton, tqdm, threadpoolctl, tenacity, sympy, sniffio, safetensors, regex, PyYAML, pydantic-core, propcache, Pillow, parameterized, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mypy-extensions, multidict, MarkupSafe, jsonpointer, joblib, jmespath, idna, httpx-sse, hf-xet, h11, greenlet, fsspec, frozenlist, filelock, fastavro, charset_normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, types-requests, SQLAlchemy, scipy, requests, rank_bm25, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, marshmallow, jsonpatch, jinja2, httpcore, faiss-cpu, botocore, anyio, aiosignal, scikit-learn, s3transfer, requests-toolbelt, nvidia-cusolver-cu12, huggingface-hub, httpx, dataclasses-json, aiohttp, torch, tokenizers, langsmith, boto3, transformers, langchain-core, cohere, sentence-transformers, langchain-text-splitters, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: packaging‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/90\u001b[0m [Pillow]oolctl]\n",
      "\u001b[2K    Found existing installation: packaging 25.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/90\u001b[0m [Pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/90\u001b[0m [Pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/90\u001b[0m [Pillow]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90/90\u001b[0m [langchain-community]ommunity]ansformers]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 Pillow-12.0.0 PyYAML-6.0.3 SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 async-timeout-4.0.3 attrs-25.4.0 boto3-1.40.68 botocore-1.40.68 certifi-2025.10.5 charset_normalizer-3.4.4 cohere-5.5.8 dataclasses-json-0.6.7 faiss-cpu-1.8.0 fastavro-1.12.1 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 greenlet-3.2.4 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 jmespath-1.0.1 joblib-1.5.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-community-0.2.5 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.7.0 mypy-extensions-1.1.0 networkx-3.4.2 numpy-1.26.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 orjson-3.11.4 packaging-24.2 parameterized-0.9.0 propcache-0.4.1 pydantic-2.12.4 pydantic-core-2.41.5 rank_bm25-0.2.2 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 s3transfer-0.14.0 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.15.3 sentence-transformers-3.0.1 sniffio-1.3.1 sympy-1.14.0 tenacity-8.5.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 types-requests-2.32.4.20250913 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.5.0 yarl-1.22.0\n",
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu124\n",
      "Collecting llama-cpp-python==0.2.78\n",
      "  Downloading llama_cpp_python-0.2.78.tar.gz (50.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.2/50.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:21\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from llama-cpp-python==0.2.78) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from llama-cpp-python==0.2.78) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.78)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from llama-cpp-python==0.2.78) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.78) (3.0.3)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.78-cp310-cp310-linux_x86_64.whl size=3681663 sha256=761d6eedc2218db520babdf69b68792e543064426aa8278da3790d034bcde8f8\n",
      "  Stored in directory: /home/danielcastillo/.cache/pip/wheels/fd/c5/bd/3b1c20081bd71ce9d28b562573c97915c790bf1ef231879a61\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [llama-cpp-python][llama-cpp-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.2.78\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install langchain==0.2.5 faiss-cpu==1.8.0 cohere==5.5.8 langchain-community==0.2.5 rank_bm25==0.2.2 sentence-transformers==3.0.1\n",
    "!pip install llama-cpp-python==0.2.78  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n",
    "\n",
    "## IMPORTANT: Make sure to restart the session after installing the packages above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0HbBr3EV0P"
   },
   "source": [
    "# Dense Retrieval Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svgdo3y3F741"
   },
   "source": [
    "## 1. Getting the text archive and chunking it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOFFg7YWFoaf"
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "\n",
    "# Paste your API key here. Remember to not share publicly\n",
    "# api_key = ''\n",
    "api_key = os.environ.get('COHERE_API_KEY') # Get API key from environment variable\n",
    "\n",
    "# Create and retrieve a Cohere API key from os.cohere.ai\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_Dcq1j_xFxIr"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
    "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades\"\"\"\n",
    "\n",
    "# Split into a list of sentences\n",
    "texts = text.split('.')\n",
    "\n",
    "# Clean up to remove empty spaces and new lines\n",
    "texts = [t.strip(' \\n') for t in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the split up sentences. Here, we use '.' (a dot) as the separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan',\n",
       " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine',\n",
       " 'Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind',\n",
       " 'Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007',\n",
       " 'Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar',\n",
       " 'Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm',\n",
       " 'Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles',\n",
       " 'Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects',\n",
       " 'Interstellar premiered on October 26, 2014, in Los Angeles',\n",
       " 'In the United States, it was first released on film stock, expanding to venues using digital projectors',\n",
       " 'The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014',\n",
       " 'It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight',\n",
       " 'It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics',\n",
       " 'Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time',\n",
       " 'Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use 'o' just to see how it would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science ficti',\n",
       " 'n film c',\n",
       " '-written, directed, and pr',\n",
       " 'duced by Christ',\n",
       " 'pher N',\n",
       " 'lan.\\nIt stars Matthew McC',\n",
       " 'naughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Dam',\n",
       " 'n, and Michael Caine.\\nSet in a dyst',\n",
       " 'pian future where humanity is struggling t',\n",
       " 'survive, the film f',\n",
       " 'll',\n",
       " 'ws a gr',\n",
       " 'up',\n",
       " 'f astr',\n",
       " 'nauts wh',\n",
       " 'travel thr',\n",
       " 'ugh a w',\n",
       " 'rmh',\n",
       " 'le near Saturn in search',\n",
       " 'f a new h',\n",
       " 'me f',\n",
       " 'r mankind.\\n\\nBr',\n",
       " 'thers Christ',\n",
       " 'pher and J',\n",
       " 'nathan N',\n",
       " 'lan wr',\n",
       " 'te the screenplay, which had its',\n",
       " 'rigins in a script J',\n",
       " 'nathan devel',\n",
       " 'ped in 2007.\\nCaltech the',\n",
       " 'retical physicist and 2017 N',\n",
       " 'bel laureate in Physics[4] Kip Th',\n",
       " 'rne was an executive pr',\n",
       " 'ducer, acted as a scientific c',\n",
       " 'nsultant, and wr',\n",
       " 'te a tie-in b',\n",
       " '',\n",
       " 'k, The Science',\n",
       " 'f Interstellar.\\nCinemat',\n",
       " 'grapher H',\n",
       " 'yte van H',\n",
       " 'ytema sh',\n",
       " 't it',\n",
       " 'n 35 mm m',\n",
       " 'vie film in the Panavisi',\n",
       " 'n anam',\n",
       " 'rphic f',\n",
       " 'rmat and IMAX 70 mm.\\nPrincipal ph',\n",
       " 't',\n",
       " 'graphy began in late 2013 and t',\n",
       " '',\n",
       " 'k place in Alberta, Iceland, and L',\n",
       " 's Angeles.\\nInterstellar uses extensive practical and miniature effects and the c',\n",
       " 'mpany D',\n",
       " 'uble Negative created additi',\n",
       " 'nal digital effects.\\n\\nInterstellar premiered',\n",
       " 'n Oct',\n",
       " 'ber 26, 2014, in L',\n",
       " 's Angeles.\\nIn the United States, it was first released',\n",
       " 'n film st',\n",
       " 'ck, expanding t',\n",
       " 'venues using digital pr',\n",
       " 'ject',\n",
       " 'rs.\\nThe film had a w',\n",
       " 'rldwide gr',\n",
       " 'ss',\n",
       " 'ver $677 milli',\n",
       " 'n (and $773 milli',\n",
       " 'n with subsequent re-releases), making it the tenth-highest gr',\n",
       " 'ssing film',\n",
       " 'f 2014.\\nIt received acclaim f',\n",
       " 'r its perf',\n",
       " 'rmances, directi',\n",
       " 'n, screenplay, musical sc',\n",
       " 're, visual effects, ambiti',\n",
       " 'n, themes, and em',\n",
       " 'ti',\n",
       " 'nal weight.\\nIt has als',\n",
       " 'received praise fr',\n",
       " 'm many astr',\n",
       " 'n',\n",
       " 'mers f',\n",
       " 'r its scientific accuracy and p',\n",
       " 'rtrayal',\n",
       " 'f the',\n",
       " 'retical astr',\n",
       " 'physics. Since its premiere, Interstellar gained a cult f',\n",
       " 'll',\n",
       " 'wing,[5] and n',\n",
       " 'w is regarded by many sci-fi experts as',\n",
       " 'ne',\n",
       " 'f the best science-ficti',\n",
       " 'n films',\n",
       " 'f all time.\\nInterstellar was n',\n",
       " 'minated f',\n",
       " 'r five awards at the 87th Academy Awards, winning Best Visual Effects, and received numer',\n",
       " 'us',\n",
       " 'ther acc',\n",
       " 'lades']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts2 = text.split('o')\n",
    "\n",
    "texts2 = [t.strip('\\n ' ) for t in texts2]\n",
    "\n",
    "texts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krDDOpcZF5qo"
   },
   "source": [
    "## 2. Embedding the Text Chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the cohere functions better and their parameters, visit https://docs.cohere.com/v1/reference/embed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1718963354789,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "xooetZg0Fz4K",
    "outputId": "1f105f8c-e6a9-4cc1-b620-1f9a03bec288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 4096)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the embeddings\n",
    "response = co.embed(\n",
    "  texts=texts,\n",
    "  input_type=\"search_document\", # this means we use the embeddings to store in a vector database.\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(response)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLVdFg1PF4GG"
   },
   "source": [
    "## 3. Building The Search Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about FAISS, visit https://faiss.ai/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyqzN2-JF24N"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim) # Uses L2 Euclidean distance metric\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x701e88be76f0> >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6qRFo8dGGrJ"
   },
   "source": [
    "## 4. Search the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /media/danielcastillo/DanielSSD1/ads525/ads525/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "o83pxM5sGHxp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search(query, number_of_results=5):\n",
    "\n",
    "  # 1. Get the query's embedding\n",
    "  query_embed = co.embed(texts=[query],\n",
    "                input_type=\"search_query\",).embeddings[0]\n",
    "\n",
    "  # 2. Retrieve the nearest neighbors\n",
    "  distances , similar_item_ids = index.search(np.float32([query_embed]), number_of_results)\n",
    "\n",
    "  # 3. Format the results\n",
    "  texts_np = np.array(texts) # Convert texts list to numpy for easier indexing\n",
    "  results = pd.DataFrame(data={'texts': texts_np[similar_item_ids[0]],\n",
    "                              'distance': distances[0]})\n",
    "\n",
    "  # 4. Print and return the results\n",
    "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use semantic similarity using embeddings (distance from each other in the embedding space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1718963357199,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "Rq_2knm_GLgR",
    "outputId": "eaee1a34-a690-4f6c-ecb1-53974ae6f319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>10757.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>11566.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>11922.841797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cinematographer Hoyte van Hoytema shot it on 3...</td>\n",
       "      <td>12673.581055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since its premiere, Interstellar gained a cult...</td>\n",
       "      <td>13249.777344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts      distance\n",
       "0  It has also received praise from many astronom...  10757.371094\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  11566.136719\n",
       "2  Interstellar uses extensive practical and mini...  11922.841797\n",
       "3  Cinematographer Hoyte van Hoytema shot it on 3...  12673.581055\n",
       "4  Since its premiere, Interstellar gained a cult...  13249.777344"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 is a ranking algorithm used in information retrieval systems to determine how relevant a document is to a given search query.\n",
    "\n",
    "Unlike dense/embedding-based retrieval, BM25 uses term/lexical features. \n",
    "\n",
    "Visit https://www.geeksforgeeks.org/nlp/what-is-bm25-best-matching-25-algorithm for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EkkDh12ZGRhY"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "cHl8HnvgGXHG",
    "outputId": "0defa2a0-8e6b-436b-f6d2-6c5ce94f1636"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 122401.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZlyGXye4GRj0"
   },
   "outputs": [],
   "source": [
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "jV-V_mhRGRmS",
    "outputId": "0957579e-0de7-4646-949e-cd9750178dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.789\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.373\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine\n"
     ]
    }
   ],
   "source": [
    "keyword_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehyhfd7NG5kw"
   },
   "source": [
    "## Caveats of Dense Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "NxYwEfYRGpNe",
    "outputId": "dfaf50a0-f500-4160-8126-1b3a825fe750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'What is the mass of the moon?'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cinematographer Hoyte van Hoytema shot it on 3...</td>\n",
       "      <td>12854.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The film had a worldwide gross over $677 milli...</td>\n",
       "      <td>13301.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>13332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It stars Matthew McConaughey, Anne Hathaway, J...</td>\n",
       "      <td>13826.293945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>14105.029297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts      distance\n",
       "0  Cinematographer Hoyte van Hoytema shot it on 3...  12854.445312\n",
       "1  The film had a worldwide gross over $677 milli...  13301.009766\n",
       "2  It has also received praise from many astronom...  13332.000000\n",
       "3  It stars Matthew McConaughey, Anne Hathaway, J...  13826.293945\n",
       "4  Interstellar uses extensive practical and mini...  14105.029297"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the mass of the moon?\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from the slides that one caveat of dense retrieval is that it always returns results. A way to get around this is by using a threshold to filter out less similar results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_RalLmuG0jw"
   },
   "source": [
    "# Reranking Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "HulOxkW_Focv",
    "outputId": "06e05541-4383-452e-d41a-04c3dc5521fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'), index=12, relevance_score=0.15239799),\n",
       " RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'), index=10, relevance_score=0.050354082),\n",
       " RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan'), index=0, relevance_score=0.0350424)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
    "results.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more about Cohere's `co.rerank()` functon, visit https://docs.cohere.com/v1/reference/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "SUrmMW8LFofP",
    "outputId": "9724bf94-cf9d-45ff-eb80-50ededa34275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15239799 It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics\n",
      "1 0.050354082 The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014\n",
      "2 0.0350424 Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score , result.document.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you see the order (according to the `relevance_score`), the `relevance_score`, and the text.\n",
    "\n",
    "As you can see, the first text has a significantly higher `relevance_score`. Read the text itself and it makes sense. The first sentence uses more science-related words like `astronomers`, `scientific accuracy`, `theoretical astrophysics`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that before reranking, the highest ranking text was at the top 3 spot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rqYJaq2CFohv"
   },
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    #Add re-ranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits re-ranked)\")\n",
    "    results = co.rerank(query=query, documents=docs, top_n=top_k, return_documents=True)\n",
    "    for hit in results.results:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit.relevance_score, hit.document.text.replace(\"\\n\", \" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use reranking with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1718963359073,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "9FITOXqkHONy",
    "outputId": "c4e81e12-b19c-4fa0-8ce6-7907002df7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.789\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.373\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tInterstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects\n",
      "\n",
      "Top-3 hits by rank-API (10 BM25 hits re-ranked)\n",
      "\t0.035\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t0.032\tIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine\n",
      "\t0.031\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n"
     ]
    }
   ],
   "source": [
    "keyword_and_reranking_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugdnTs_VHV25"
   },
   "source": [
    "# Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iqKQ7F0HZh-"
   },
   "source": [
    "## Example: Grounded Generation with an LLM API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2275,
     "status": "ok",
     "timestamp": 1718963362077,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "VeHX0D8DHaim",
    "outputId": "364b75ea-0b36-4a01-b16f-aa407768dde8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'income generated'\n",
      "Nearest neighbors:\n",
      "The film generated a worldwide gross of over $677 million, or $773 million with subsequent re-releases.\n"
     ]
    }
   ],
   "source": [
    "query = \"income generated\"\n",
    "\n",
    "# 1- Retrieval\n",
    "# We'll use embedding search. But ideally we'd do hybrid\n",
    "results = search(query)\n",
    "\n",
    "# 2- Grounded Generation\n",
    "docs_dict = [{'text': text} for text in results['texts']]\n",
    "response = co.chat(\n",
    "    message = query,\n",
    "    documents=docs_dict\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1718963362438,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "E9YmHEOHHpUW",
    "outputId": "f8670a77-8f69-4870-8887-060fdf195978"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonStreamedChatResponse(text='The film generated a worldwide gross of over $677 million, or $773 million with subsequent re-releases.', generation_id='bebc32bd-d620-42cf-bd13-f8d1f96d4aa6', citations=[ChatCitation(start=21, end=57, text='worldwide gross of over $677 million', document_ids=['doc_0']), ChatCitation(start=62, end=103, text='$773 million with subsequent re-releases.', document_ids=['doc_0'])], documents=[{'id': 'doc_0', 'text': 'The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'}], is_search_required=None, search_queries=None, search_results=None, finish_reason='COMPLETE', tool_calls=None, chat_history=[Message_User(message='income generated', tool_calls=None, role='USER'), Message_Chatbot(message='The film generated a worldwide gross of over $677 million, or $773 million with subsequent re-releases.', tool_calls=None, role='CHATBOT')], prompt=None, meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=106, output_tokens=26, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=797, output_tokens=95), warnings=None), response_id='319002db-505d-4d3c-903f-41eefbf0f856')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718963362438,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "YLwaGXM2Hg7b",
    "outputId": "03f052d6-0723-45d9-8b24-fbc1195664c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCitation(start=21, end=57, text='worldwide gross of over $677 million', document_ids=['doc_0']),\n",
       " ChatCitation(start=62, end=103, text='$773 million with subsequent re-releases.', document_ids=['doc_0'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_25ztzEHuWX"
   },
   "source": [
    "## Example: RAG with Local Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNZ5gUoWIYhp"
   },
   "source": [
    "### Loading the Generation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33056,
     "status": "ok",
     "timestamp": 1718963395761,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "E4LNwOWTHvOv",
    "outputId": "945a6fa3-511d-48b7-d305-fe6d1dd23be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-21 09:49:22--  https://huggingface.co/lmstudio-community/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q8_0.gguf\n",
      "Resolving huggingface.co (huggingface.co)... 18.164.174.118, 18.164.174.23, 18.164.174.17, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.164.174.118|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/8e/3f/8e3fafa0351929e621a3db9a53b131a9d7f4b222332208032555bb92f11ab100/8d2f3732e31c354e169cd81dcde9807a1c73b85b9a0f9b16c19013e7a4bb151c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-Q8_0.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-Q8_0.gguf%22%3B&Expires=1719222562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTIyMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzhlLzNmLzhlM2ZhZmEwMzUxOTI5ZTYyMWEzZGI5YTUzYjEzMWE5ZDdmNGIyMjIzMzIyMDgwMzI1NTViYjkyZjExYWIxMDAvOGQyZjM3MzJlMzFjMzU0ZTE2OWNkODFkY2RlOTgwN2ExYzczYjg1YjlhMGY5YjE2YzE5MDEzZTdhNGJiMTUxYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=DFqGVAGZBHhpPlWt2pSH5nbTgskxr6FrSK19FhopbgIYnqujHL3LDgnleMTDHrtRvflyX-6QE88ZAYZc1wIZA7ZXgBVoFdYMNPbHixfv4hqGdKiddWcF4QYi5JCYChS3Z8oZPUkcbyX6KNTqMR1nls2KTZ3K0Xl3E7nGmlTXo85mRdRKQojZLkuLOa28pG2z9jrs1wJ1B2W3Ed%7E%7EK1E-BXhjKsK4zUR1Ch-3KfqAqe0q0XmnCcF1Ml2xosujvlA%7EZuVxflmRf8wRVZBZsbZNXaUFAb3oiyNTuyr9g1fvSxJPmAJocs9jIMUZwU88Sa4s%7EVdfytD0s6YruNH1GOAfoA__&Key-Pair-Id=K2FPYV99P2N66Q [following]\n",
      "--2024-06-21 09:49:22--  https://cdn-lfs-us-1.huggingface.co/repos/8e/3f/8e3fafa0351929e621a3db9a53b131a9d7f4b222332208032555bb92f11ab100/8d2f3732e31c354e169cd81dcde9807a1c73b85b9a0f9b16c19013e7a4bb151c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-Q8_0.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-Q8_0.gguf%22%3B&Expires=1719222562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTIyMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzhlLzNmLzhlM2ZhZmEwMzUxOTI5ZTYyMWEzZGI5YTUzYjEzMWE5ZDdmNGIyMjIzMzIyMDgwMzI1NTViYjkyZjExYWIxMDAvOGQyZjM3MzJlMzFjMzU0ZTE2OWNkODFkY2RlOTgwN2ExYzczYjg1YjlhMGY5YjE2YzE5MDEzZTdhNGJiMTUxYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=DFqGVAGZBHhpPlWt2pSH5nbTgskxr6FrSK19FhopbgIYnqujHL3LDgnleMTDHrtRvflyX-6QE88ZAYZc1wIZA7ZXgBVoFdYMNPbHixfv4hqGdKiddWcF4QYi5JCYChS3Z8oZPUkcbyX6KNTqMR1nls2KTZ3K0Xl3E7nGmlTXo85mRdRKQojZLkuLOa28pG2z9jrs1wJ1B2W3Ed%7E%7EK1E-BXhjKsK4zUR1Ch-3KfqAqe0q0XmnCcF1Ml2xosujvlA%7EZuVxflmRf8wRVZBZsbZNXaUFAb3oiyNTuyr9g1fvSxJPmAJocs9jIMUZwU88Sa4s%7EVdfytD0s6YruNH1GOAfoA__&Key-Pair-Id=K2FPYV99P2N66Q\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 18.65.25.71, 18.65.25.64, 18.65.25.113, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|18.65.25.71|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4061221024 (3.8G) [binary/octet-stream]\n",
      "Saving to: ‚ÄòPhi-3-mini-4k-instruct-Q8_0.gguf‚Äô\n",
      "\n",
      "Phi-3-mini-4k-instr 100%[===================>]   3.78G  66.7MB/s    in 33s     \n",
      "\n",
      "2024-06-21 09:49:55 (119 MB/s) - ‚ÄòPhi-3-mini-4k-instruct-Q8_0.gguf‚Äô saved [4061221024/4061221024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2Qgnc5OHvRQ"
   },
   "outputs": [],
   "source": [
    "from langchain import LlamaCpp\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7ahQtlvIZjS"
   },
   "source": [
    "### Loading the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539,
     "referenced_widgets": [
      "138cc674d550408d92f2793bb8d8feef",
      "83f7665ab87042798e1b8e94ef3275f7",
      "3c73236c809f45e49293deb47b55de0a",
      "5d2bcf6e2b874522ae07d65d59bac90b",
      "6058adc08c9e43adb214dc157980ccd5",
      "94f720fd05bd42d2a3e80456516511ad",
      "05e80b09ac484cc5a580d8d23bab4727",
      "acd7c3193cd849d2927811bcc7c3ab86",
      "d0db0682e7bb48b3b195dec91dfceea5",
      "d189e49a470a4fe5ad2b8374cd1c3422",
      "bdacebab45304f47b732c33ac4639e9e",
      "5cff7f41f95d47dbb1c296647c967bfc",
      "ae492efb01234d4fbfb928087d05f094",
      "a453e6e3da5548d3a0d3336ba397e505",
      "4dc38e826b7f4982ba36b77a4bf2db2e",
      "255c1e532ee048e286e1d5c89fe3015d",
      "19b25464d66945a2a0e40284b0f278ec",
      "d7b688b70a2d48e3b20b7fa1d90e8e97",
      "7f75961fa15b443fb4d528116b925922",
      "b6a72b7b8e864691996256146e91ef48",
      "1adb2c1d93004a4aaec5842eb07dd5df",
      "89b93e5618f64fbca249f7f3a0eaae49",
      "a8e14699f76a49fc95bf572c33e89b9e",
      "ba3157d275b845edb92df2ebc4ea9bc1",
      "6a4f72cbd2b94be5af4d3ffcad6b1e87",
      "71815245763045838934063bd772d3ab",
      "0b8f820e5efe4e10b33e9693c3eef9bf",
      "e702233daf474196a5eb7a6b9500e75a",
      "db1c9245b86946ac9dde32c29604f215",
      "e61d6b43f4144e6eaa43716261a85516",
      "ef4669fd011241c2ab048399a5ad89c4",
      "5d9802b14082481e93aa3650e7a14cec",
      "c4de82afef0f40af8147f0d93f978174",
      "25d46b46b26a48d7a4810dd691dbfa86",
      "d3aee1810b1c40e19a184d2d6af8eefa",
      "715ed5ce1cd243d09d19ade841be1a7c",
      "1a8e6ef4564e43c3b4631223491d1138",
      "277df89d75b0440e99c7c38304de709d",
      "a95a3d6cff4f4b1fa9d716099789cb9f",
      "f366405bc2af4d5e97a179300fe267b9",
      "00fc8b78e0c2440d9b514378c6f95099",
      "68e451cf20454e86aec8160ae82f3670",
      "c74ad52fe8bb44da8d3b2a7b1b10c4f1",
      "a7a538d9ec814c9e8fd50eb15712de8f",
      "3b990fafeff24fe8adb29a3d24a89565",
      "e39c103ec551423aa126540b6afa7d10",
      "29e90bb4d1fa4c11a3a8d563bdbeb160",
      "82e4cb20b3724261b1c59d8841325bb9",
      "8cc39fab52804fa1867d6395a51900f9",
      "fe5b5da0ccad4bd2b5dedbbb25d0817d",
      "f94579b834ee41d9b12a0759e8206763",
      "525c9e8a0d834bbd83e23bc381cf3ecd",
      "7372effad89243fb8d7dbbd87fa3b413",
      "b935647ac06f4e20bfa62de8a1ddf05e",
      "681ea5b1d73b4c3580f4dcca25b9d9d0",
      "89c99f9a11164857a367d22af469cf85",
      "d4604e6f553941fab0d2c583fcbd593a",
      "eda119b60c004a1bb00b7ca0e583188d",
      "2b8114428e8d484a9c0c0638477a31d1",
      "ad192a0f6d9d42f49e3e24caaee42e26",
      "f9af1e04b2144d9f9b104cfa87455109",
      "368731d085ed4eb5bc1c78d73725df39",
      "430ff548ae1d4edeb14b91c12fbeb9dc",
      "3038cc2ac17f4a0397840b7104d2fd7c",
      "15d6c1ab1e0f4908b2a7584159bb0105",
      "65a247e214364094a8d6fcefdbce1c3a",
      "326669dae98648b2b55e6fcb45ed4f43",
      "30cee3a3d2684bd59ec661e67090b7ea",
      "196331e7f282454fb4ea32de0410a495",
      "6e5aa6453a5741aa9696ce0444b7fca4",
      "14f8aa41b5574d6f855ddcde71c1e59b",
      "4930e2e16041457580e15399bb983c34",
      "c3180ac3bc61416abc7fe10db1171bd9",
      "a1f95710663b4bdeb7b1c7dc6f4f4eb7",
      "6328742a36d54f619a1a7803b6be790e",
      "cd87abc413db4d65be32fd47389b46ed",
      "a78c6111af5541e0893f3775f3992a6a",
      "2d6c6545fc9e446f882e1b0eadd03ffc",
      "b574a5cb83164992a2dff90c17587acb",
      "05f0d4f09ba84f7287178b1dd43fdd25",
      "0b5c0e31175b4b2f9f1c1c3cdc15d34e",
      "31f1a648bf5d4c7baf88de71dcc6d3c1",
      "fc5cc6536106431d8515731c0e682acc",
      "653c8fe00d5d4996b155df26d0a0598d",
      "1eb0802651cb4560bacfb9be6e23f335",
      "8518599e1b1144fda9f208956f8f1eff",
      "ed0677d112e5469bb42068f0e3b14adf",
      "cb6d2cb161c347aab0b3a06727d776df",
      "e7fdfec1d8b341d7a1c228c069632400",
      "32d56ae437da4d9cbcdecc6942a54ce8",
      "23ed3163e67f4a10bc626b3440de7553",
      "53f46138cc2c4e74a3cbe1f77ac2f92e",
      "dac714e2ccba4635a1aceb46ebdc33ac",
      "b3001c1847394d08ae53cf68ec697e0f",
      "bb434d424fa144b0b0211603d30b5c72",
      "e4cb2ade41d4466d99149cee70c1e7e9",
      "dddb4584c34f40c6bc66df30c1c3c4c0",
      "23169e2b0cb34fa388a7c7f7a140335c",
      "c3aacf3d8c7b4b4b9b98ca123e087593",
      "44d38a0ba97444c6bfd80c8c9553c070",
      "dd7f4f080941498397dc51d459bbc519",
      "5c5c32897b19438dbba56f72c577fe64",
      "e049e3a92fbd422198c16a94e46a5455",
      "18588efdadbc457a8940facc0aa96511",
      "ae97a2366ac944d1a089b4f1d8269822",
      "23dc7b6255cc479c89799dc10653008c",
      "f19fe22a899e4fa19e607c16c94cf16c",
      "28f6bcec0d6448e18fb894e2dae4c2ae",
      "3fd02e49e5f64baf95596b82e1c5d9fb",
      "9e0b0f814ad6487fb5ee842e723a0b52"
     ]
    },
    "executionInfo": {
     "elapsed": 23624,
     "status": "ok",
     "timestamp": 1718963519389,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "ODkBMgsIIddp",
    "outputId": "2ca552cb-565a-459b-e9eb-0aed4481d492"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138cc674d550408d92f2793bb8d8feef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cff7f41f95d47dbb1c296647c967bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e14699f76a49fc95bf572c33e89b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d46b46b26a48d7a4810dd691dbfa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b990fafeff24fe8adb29a3d24a89565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/66.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c99f9a11164857a367d22af469cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326669dae98648b2b55e6fcb45ed4f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6c6545fc9e446f882e1b0eadd03ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fdfec1d8b341d7a1c228c069632400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d38a0ba97444c6bfd80c8c9553c070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding Model for converting text to numerical representations\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-small-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgPua3jsIgmW"
   },
   "source": [
    "### Preparing the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV57LOf8IjM-"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a local vector database\n",
    "db = FAISS.from_texts(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P06UYeIVIk1e"
   },
   "source": [
    "### The RAG Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_3nTc69InwO"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "# Create a prompt template\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG Pipeline\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90250,
     "status": "ok",
     "timestamp": 1718963614201,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "x2p2pJPfIp16",
    "outputId": "3d284ce5-d35d-429d-fcec-a6a4a427dc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Income generated',\n",
       " 'result': \" Interstellar grossed over $677 million worldwide in 2014 and had additional earnings from subsequent re-releases, totaling approximately $773 million. The film's release utilized both traditional film stock and digital projectors across various venues to maximize its income generation potential.\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.invoke('Income generated')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ads525",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
