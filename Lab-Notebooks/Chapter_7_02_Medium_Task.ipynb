{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Chapter 7 - Medium Tasks</h1>\n",
    "<i>Going beyond prompt engineering.</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI API\n",
    "- This notebook uses OpenAI via LangChain (`ChatOpenAI`).\n",
    "- Set `OPENAI_API_KEY` in your environment before running.\n",
    "- All tasks use `llm`, which is the OpenAI chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API setup\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the API key directly\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"api-key-here\"\n",
    "\n",
    "print(\"API key set\")\n",
    "\n",
    "# Fast model\n",
    "openai_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "# Default LLM for the tasks below\n",
    "llm = openai_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Medium Tasks: Chains</h2>\n",
    "<p>Build simple but powerful chains. Keep it step-by-step and observe how each link changes the output.|</p>\n",
    "\n",
    "<h3>Medium Task 1 - A Single Link: Prompt Template -> LLM</h3>\n",
    "<p>Goal: Make a minimal prompt template and connect it to the OpenAI chat model.</p>\n",
    "<ol>\n",
    "  <li>Create a minimal prompt template.</li>\n",
    "  <li>Connect the template to the chat model as a simple chain.</li>\n",
    "  <li>Invoke the chain with a short input and observe the output.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for chains and prompts\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "# We'll use the OpenAI chat model defined above\n",
    "llm = openai_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Minimal prompt template\n",
    "template = \"{input_prompt}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110123/2165525862.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  basic_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "# Single-link chain (prompt -> LLM)\n",
    "basic_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_prompt': 'Hi! My name is Pat. What is 1 + 1?', 'text': 'Hi Pat! 1 + 1 equals 2.'}\n"
     ]
    }
   ],
   "source": [
    "# Try a tiny warm-up\n",
    "result_basic = basic_chain.invoke({\"input_prompt\": \"Hi! My name is Pat. What is 1 + 1?\"})\n",
    "print(result_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Medium Task 2 - Multiple Links: Title -> Character -> Story</h3>\n",
    "<p>Goal: Break a bigger task into smaller steps (links) and chain them.</p>\n",
    "<ol>\n",
    "  <li>Make a title from a short summary.</li>\n",
    "  <li>Describe the main character using the title + summary.</li>\n",
    "  <li>Write a short story using title + character + summary.</li>\n",
    "</ol>\n",
    "<p>Be playful. Keep each output short so you can see the flow clearly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed summary used across steps\n",
    "summary = \"a sandwich that dreams of becoming a chef\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1: Title</b> — Create a title from the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "title_template = \"Create a catchy title for a story about {summary}. Only return the title.\"\n",
    "title_prompt = PromptTemplate(template=title_template, input_variables=[\"summary\"])\n",
    "title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: \"Chef in the Crust: The Dream of a Culinary Sandwich\"\n"
     ]
    }
   ],
   "source": [
    "step1 = title_chain.invoke({\"summary\": summary})\n",
    "my_title = step1.get(\"title\", step1.get(\"text\", \"\"))\n",
    "print(\"TITLE:\", my_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2: Character</b> — Describe the protagonist using title + summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "character_template = \"Describe the main character of a story about {summary} titled {title}. Use two sentences.\"\n",
    "character_prompt = PromptTemplate(template=character_template, input_variables=[\"summary\", \"title\"])\n",
    "character_chain = LLMChain(llm=llm, prompt=character_prompt, output_key=\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER: The main character, Sammy the Sandwich, is a spirited and ambitious hero made of fresh ingredients, with a zest for life and a passion for culinary creativity. Despite being nestled in a bustling deli, Sammy dreams of escaping the confines of his sandwich board to become a renowned chef, crafting gourmet dishes that tantalize taste buds everywhere.\n"
     ]
    }
   ],
   "source": [
    "step2 = character_chain.invoke({\"summary\": summary, \"title\": my_title})\n",
    "my_character = step2.get(\"character\", step2.get(\"text\", \"\"))\n",
    "print(\"CHARACTER:\", my_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3: Story</b> — Write a short story using title + character + summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "story_template = (\n",
    "    \"Write a very short story (one paragraph) about {summary} with the title {title}. \"\n",
    "    \"The main character is: {character}. \"\n",
    "    \"Only return the story.\"\n",
    ")\n",
    "story_prompt = PromptTemplate(template=story_template, input_variables=[\"summary\", \"title\", \"character\"])\n",
    "story_chain = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORY: **Chef in the Crust: The Dream of a Culinary Sandwich**  \n",
      "\n",
      "Sammy the Sandwich, layered with crisp lettuce, ripe tomatoes, and a hint of zesty mustard, gazed longingly at the bustling kitchen behind the deli counter, where chefs danced with knives and flames, creating culinary masterpieces. Each day, as customers devoured his fellow sandwiches, Sammy's dreams grew bolder; he envisioned himself plating exquisite dishes, transforming simple ingredients into art. With a heart full of ambition and a sprinkle of hope, he plotted his escape, dreaming of a world where he could sprinkle herbs and sauté vegetables, proving that even a humble sandwich could rise to the occasion and become a culinary sensation.\n"
     ]
    }
   ],
   "source": [
    "step3 = story_chain.invoke({\"summary\": summary, \"title\": my_title, \"character\": my_character})\n",
    "my_story = step3.get(\"story\", step3.get(\"text\", \"\"))\n",
    "print(\"STORY:\", my_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reflect</h3>\n",
    "<ul>\n",
    "  <li>How did chaining smaller prompts change the quality of the final story?</li>\n",
    "  <li>What happens if you change the summary to something else?</li>\n",
    "  <li>Try running the chain again and see if you get different results.</li>\n",
    "</ul>\n",
    "<p>If any cell feels slow or costly, use a smaller OpenAI model (e.g., keep <code>gpt-4o-mini</code> or lower temperature) and rerun that section.</p>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ads525",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
