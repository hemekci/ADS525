{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Prompt Engineering - Medium Tasks (Solutions)\n",
    "\n",
    "Complete solutions for all Medium Tasks with filled-in answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Prompt Builder - SOLUTION\n",
    "\n",
    "The key insight is that different components have different impacts. Format and Audience typically matter most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b Solution: Component Impact Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Version 3 with format added\n",
    "v3 = PromptBuilder() \\\n",
    "    .set_instruction(base_task) \\\n",
    "    .set_audience(\"A 12-year-old student\") \\\n",
    "    .set_format(\"1. What it is\\n2. How it spreads\\n3. How to stay safe\") \\\n",
    "    .build()\n",
    "    \n",
    "print(\"\\nVersion 3 (with format):\")\n",
    "print(generate_text(v3, temperature=0, max_tokens=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Answered\n",
    "\n",
    "**1. Which component had the biggest impact on output quality?**\n",
    "\n",
    "Format typically has the biggest impact because it structures the entire response. Audience is second because it directly affects language complexity.\n",
    "\n",
    "**2. How did adding audience change the language used?**\n",
    "\n",
    "With \"12-year-old student\", the model used:\n",
    "- Simpler vocabulary\n",
    "- Shorter sentences\n",
    "- Concrete examples instead of abstract concepts\n",
    "- Avoided technical jargon\n",
    "\n",
    "**3. When would you intentionally omit certain components?**\n",
    "\n",
    "- Simple tasks: Instruction alone may suffice\n",
    "- Creative tasks: Too much structure limits creativity\n",
    "- Token budget: When paying per token, remove least critical components\n",
    "- Exploratory work: Start minimal, add components as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Self-Consistency - SOLUTION\n",
    "\n",
    "Self-consistency improves accuracy on tricky problems by sampling multiple reasoning paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b Solution: Different Sample Counts\n",
    "\n",
    "The bat-and-ball problem is counter-intuitive. More samples help catch the common mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results typically show:\n",
    "# - 3 samples: May get unlucky and miss correct answer\n",
    "# - 5 samples: Usually catches the right answer\n",
    "# - 10 samples: Most reliable, but 2x the cost of 5 samples\n",
    "\n",
    "print(\"Testing different sample counts:\")\n",
    "print(f\"Problem: {tricky_problem['problem']}\")\n",
    "print(f\"Correct answer: {tricky_problem['answer']}\")\n",
    "\n",
    "for n in sample_counts:\n",
    "    majority, _, all_answers = self_consistency_solve(tricky_problem[\"problem\"], num_samples=n)\n",
    "    print(f\"\\n{n} samples: {all_answers}\")\n",
    "    print(f\"Majority: {majority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Answered\n",
    "\n",
    "**1. Which problem benefited most from self-consistency?**\n",
    "\n",
    "The bat-and-ball problem. It's counter-intuitive with a strong wrong intuition ($0.10). Multiple samples help overcome the bias.\n",
    "\n",
    "**2. Did all samples agree? What does disagreement tell you?**\n",
    "\n",
    "- Simple problems: High agreement (all samples get it right)\n",
    "- Tricky problems: More disagreement, showing the problem is genuinely difficult\n",
    "- Disagreement signals you should investigate further or use more samples\n",
    "\n",
    "**3. What is the trade-off of using more samples?**\n",
    "\n",
    "- **Pro**: Higher accuracy, more reliable on difficult problems\n",
    "- **Con**: N times more API calls = N times the cost\n",
    "- **Con**: N times slower (if run sequentially)\n",
    "- **Best practice**: Use self-consistency only for high-stakes or known-difficult problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Constrained JSON Output - SOLUTION\n",
    "\n",
    "JSON constraints guarantee valid structure, which is essential for production applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b Solution: Product Catalog Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Product catalog prompt is already provided, just run it\n",
    "product_prompt = \"\"\"Create a product catalog entry for a laptop:\n",
    "- Brand: TechPro\n",
    "- Model: UltraBook X1\n",
    "- Price: $1299.99\n",
    "- RAM: 16GB\n",
    "- Storage: 512GB SSD\n",
    "- In stock: Yes\n",
    "\n",
    "Return as JSON.\"\"\"\n",
    "\n",
    "output = llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": product_prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "response = output['choices'][0]['message']['content']\n",
    "parsed = json.loads(response)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "\n",
    "# Example output structure:\n",
    "# {\n",
    "#   \"brand\": \"TechPro\",\n",
    "#   \"model\": \"UltraBook X1\",\n",
    "#   \"price\": 1299.99,\n",
    "#   \"specs\": {\n",
    "#     \"ram\": \"16GB\",\n",
    "#     \"storage\": \"512GB SSD\"\n",
    "#   },\n",
    "#   \"in_stock\": true\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Answered\n",
    "\n",
    "**1. Why is guaranteed JSON output important for applications?**\n",
    "\n",
    "- **No parsing errors**: Can safely call `json.loads()` without try/except\n",
    "- **Reliable integration**: Other services can consume the output\n",
    "- **Type safety**: Know what fields to expect\n",
    "- **Production-ready**: No need to handle malformed responses\n",
    "\n",
    "**2. What happens if you request fields the model cannot infer from the prompt?**\n",
    "\n",
    "The model may:\n",
    "- Generate placeholder values (\"N/A\", \"Unknown\")\n",
    "- Omit the field entirely\n",
    "- Hallucinate reasonable-sounding but incorrect data\n",
    "\n",
    "**Best practice**: Only request fields that can be inferred from the input.\n",
    "\n",
    "**3. How would you handle optional vs required fields?**\n",
    "\n",
    "```python\n",
    "required_fields = [\"brand\", \"model\", \"price\"]\n",
    "optional_fields = [\"warranty\", \"color_options\"]\n",
    "\n",
    "# Validate required\n",
    "valid, message = validate_schema(parsed, required_fields)\n",
    "if not valid:\n",
    "    raise ValueError(message)\n",
    "\n",
    "# Provide defaults for optional\n",
    "parsed.setdefault(\"warranty\", \"1 year\")\n",
    "parsed.setdefault(\"color_options\", [])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Prompt Optimization - SOLUTION\n",
    "\n",
    "Systematic optimization: baseline → add definitions → add examples → measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Version 3 is already implemented\n",
    "\n",
    "The task notebook already provides V3 with examples. Students just need to run and observe the improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V3 already has good examples:\n",
    "# - \"I can't access my account and think it's been compromised\" → high\n",
    "# - \"I was charged for a subscription I cancelled\" → medium  \n",
    "# - \"Do you ship internationally?\" → low\n",
    "\n",
    "# These examples cover:\n",
    "# 1. Security issue (high urgency)\n",
    "# 2. Billing problem (medium urgency)\n",
    "# 3. Information request (low urgency)\n",
    "\n",
    "# The examples help the model learn the pattern:\n",
    "# - Security + account access = high\n",
    "# - Money + not urgent deadline = medium\n",
    "# - Questions without issues = low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions Answered\n",
    "\n",
    "**1. Which improvement (definitions or examples) had a bigger impact?**\n",
    "\n",
    "Typically:\n",
    "- **Definitions**: 10-20% improvement (clarifies boundaries)\n",
    "- **Examples**: Additional 5-15% improvement (shows the pattern)\n",
    "- **Combined**: Best results, 20-30% total improvement\n",
    "\n",
    "Definitions usually have more impact because they explicitly state the criteria.\n",
    "\n",
    "**2. Are there tickets that all versions got wrong? What makes them difficult?**\n",
    "\n",
    "Difficult cases:\n",
    "- Borderline urgency (medium vs low)\n",
    "- Context-dependent urgency (\"site is down\" - high for business, low for personal)\n",
    "- Multiple issues in one ticket (billing + security)\n",
    "- Vague language (\"having problems\" - what kind?)\n",
    "\n",
    "**3. What would you try next to improve further?**\n",
    "\n",
    "- **More diverse examples**: Cover edge cases and ambiguous tickets\n",
    "- **Chain-of-Thought**: Ask model to explain its reasoning\n",
    "- **Self-consistency**: Sample multiple classifications for borderline cases\n",
    "- **Refine definitions**: Based on failure analysis\n",
    "- **Add context**: Time of day, customer tier, SLA requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **PromptBuilder**: Format and Audience components have the biggest impact\n",
    "2. **Self-Consistency**: Use multiple samples for tricky problems, but balance cost\n",
    "3. **JSON Constraints**: Essential for production applications that consume LLM output\n",
    "4. **Optimization**: Systematic testing with definitions + examples yields 20-30% improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
