{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Prompt Engineering - Medium Tasks (Solutions)\n\nComplete solutions matching task structure exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run all cells in this section to set up the environment and load the model.\n",
    "\n",
    "Before running these cells, review the concepts from the main Chapter 6 notebook (00_Start_Here.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] - Installing Packages on Google Colab",
    "",
    "If you are viewing this notebook on Google Colab, uncomment and run the following code to install dependencies.",
    "",
    "**Note**: Use a GPU for this notebook. In Google Colab, go to Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# %%capture\n# !pip install --upgrade transformers>=4.40.0 torch accelerate\n# !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_path = \"microsoft/Phi-3-mini-4k-instruct\"",
    "",
    "model = AutoModelForCausalLM.from_pretrained(",
    "    model_path,",
    "    device_map=\"cuda\",",
    "    torch_dtype=\"auto\",",
    "    trust_remote_code=False,",
    ")",
    "",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def generate_text(prompt, temperature=0.7, max_tokens=300):\n",
    "    \"\"\"Generate text with specified parameters\"\"\"\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True if temperature > 0 else False,\n",
    "        temperature=temperature if temperature > 0 else None,\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    output = pipe(messages)\n",
    "    return output[0]['generated_text']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "Complete the following tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About This Task:**\n",
    "Building production prompts requires assembling components dynamically based on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medium Task 1: Prompt Builder\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run the PromptBuilder to see how components are assembled\n",
    "2. Create different prompts by setting different components\n",
    "3. Test removing individual components to see their impact\n",
    "4. Build prompts for different scenarios (instructions, explanations, translations)\n",
    "5. Compare outputs with different component combinations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class PromptBuilder:\n",
    "    \"\"\"Build structured prompts with all 7 components\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.persona = None\n",
    "        self.instruction = None\n",
    "        self.context = None\n",
    "        self.format_spec = None\n",
    "        self.audience = None\n",
    "        self.tone = None\n",
    "        self.data = None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    def set_persona(self, persona):\n",
    "        self.persona = persona\n",
    "        return self\n",
    "    \n",
    "    def set_instruction(self, instruction):\n",
    "        self.instruction = instruction\n",
    "        return self\n",
    "    \n",
    "    def set_context(self, context):\n",
    "        self.context = context\n",
    "        return self\n",
    "    \n",
    "    def set_format(self, format_spec):\n",
    "        self.format_spec = format_spec\n",
    "        return self\n",
    "    \n",
    "    def set_audience(self, audience):\n",
    "        self.audience = audience\n",
    "        return self\n",
    "    \n",
    "    def set_tone(self, tone):\n",
    "        self.tone = tone\n",
    "        return self\n",
    "    \n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        return self"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    def build(self):\n",
    "        \"\"\"Assemble the complete prompt\"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        if self.persona:\n",
    "            parts.append(f\"You are {self.persona}.\")\n",
    "        \n",
    "        if self.instruction:\n",
    "            parts.append(f\"\\nYour task: {self.instruction}\")\n",
    "        \n",
    "        if self.context:\n",
    "            parts.append(f\"\\nContext: {self.context}\")\n",
    "        \n",
    "        if self.format_spec:\n",
    "            parts.append(f\"\\nFormat:\\n{self.format_spec}\")\n",
    "        \n",
    "        if self.audience:\n",
    "            parts.append(f\"\\nAudience: {self.audience}\")\n",
    "        \n",
    "        if self.tone:\n",
    "            parts.append(f\"\\nTone: {self.tone}\")\n",
    "        \n",
    "        if self.data:\n",
    "            parts.append(f\"\\nData to work with:\\n{self.data}\")\n",
    "        \n",
    "        return \"\".join(parts)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the build method to the class. Run this to fix that:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "PromptBuilder.build = build"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: Responding to a complaint"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "complaint_prompt = PromptBuilder() \\\n",
    "    .set_persona(\"a helpful customer service representative\") \\\n",
    "    .set_instruction(\"Respond to this customer complaint\") \\\n",
    "    .set_context(\"The customer has been waiting 2 weeks for a refund\") \\\n",
    "    .set_format(\"1. Acknowledge\\n2. Apologize\\n3. Solution\") \\\n",
    "    .set_audience(\"A frustrated customer\") \\\n",
    "    .set_tone(\"Professional and empathetic\") \\\n",
    "    .set_data(\"Customer: Sarah\\nOrder: 12345\\nAmount: $89.99\") \\\n",
    "    .build()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(complaint_prompt)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output = generate_text(complaint_prompt, temperature=0, max_tokens=200)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Explaining a concept\n",
    "\n",
    "Your task: Build a prompt for explaining how email works to someone unfamiliar with technology."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explanation_prompt = PromptBuilder() \\\n",
    "    .set_persona(\"a patient technology teacher\") \\\n",
    "    .set_instruction(\"Explain how email works\") \\\n",
    "    .set_context(\"The person has never used email before\") \\\n",
    "    .set_format(\"1. What it is\\n2. How to use it\\n3. Simple analogy\") \\\n",
    "    .set_audience(\"Someone unfamiliar with technology\") \\\n",
    "    .set_tone(\"Simple and encouraging\") \\\n",
    "    .build()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(explanation_prompt)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output = generate_text(explanation_prompt, temperature=0, max_tokens=200)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b: Component Impact Test\n",
    "\n",
    "Test what happens when you remove different components."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_task = \"Explain what a computer virus is\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1: Instruction only"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "v1 = PromptBuilder().set_instruction(base_task).build()\n",
    "print(\"Version 1 (instruction only):\")\n",
    "print(generate_text(v1, temperature=0, max_tokens=150))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2: Add audience"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "v2 = PromptBuilder() \\\n",
    "    .set_instruction(base_task) \\\n",
    "    .set_audience(\"A 12-year-old student\") \\\n",
    "    .build()\n",
    "print(\"\\nVersion 2 (with audience):\")\n",
    "print(generate_text(v2, temperature=0, max_tokens=150))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 3: Add format\n",
    "\n",
    "Your task: Add a format specification to structure the output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "v3 = PromptBuilder() \\\n",
    "    .set_instruction(base_task) \\\n",
    "    .set_audience(\"A 12-year-old student\") \\\n",
    "    .set_format(\"1. What it is\\n2. How it spreads\\n3. How to stay safe\") \\\n",
    "    .build()\n",
    "print(\"\\nVersion 3 (with format):\")\n",
    "print(generate_text(v3, temperature=0, max_tokens=200))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Which component had the biggest impact on output quality?\n",
    "\n",
    "2. How did adding audience change the language used?\n",
    "\n",
    "3. When would you intentionally omit certain components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About This Task:**\n",
    "Self-consistency improves reliability by sampling multiple reasoning paths and taking the majority answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medium Task 2: Self-Consistency\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run single CoT to see baseline performance\n",
    "2. Run self-consistency with 5 samples to see multiple reasoning paths\n",
    "3. Test with different sample counts (3, 5, 10)\n",
    "4. Try different temperature values\n",
    "5. Identify which problems benefit most from multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_problems = [\n",
    "    {\n",
    "        \"problem\": \"A bill is $80. You want to leave a 20% tip. What is the total?\",\n",
    "        \"answer\": 96\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"If 5 machines make 5 widgets in 5 minutes, how long for 100 machines to make 100 widgets?\",\n",
    "        \"answer\": 5\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much is the ball?\",\n",
    "        \"answer\": 0.05\n",
    "    },\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single CoT Reasoning\n\nFirst we solve each problem with a single chain-of-thought."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Single CoT: A bill is $80. You want to leave a 20% tip. What i...",
    "tip_problem = \"A bill is $80. You want to leave a 20% tip. What is the total?\"",
    "tip_problem_correct = 96",
    "",
    "prompt = f\"\"\"{tip_problem}",
    "",
    "Let's think step-by-step:\"\"\"",
    "",
    "answer = generate_text(prompt, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\nProblem: {tip_problem}\")",
    "print(f\"Answer: {answer}\")",
    "print(f\"Correct: {tip_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Single CoT: Sarah is twice as old as her son. Her son is 12. H...",
    "age_problem = \"Sarah is twice as old as her son. Her son is 12. How old is Sarah?\"",
    "age_problem_correct = 24",
    "",
    "prompt = f\"\"\"{age_problem}",
    "",
    "Let's think step-by-step:\"\"\"",
    "",
    "answer = generate_text(prompt, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\nProblem: {age_problem}\")",
    "print(f\"Answer: {answer}\")",
    "print(f\"Correct: {age_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Single CoT: A $50 item is on sale for 30% off. What is the sal...",
    "discount_problem = \"A $50 item is on sale for 30% off. What is the sale price?\"",
    "discount_problem_correct = 35",
    "",
    "prompt = f\"\"\"{discount_problem}",
    "",
    "Let's think step-by-step:\"\"\"",
    "",
    "answer = generate_text(prompt, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\nProblem: {discount_problem}\")",
    "print(f\"Answer: {answer}\")",
    "print(f\"Correct: {discount_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def single_cot_solve(problem):\n",
    "    prompt = f\"{problem}\\n\\nLet's think step-by-step:\"\n",
    "    return generate_text(prompt, temperature=0, max_tokens=200)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Single CoT Reasoning:\")\n",
    "for item in test_problems:\n",
    "    problem = item[\"problem\"]\n",
    "    correct = item[\"answer\"]\n",
    "    output = single_cot_solve(problem)\n",
    "    print(f\"\\nProblem: {problem}\")\n",
    "    print(f\"Correct: {correct}\")\n",
    "    print(f\"Reasoning: {output}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Self-Consistency: A bill is $80. You want to leave a 20% tip. What i...",
    "majority, vote_counts, all_answers = self_consistency_solve(tip_problem, num_samples=5, temperature=0.7)",
    "",
    "print(f\"\\nProblem: {tip_problem}\")",
    "print(f\"Majority answer: {majority}\")",
    "print(f\"Vote distribution: {vote_counts}\")",
    "print(f\"All 5 answers: {all_answers}\")",
    "print(f\"Correct: {tip_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Self-Consistency: Sarah is twice as old as her son. Her son is 12. H...",
    "majority, vote_counts, all_answers = self_consistency_solve(age_problem, num_samples=5, temperature=0.7)",
    "",
    "print(f\"\\nProblem: {age_problem}\")",
    "print(f\"Majority answer: {majority}\")",
    "print(f\"Vote distribution: {vote_counts}\")",
    "print(f\"All 5 answers: {all_answers}\")",
    "print(f\"Correct: {age_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Self-Consistency: A $50 item is on sale for 30% off. What is the sal...",
    "majority, vote_counts, all_answers = self_consistency_solve(discount_problem, num_samples=5, temperature=0.7)",
    "",
    "print(f\"\\nProblem: {discount_problem}\")",
    "print(f\"Majority answer: {majority}\")",
    "print(f\"Vote distribution: {vote_counts}\")",
    "print(f\"All 5 answers: {all_answers}\")",
    "print(f\"Correct: {discount_problem_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def self_consistency_solve(problem, num_samples=5, temperature=0.7):\n",
    "    \"\"\"Solve using self-consistency\"\"\"\n",
    "    prompt = f\"{problem}\\n\\nLet's think step-by-step:\"\n",
    "    \n",
    "    reasoning_paths = []\n",
    "    answers = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        output = generate_text(prompt, temperature=temperature, max_tokens=200)\n",
    "        reasoning_paths.append(output)\n",
    "        \n",
    "        answer = extract_answer(output)\n",
    "        if answer is not None:\n",
    "            answers.append(answer)\n",
    "    \n",
    "    if not answers:\n",
    "        return None, reasoning_paths, []\n",
    "    \n",
    "    answer_counts = Counter(answers)\n",
    "    majority_answer = answer_counts.most_common(1)[0][0]\n",
    "    \n",
    "    return majority_answer, reasoning_paths, answers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Self-Consistency (5 samples):\")\n",
    "for item in test_problems:\n",
    "    problem = item[\"problem\"]\n",
    "    correct = item[\"answer\"]\n",
    "    \n",
    "    majority, paths, all_answers = self_consistency_solve(problem, num_samples=5)\n",
    "    \n",
    "    print(f\"\\nProblem: {problem}\")\n",
    "    print(f\"Correct: {correct}\")\n",
    "    print(f\"All answers: {all_answers}\")\n",
    "    print(f\"Majority: {majority}\")\n",
    "    \n",
    "    if paths:\n",
    "        print(f\"Example reasoning: {paths[0][:150]}...\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b: Test Different Sample Counts\n",
    "\n",
    "Your task: Try different numbers of samples and see how it affects reliability."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tricky_problem = test_problems[2]\n",
    "sample_counts = [3, 5, 10]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Testing different sample counts:\")\n",
    "print(f\"Problem: {tricky_problem['problem']}\")\n",
    "print(f\"Correct answer: {tricky_problem['answer']}\")\n",
    "\n",
    "for n in sample_counts:\n",
    "    majority, _, all_answers = self_consistency_solve(tricky_problem[\"problem\"], num_samples=n)\n",
    "    print(f\"\\n{n} samples: {all_answers}\")\n",
    "    print(f\"Majority: {majority}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Which problem benefited most from self-consistency?\n",
    "\n",
    "2. Did all samples agree? What does disagreement tell you?\n",
    "\n",
    "3. What is the trade-off of using more samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About This Task:**\n",
    "Constrained generation forces the model to output valid JSON, which is critical for applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medium Task 3: Constrained JSON Output\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run without constraints to see free-form output\n",
    "2. Apply JSON constraints to guarantee valid output\n",
    "3. Test different data structures (user profiles, products, events)\n",
    "4. Create prompts that request specific JSON schemas\n",
    "5. Handle validation of required fields"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from llama_cpp import Llama\n",
    "import json"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "    filename=\"*fp16.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=2048,\n",
    "    verbose=False\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Constraints"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prompt = \"\"\"Create a user profile for a software engineer:\n",
    "- Name: Alex Johnson\n",
    "- Age: 28\n",
    "- Skills: Python, Machine Learning\n",
    "- Experience: 5 years\n",
    "\n",
    "Return as JSON.\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output = llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0,\n",
    "    max_tokens=300\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = output['choices'][0]['message']['content']\n",
    "print(\"Without constraints:\")\n",
    "print(response)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    parsed = json.loads(response)\n",
    "    print(\"\\nValid JSON\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nInvalid JSON: {e}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With JSON Constraints"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output = llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0,\n",
    "    max_tokens=300\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = output['choices'][0]['message']['content']\n",
    "print(\"With constraints:\")\n",
    "print(response)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    parsed = json.loads(response)\n",
    "    print(\"\\nValid JSON\")\n",
    "    print(\"\\nFields:\")\n",
    "    for key, value in parsed.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nInvalid JSON: {e}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def validate_schema(data, required_fields):\n",
    "    \"\"\"Check if JSON contains required fields\"\"\"\n",
    "    missing = []\n",
    "    \n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            missing.append(field)\n",
    "    \n",
    "    if missing:\n",
    "        return False, f\"Missing fields: {', '.join(missing)}\"\n",
    "    return True, \"Valid schema\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "user_schema = [\"name\", \"age\", \"skills\", \"years_of_experience\"]\n",
    "valid, message = validate_schema(parsed, user_schema)\n",
    "print(f\"\\nSchema validation: {message}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b: Different Data Structures\n",
    "\n",
    "Your task: Create a prompt that generates a product catalog entry as JSON."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "product_prompt = \"\"\"Create a product catalog entry for a laptop:\n",
    "- Brand: TechPro\n",
    "- Model: UltraBook X1\n",
    "- Price: $1299.99\n",
    "- RAM: 16GB\n",
    "- Storage: 512GB SSD\n",
    "- In stock: Yes\n",
    "\n",
    "Return as JSON.\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output = llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": product_prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0,\n",
    "    max_tokens=300\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = output['choices'][0]['message']['content']\n",
    "parsed = json.loads(response)\n",
    "print(json.dumps(parsed, indent=2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Why is guaranteed JSON output important for applications?\n",
    "\n",
    "2. What happens if you request fields the model cannot infer from the prompt?\n",
    "\n",
    "3. How would you handle optional vs required fields?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About This Task:**\n",
    "Systematic optimization means testing variations, measuring performance, and iterating to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medium Task 4: Prompt Optimization\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run baseline prompt to see initial performance\n",
    "2. Create improved versions with definitions and examples\n",
    "3. Test each version on the same evaluation set\n",
    "4. Measure accuracy to quantify improvements\n",
    "5. Analyze which improvements had the biggest impact"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_tickets = [\n",
    "    {\"text\": \"My account has been hacked! Someone is making purchases\", \"urgency\": \"high\"},\n",
    "    {\"text\": \"How do I change my password?\", \"urgency\": \"low\"},\n",
    "    {\"text\": \"I've been trying to log in for 2 hours, site is down\", \"urgency\": \"high\"},\n",
    "    {\"text\": \"What are your business hours?\", \"urgency\": \"low\"},\n",
    "    {\"text\": \"I was charged twice for my order\", \"urgency\": \"medium\"},\n",
    "    {\"text\": \"Can you recommend a product?\", \"urgency\": \"low\"},\n",
    "    {\"text\": \"Payment failing and order deadline is today\", \"urgency\": \"high\"},\n",
    "    {\"text\": \"Update my shipping address\", \"urgency\": \"medium\"},\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Basic Prompt\n\nTest the basic classifier on all tickets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V1: My account has been hacked! Someone is making purc...",
    "ticket1_text = \"My account has been hacked! Someone is making purchases\"",
    "ticket1_urgency = \"high\"",
    "",
    "prediction = classify_urgency_v1(ticket1_text)",
    "correct = \"✓\" if prediction.lower() == ticket1_urgency else \"✗\"",
    "print(f\"ticket1: {ticket1_text[:50]}... -> {prediction} {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V1: I was charged for a subscription I cancelled last ...",
    "ticket2_text = \"I was charged for a subscription I cancelled last month\"",
    "ticket2_urgency = \"medium\"",
    "",
    "prediction = classify_urgency_v1(ticket2_text)",
    "correct = \"✓\" if prediction.lower() == ticket2_urgency else \"✗\"",
    "print(f\"ticket2: {ticket2_text[:50]}... -> {prediction} {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V1: Do you ship internationally?...",
    "ticket3_text = \"Do you ship internationally?\"",
    "ticket3_urgency = \"low\"",
    "",
    "prediction = classify_urgency_v1(ticket3_text)",
    "correct = \"✓\" if prediction.lower() == ticket3_urgency else \"✗\"",
    "print(f\"ticket3: {ticket3_text[:50]}... -> {prediction} {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V1: The product arrived damaged...",
    "ticket4_text = \"The product arrived damaged\"",
    "ticket4_urgency = \"medium\"",
    "",
    "prediction = classify_urgency_v1(ticket4_text)",
    "correct = \"✓\" if prediction.lower() == ticket4_urgency else \"✗\"",
    "print(f\"ticket4: {ticket4_text[:50]}... -> {prediction} {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V1: I can't log in to my account...",
    "ticket5_text = \"I can't log in to my account\"",
    "ticket5_urgency = \"medium\"",
    "",
    "prediction = classify_urgency_v1(ticket5_text)",
    "correct = \"✓\" if prediction.lower() == ticket5_urgency else \"✗\"",
    "print(f\"ticket5: {ticket5_text[:50]}... -> {prediction} {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: With Definitions\n\nTest the improved classifier with definitions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V2: My account has been hacked! Someone is making purc...",
    "prediction_v2 = classify_urgency_v2(ticket1_text)",
    "correct_v2 = \"✓\" if prediction_v2.lower() == ticket1_urgency else \"✗\"",
    "print(f\"ticket1: {ticket1_text[:50]}... -> {prediction_v2} {correct_v2}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V2: I was charged for a subscription I cancelled last ...",
    "prediction_v2 = classify_urgency_v2(ticket2_text)",
    "correct_v2 = \"✓\" if prediction_v2.lower() == ticket2_urgency else \"✗\"",
    "print(f\"ticket2: {ticket2_text[:50]}... -> {prediction_v2} {correct_v2}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V2: Do you ship internationally?...",
    "prediction_v2 = classify_urgency_v2(ticket3_text)",
    "correct_v2 = \"✓\" if prediction_v2.lower() == ticket3_urgency else \"✗\"",
    "print(f\"ticket3: {ticket3_text[:50]}... -> {prediction_v2} {correct_v2}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V2: The product arrived damaged...",
    "prediction_v2 = classify_urgency_v2(ticket4_text)",
    "correct_v2 = \"✓\" if prediction_v2.lower() == ticket4_urgency else \"✗\"",
    "print(f\"ticket4: {ticket4_text[:50]}... -> {prediction_v2} {correct_v2}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V2: I can't log in to my account...",
    "prediction_v2 = classify_urgency_v2(ticket5_text)",
    "correct_v2 = \"✓\" if prediction_v2.lower() == ticket5_urgency else \"✗\"",
    "print(f\"ticket5: {ticket5_text[:50]}... -> {prediction_v2} {correct_v2}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3: With Examples\n\nTest the fully optimized classifier with examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V3: My account has been hacked! Someone is making purc...",
    "prediction_v3 = classify_urgency_v3(ticket1_text)",
    "correct_v3 = \"✓\" if prediction_v3.lower() == ticket1_urgency else \"✗\"",
    "print(f\"ticket1: {ticket1_text[:50]}... -> {prediction_v3} {correct_v3}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V3: I was charged for a subscription I cancelled last ...",
    "prediction_v3 = classify_urgency_v3(ticket2_text)",
    "correct_v3 = \"✓\" if prediction_v3.lower() == ticket2_urgency else \"✗\"",
    "print(f\"ticket2: {ticket2_text[:50]}... -> {prediction_v3} {correct_v3}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V3: Do you ship internationally?...",
    "prediction_v3 = classify_urgency_v3(ticket3_text)",
    "correct_v3 = \"✓\" if prediction_v3.lower() == ticket3_urgency else \"✗\"",
    "print(f\"ticket3: {ticket3_text[:50]}... -> {prediction_v3} {correct_v3}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V3: The product arrived damaged...",
    "prediction_v3 = classify_urgency_v3(ticket4_text)",
    "correct_v3 = \"✓\" if prediction_v3.lower() == ticket4_urgency else \"✗\"",
    "print(f\"ticket4: {ticket4_text[:50]}... -> {prediction_v3} {correct_v3}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# V3: I can't log in to my account...",
    "prediction_v3 = classify_urgency_v3(ticket5_text)",
    "correct_v3 = \"✓\" if prediction_v3.lower() == ticket5_urgency else \"✗\"",
    "print(f\"ticket5: {ticket5_text[:50]}... -> {prediction_v3} {correct_v3}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Which improvement (definitions or examples) had a bigger impact?\n",
    "\n",
    "2. Are there tickets that all versions got wrong? What makes them difficult?\n",
    "\n",
    "3. What would you try next to improve further?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}