{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRzqIWcNhapW"
   },
   "source": [
    "# Chapter 6: Prompt Engineering - Easy Tasks (Solutions)\n\nComplete solutions with all answers filled in. This notebook has the same structure as the task notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-G7sDQehapZ"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run all cells in this section to set up the environment and load the model.\n",
    "\n",
    "Before running these cells, review the concepts from the main Chapter 6 notebook (00_Start_Here.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krjc07zphapa"
   },
   "source": [
    "### [Optional] - Installing Packages on Google Colab",
    "",
    "If you are viewing this notebook on Google Colab, uncomment and run the following code to install dependencies.",
    "",
    "**Note**: Use a GPU for this notebook. In Google Colab, go to Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_rg-7L4bhapc"
   },
   "source": [
    "%%capture\n",
    "!pip install transformers>=4.40.0 torch accelerate"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckF6KJOUhape"
   },
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b-keCkFYhapf"
   },
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NlwLNGmThapg",
    "outputId": "8cac4d56-54b7-421d-ba87-66bde80745c4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545,
     "referenced_widgets": [
      "339e5d68463f4f1e95f539196467cf31",
      "8736989445724c2e8b07937c681bcf17",
      "557c0834762445968cc7a6e5e881ef3e",
      "892a2de84d794d9aaab34cd91f834335",
      "05218d2b974e438bb158f50da40017c7",
      "c99c3da30a6947759134725b4b28cddb",
      "13a8e1c1d1f443daa93c71596ac254b5",
      "f862d9b8053c4e9ea19be435edff3999",
      "858aace480dd4811be3fca75e1364284",
      "ef277020e8e04ce4b299c4b920adf87a",
      "f038664a78674f72a41239870021adce",
      "10dc4f58a57b460fa03ba44463d45b5f",
      "16f7b316b10c4ebeb8c61e475f8b252f",
      "95c7ba8bfa65419e9fcb1c08c5c500d8",
      "3108bd17bc76411cbcd6115bdc998896",
      "6a61d9e650d54182829f6698df30e16f",
      "e7c301703ff44f54afde2639400f3640",
      "b98cbc3ed51647cfb3ad98db5359354b",
      "25576ac11b4e4cefab8f9e075ba34482",
      "b726aa2f241342ff908ca7b6a80eb9c6",
      "d63218a903354825af6505b6a6223d8d",
      "7705d7f1db61432490c65dc4f446ac3f",
      "2f9601d2f93346c78b8ffae5681baafe",
      "88bb652cc472414f9f17b046e96cf0b1",
      "266254dbb2944dc9a477083a9727a61d",
      "b47212c566954b41b5a4cef1ad338544",
      "f7a5d07ddf404e08873bd226b64caba3",
      "4d2cddba17074b27940ff45b48559081",
      "8d4c3dfb40fd420b8afcaa4137c379d6",
      "54dcbcd6c3644a00ac1acb70ecb5441a",
      "3f94a3c2db0e4ec197c9f76424680653",
      "cc2229844fd141df85b1b9258b4d3bf7",
      "b028a64624c649dfaeb52731c9651f70",
      "f5ad2fe5162f4ee89e29c0566487b194",
      "6c86da122a424b51b6d7b872d8779dde",
      "7dfc2290a4bd4fa0a46cb697ec87448b",
      "74d0b41ef7e14c9ea08b2cc9364a0026",
      "3d835f1f556740e6bc79171152e50e93",
      "55463612374e42b18eee2599b7e988ff",
      "eb1c4ea4e6b24aff85df487ab89263f3",
      "67d1fd7dcadb43a4b7bd3ba50a2ee732",
      "50d4b0190d1f44feb3cb2dea939f4670",
      "4732794f126144fcac9755ce4b145d03",
      "e541f185df704c0da7635e2671993f66",
      "1b86925154414c68a0d5a6ffbb970b47",
      "33d265f840a64e409c535f92b661e86a",
      "28dd2274231e417a8311723e51770eb2",
      "638b3da948ee4ae9a5886b34b6c82b0b",
      "4429a8e15c514c958ce2277f304ba40a",
      "a7953d2bc5e741938f1e0cec2ff574a6",
      "5057e83fc23745e58e1aa684c1b229c9",
      "ac405df6627c4c6ea60f1dd400bac855",
      "64bdc0c5c23046e5880f880b38dbd55f",
      "ad0801c5698a4b729742e28cb44bd920",
      "35940d2e48f54f8db6e890bed38f0943",
      "63d1eb80b91e4f36af3f78e824027a44",
      "82a6c3b21c5b43c2bc3800be8ebcb7c7",
      "0aa7cf37ae2640d598787068104f362d",
      "81e7d54f80fc4b0695827f7a812b6a2e",
      "c2267ffc9467405daa14e4c3ba37949c",
      "6fd35c4a30c74f9781a7aad356e32482",
      "f29ad15928e24a6e99be4d6c5a971900",
      "892bfa4283524afcaa05719e353e2dab",
      "537b06933a1b4aeb871dbbc79d357600",
      "017bf15360fa47b9b49ce6e56d1cd0f6",
      "ddb92fe9b1ee4e34b361dfe0d36339b4",
      "41c497eabd8e4f22b2286a0c41d2ef04",
      "935635787c7647ffb84d52a304900ad5",
      "c05501d77f814c55a1a0e2e011e23c52",
      "8d7163c1444e4b8d9aeda007b14f3c19",
      "8b29732c19a04231a82008878ff184b2",
      "def68d4f72b94f109e96d780fe6e9c68",
      "5357b18caff1420ba9aa58c2d5a44223",
      "7d7409b683d747439a054ef4d30426d2",
      "7b6e61d02bdc4b0ca8ec56f629c2248f",
      "f1f37e59486e43689dc7d2dc11ac6a4f",
      "c2a4f34266334ac4b3354a71b637b400",
      "6cd3fb59c9ef4ec1b537cf1777e9510f",
      "45b094cfe7e941fda00fba49435f761a",
      "ac247f4d833041eb8ae42911c840843b",
      "abc52a37d7fe4f0aa49c02188c151ca0",
      "511577c1460c4c42baefb84bf5905d91",
      "b931ad9b93294f098cda432b5f8c09b7",
      "84b747c5de304e128efc93acfd1cefac",
      "fe581f4d9f6d4eb5b36e30c8d4df9426",
      "743bc9c263054b5eac87834b7f24dd9d",
      "e3b81716487b4617aa97fbce98a435c9",
      "ee0d954d7c884a4094351b412e8c7330",
      "60852d51d47c4fa5b28198bd87c45161",
      "28df7f168466402095a0d0546ad28689",
      "a665d26c53254467a438567c81f25579",
      "7e528a9baf69412aab74185fe9400981",
      "264a99eb43394db69d9d6d58c7ab8ff9",
      "5d826b61f4d54377a1e1c5746c3a09b3",
      "465fa59da29d44e3ba82d4f8d20aef4d",
      "64dae89482204884a14705c2bacf8d47",
      "37d4b34ed76946359a5bc1a46f36d69e",
      "d03b09a2b509421f940032c9e6269f30",
      "471bb3b3c73f4086a1997cf3207977d9",
      "50e5b3e3beaf4fb3bd7f92d27eb0d83e",
      "eea824957ec14e52bdea070ffb31c682",
      "4151c8725246413f8cb2689686988c9d",
      "ed54bae6a227424bad2448b355bdc9a8",
      "6d58d5a2005e432fa35e305400fe6a4a",
      "101d9e25d26f480092f7df0aab8c2300",
      "7a80b662a3fc4b53a20078877db80bfd",
      "55eb90ce839b4e3b9ca54faa1aa46afa",
      "2c643367b0c34eacb1739f426f245b29",
      "117fc6bfcba1415d9b51dd63cfb7e6c9",
      "405a02d644524198b6da3a6e445d7bbb",
      "4a17dd68eb9a4d04a9f8c222279ca43a",
      "3f946f90f1d04a43a03fad2f2e88b094",
      "fc68b02f01bf4e89974bf2b544ea4da1",
      "72cfb03df9b148a6af25b2bf91aae478",
      "125d3e7bec2841138d2954ea05dfcd57",
      "99112dc481d44a929643094486eabd00",
      "df8b8d34af5f43d693af20339bbf43e8",
      "a034e93145b54c628c9352d95e1ebd02",
      "f08ae7839db34d2798ab1f33bf51a4e8",
      "0323a137d7574dd5bb53fda3907cc79f",
      "9ab16391afac4cd1883ab2a313341347",
      "74ccc032950c4b32a55fb37fa9e181c6",
      "9f41f1812a524440acaa34bbf9ef2aed",
      "f1fce6ea144d49e49de26599e3e0995f",
      "328f27953db14a14963ff3e0a8671152",
      "3ea7545a08ee44bcb26c31cfad245623",
      "24c526ae699544ba9b3e576dd990370c",
      "83440b0bec1c4d12ad421c75129b9ca8",
      "2f099979142f41d195c05768706123b0",
      "e279f8da71af41a0a6aa8f3f67928cc1",
      "f4afb0f2ee794b2a8ed72fe1365527e2",
      "4b107b1b445e4c23af8486a4c33c08f8"
     ]
    }
   },
   "source": [
    "model_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PBa4AhDhapi"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d1Lw2uFUhapj"
   },
   "source": [
    "def generate_text(prompt, temperature=0.7, max_tokens=200):\n",
    "    \"\"\"Generate text with specified parameters\"\"\"\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True if temperature > 0 else False,\n",
    "        temperature=temperature if temperature > 0 else None,\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    output = pipe(messages)\n",
    "    return output[0]['generated_text']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZ72a1jQhapm"
   },
   "source": [
    "## Challenges\n",
    "\n",
    "Complete the following tasks by implementing the starter code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq9Gs_vPhapo"
   },
   "source": [
    "### Level: Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEyqqpbZhapp"
   },
   "source": [
    "**About This Task:**\n",
    "Temperature controls randomness in generation. Lower values give consistent outputs, higher values give varied outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK0A8Dorhapq"
   },
   "source": [
    "#### Easy Task 1: Finding the Right Temperature\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Execute code to compare temperature effects on three use cases\n",
    "2. Fill in missing temperature values based on your observations\n",
    "3. Run determinism test to verify temperature=0 consistency\n",
    "4. Test with your own prompts\n",
    "5. Analyze which temperatures work best for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p_YJQylfhapu"
   },
   "source": [
    "temperatures = [0.0, 0.3, 0.7, 1.0, 1.5, 4.0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSjyRB3Uhapv"
   },
   "source": [
    "Notice how different temperatures affect each use case."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HS7i-jUAhapv",
    "outputId": "2dd1c554-3c46-4303-8eec-c3d2493d3ca5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Factual: What is the capital city of France?\n",
    "prompt1 = \"What is the capital city of France?\"\n",
    "print(f\"Prompt 1: {prompt1}\")\n",
    "for temp in temperatures:\n",
    "  output = generate_text(prompt1, temperature=temp, max_tokens=50)\n",
    "  print(f\"Temp={temp}: {output}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cn5GK5WOoKy6",
    "outputId": "50cef860-baa2-406a-b9bf-8473adc4e342",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Creative: Write the first sentence of a romance novel.\n",
    "prompt2 = \"Write the first sentence of a romance novel.\"\n",
    "print(f\"Prompt 2: {prompt2}\")\n",
    "for temp in temperatures:\n",
    "  output = generate_text(prompt2, temperature=temp, max_tokens=50)\n",
    "  print(f\"Temp={temp}: {output}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uMj2GV0Eo-A1",
    "outputId": "86826228-683c-46b0-d029-5b3947998d97",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Math: \"What is the square root of 10000?\"\n",
    "prompt3 = \"What is the square root of 10000?\"\n",
    "print(f\"Prompt 3: {prompt3}\")\n",
    "for temp in temperatures:\n",
    "  output = generate_text(prompt3, temperature=temp, max_tokens=50)\n",
    "  print(f\"Temp={temp}: {output}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9szseWpq-t7"
   },
   "source": [
    "The effects of temperature is clear in the codes above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdceHXpnhapw"
   },
   "source": [
    "### Task 1a: Select Best Temperature\n",
    "\n",
    "Based on the outputs above, fill in the best temperature for each use case."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iBA7Ttdohapw"
   },
   "source": [
    "# Fill in: What temperature works best for each task?",
    "best_temp_factual = 0.0  # SOLUTION  # For \"What is the capital of France?\"",
    "best_temp_creative = 1.0  # SOLUTION  # For \"Write the first sentence...\"",
    "best_temp_math = 0.0  # SOLUTION  # For \"What is the square...\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOwtpbg-hapw"
   },
   "source": [
    "Test your selections here."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1zXkPClThapx",
    "outputId": "0c98c3a2-330d-4619-8600-e42180cb0001",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"Testing your temperature selections:\")\n",
    "\n",
    "if best_temp_factual is not None:\n",
    "    output = generate_text(\"What is the capital of France?\", temperature=best_temp_factual, max_tokens=30)\n",
    "    print(f\"\\nFactual (temp={best_temp_factual}): {output}\")\n",
    "\n",
    "if best_temp_creative is not None:\n",
    "    output = generate_text(\"Write the first sentence of a mystery novel.\", temperature=best_temp_creative, max_tokens=50)\n",
    "    print(f\"\\nCreative (temp={best_temp_creative}): {output}\")\n",
    "\n",
    "if best_temp_code is not None:\n",
    "    output = generate_text(\"Write a Python function to calculate factorial.\", temperature=best_temp_code, max_tokens=100)\n",
    "    print(f\"\\nCode (temp={best_temp_code}): {output}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-fxp3Uxhapx"
   },
   "source": [
    "### Task 1b: Determinism Test\n",
    "\n",
    "Run this cell multiple times to verify temperature=0 gives identical outputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fMnwnRLuhapx",
    "outputId": "67c97822-19d8-48df-e463-54483cb0ecc5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "output = generate_text(\"What is 2+2?\", temperature=0, max_tokens=20)\n",
    "print(f\"Output: {output}\")\n",
    "print(\"\\nRun this cell again - you should get the EXACT same output.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-OylD3Bhapz"
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. At temperature=1.5, did the factual question give wrong answers? Why is determinism critical for factual tasks?\n",
    "\n",
    "2. For creative writing, compare outputs at temperature=0.3 vs 1.0. Which produced more interesting variations?\n",
    "\n",
    "3. Did code generation at temperature=1.5 produce valid Python? What's the risk of high temperature for code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIxF9IeGhap0"
   },
   "source": [
    "**About This Task:**\n",
    "Prompts have seven components: Persona, Instruction, Context, Format, Audience, Tone, Data. Adding more components improves output quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadGVCcbhap0"
   },
   "source": [
    "#### Easy Task 2: Building a Complete Prompt\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run pre-built prompt versions to see incremental improvements\n",
    "2. Complete `prompt_v5` by adding the missing 3 components\n",
    "3. Test removing Format to see its impact\n",
    "4. Create your own scenario\n",
    "5. Compare output quality as components are added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5sG5TXzhap1"
   },
   "source": [
    "We start with just an instruction and gradually add components."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FiJ2rIRDhap1"
   },
   "source": [
    "# Version 1: Instruction only\n",
    "prompt_v1 = \"Explain how to make coffee.\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DE6UsZo7hap2",
    "outputId": "8e0057e3-af31-4f90-ad42-3b5453d504cc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"V1: Instruction only\")\n",
    "output = generate_text(prompt_v1, temperature=0, max_tokens=150)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yWxRualEhap2"
   },
   "source": [
    "# Version 2: + Audience\n",
    "prompt_v2 = \"\"\"Explain how to make coffee.\n",
    "\n",
    "Audience: Someone who has never made coffee before.\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j4dlYH1whap3",
    "outputId": "b8d37a02-e87c-4505-9f6a-d24f41e9d64f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"V2: + Audience\")\n",
    "output = generate_text(prompt_v2, temperature=0, max_tokens=150)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkY0AqjDhap4"
   },
   "source": [
    "Notice how adding Audience changes the language."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wwDefDwNhap4"
   },
   "source": [
    "# Version 3: + Format\n",
    "prompt_v3 = \"\"\"Explain how to make coffee.\n",
    "\n",
    "Audience: Someone who has never made coffee before.\n",
    "\n",
    "Format:\n",
    "1. Equipment needed\n",
    "2. Step-by-step instructions\n",
    "3. Common mistakes\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ZH7uHPGhap5",
    "outputId": "ab071488-3581-4c81-9a94-9cf07ceb163e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"V3: + Format\")\n",
    "output = generate_text(prompt_v3, temperature=0, max_tokens=200)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBRnUFsbhap6"
   },
   "source": [
    "See how Format structures the output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NFpzltckhap6"
   },
   "source": [
    "# Version 4: + Tone\n",
    "prompt_v4 = \"\"\"Explain how to make coffee.\n",
    "\n",
    "Audience: Someone who has never made coffee before.\n",
    "\n",
    "Format:\n",
    "1. Equipment needed\n",
    "2. Step-by-step instructions\n",
    "3. Common mistakes\n",
    "\n",
    "Tone: Friendly and encouraging.\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NZOwYW0Whap7",
    "outputId": "25d2fd0d-63e2-4b0a-f828-98d643eaa29e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"V4: + Tone\")\n",
    "output = generate_text(prompt_v4, temperature=0, max_tokens=200)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8vJA-C_hap8"
   },
   "source": [
    "### Task 2a: Complete Version 5\n",
    "\n",
    "Your task: Add Character, Context, and Data to create a complete prompt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nT-eaYajhap9"
   },
   "source": [
    "# Fill in: Add the 3 missing components",
    "prompt_v5 = \"\"\"Character: You are a patient barista trainer with 10 years of experience  # SOLUTION",
    "",
    "Explain how to make coffee.",
    "",
    "Context: This person just got their first coffee machine at home  # SOLUTION",
    "",
    "Audience: Someone who has never made coffee before.",
    "",
    "Format:",
    "1. Equipment needed",
    "2. Step-by-step instructions",
    "3. Common mistakes",
    "",
    "Tone: Friendly and encouraging.",
    "",
    "Data: Use 15g coffee to 240ml water (1:16 ratio). Water temperature 195-205°F  # SOLUTION\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bFNeKxFdhap-",
    "outputId": "34858625-9381-485a-9833-f1edc78b16e4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"V5: All 7 components\")\n",
    "output = generate_text(prompt_v5, temperature=0, max_tokens=250)\n",
    "print(output)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3moaCS1Dhap_"
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. Compare V1 and V2 outputs. How did specifying Audience change the language complexity?\n",
    "\n",
    "2. Which component made the biggest single improvement to output quality?\n",
    "\n",
    "3. When might you intentionally use fewer components? Give a specific scenario where V1 would be better than V5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EX2qfefhaqA"
   },
   "source": [
    "**About This Task:**\n",
    "In-context learning uses examples to guide the model. Zero-shot has no examples, one-shot has one, few-shot has multiple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OWJlT_-haqB"
   },
   "source": [
    "#### Easy Task 3: Improving Few-Shot Examples\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run zero-shot, one-shot, and few-shot on test greetings\n",
    "2. Identify which greetings cause disagreement\n",
    "3. Improve the few-shot prompt by adding better examples\n",
    "4. Test edge cases\n",
    "5. Analyze why certain examples improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tIlhPE3UhaqC"
   },
   "source": [
    "test_greetings = [\n",
    "    \"Good morning, how may I assist you?\",\n",
    "    \"Hey, what's up?\",\n",
    "    \"Hello, nice to meet you.\",\n",
    "    \"Hi there.\",\n",
    "    \"Dear valued customer,\",  # Very formal\n",
    "    \"Yo!\",  # Very casual\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg5QjIrQhaqD"
   },
   "source": [
    "### Zero-Shot\n",
    "\n",
    "Here we ask the model to classify without any examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Good morning, how may I assist you?",
    "greeting1 = \"Good morning, how may I assist you?\"",
    "prompt_greeting1_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting1}",
    "Formality:\"\"\"",
    "",
    "result_greeting1_zero = generate_text(prompt_greeting1_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting1} -> {result_greeting1_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Hey, what's up?",
    "greeting2 = \"Hey, what's up?\"",
    "prompt_greeting2_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting2}",
    "Formality:\"\"\"",
    "",
    "result_greeting2_zero = generate_text(prompt_greeting2_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting2} -> {result_greeting2_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Hello, nice to meet you.",
    "greeting3 = \"Hello, nice to meet you.\"",
    "prompt_greeting3_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting3}",
    "Formality:\"\"\"",
    "",
    "result_greeting3_zero = generate_text(prompt_greeting3_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting3} -> {result_greeting3_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Hi there.",
    "greeting4 = \"Hi there.\"",
    "prompt_greeting4_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting4}",
    "Formality:\"\"\"",
    "",
    "result_greeting4_zero = generate_text(prompt_greeting4_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting4} -> {result_greeting4_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Dear valued customer,",
    "greeting5 = \"Dear valued customer,\"",
    "prompt_greeting5_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting5}",
    "Formality:\"\"\"",
    "",
    "result_greeting5_zero = generate_text(prompt_greeting5_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting5} -> {result_greeting5_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot: Yo!",
    "greeting6 = \"Yo!\"",
    "prompt_greeting6_zero = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Greeting: {greeting6}",
    "Formality:\"\"\"",
    "",
    "result_greeting6_zero = generate_text(prompt_greeting6_zero, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting6} -> {result_greeting6_zero}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Shot\n\nSee how a single example helps guide the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Good morning, how may I assist you?",
    "prompt_greeting1_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting1}",
    "Formality:\"\"\"",
    "",
    "result_greeting1_one = generate_text(prompt_greeting1_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting1} -> {result_greeting1_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Hey, what's up?",
    "prompt_greeting2_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting2}",
    "Formality:\"\"\"",
    "",
    "result_greeting2_one = generate_text(prompt_greeting2_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting2} -> {result_greeting2_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Hello, nice to meet you.",
    "prompt_greeting3_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting3}",
    "Formality:\"\"\"",
    "",
    "result_greeting3_one = generate_text(prompt_greeting3_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting3} -> {result_greeting3_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Hi there.",
    "prompt_greeting4_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting4}",
    "Formality:\"\"\"",
    "",
    "result_greeting4_one = generate_text(prompt_greeting4_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting4} -> {result_greeting4_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Dear valued customer,",
    "prompt_greeting5_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting5}",
    "Formality:\"\"\"",
    "",
    "result_greeting5_one = generate_text(prompt_greeting5_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting5} -> {result_greeting5_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# One-shot: Yo!",
    "prompt_greeting6_one = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Example:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: {greeting6}",
    "Formality:\"\"\"",
    "",
    "result_greeting6_one = generate_text(prompt_greeting6_one, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting6} -> {result_greeting6_one}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot\n\nYour task: Improve this prompt by adding 1-2 more examples to handle edge cases better."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Good morning, how may I assist you?",
    "prompt_greeting1_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting1}",
    "Formality:\"\"\"",
    "",
    "result_greeting1_few = generate_text(prompt_greeting1_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting1} -> {result_greeting1_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Hey, what's up?",
    "prompt_greeting2_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting2}",
    "Formality:\"\"\"",
    "",
    "result_greeting2_few = generate_text(prompt_greeting2_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting2} -> {result_greeting2_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Hello, nice to meet you.",
    "prompt_greeting3_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting3}",
    "Formality:\"\"\"",
    "",
    "result_greeting3_few = generate_text(prompt_greeting3_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting3} -> {result_greeting3_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Hi there.",
    "prompt_greeting4_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting4}",
    "Formality:\"\"\"",
    "",
    "result_greeting4_few = generate_text(prompt_greeting4_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting4} -> {result_greeting4_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Dear valued customer,",
    "prompt_greeting5_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting5}",
    "Formality:\"\"\"",
    "",
    "result_greeting5_few = generate_text(prompt_greeting5_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting5} -> {result_greeting5_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot: Yo!",
    "prompt_greeting6_few = f\"\"\"Classify formality: formal, neutral, or casual.",
    "",
    "Examples:",
    "Greeting: Dear Sir or Madam",
    "Formality: formal",
    "",
    "Greeting: Yo dude",
    "Formality: casual",
    "",
    "Greeting: Hello, how are you",
    "Formality: neutral",
    "",
    "# SOLUTION: Added two edge case examples",
    "Greeting: Good evening, I hope you are well",
    "Formality: formal",
    "",
    "Greeting: Hey there",
    "Formality: casual",
    "",
    "Greeting: {greeting6}",
    "Formality:\"\"\"",
    "",
    "result_greeting6_few = generate_text(prompt_greeting6_few, temperature=0, max_tokens=10).strip()",
    "print(f\"{greeting6} -> {result_greeting6_few}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n\nHere we identify disagreements to see where examples help most."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Good morning, how may I assist you?",
    "print(f\"\\n{greeting1}\")",
    "print(f\"  Zero-shot: {result_greeting1_zero}\")",
    "print(f\"  One-shot:  {result_greeting1_one}\")",
    "print(f\"  Few-shot:  {result_greeting1_few}\")",
    "",
    "if result_greeting1_zero == result_greeting1_one == result_greeting1_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Hey, what's up?",
    "print(f\"\\n{greeting2}\")",
    "print(f\"  Zero-shot: {result_greeting2_zero}\")",
    "print(f\"  One-shot:  {result_greeting2_one}\")",
    "print(f\"  Few-shot:  {result_greeting2_few}\")",
    "",
    "if result_greeting2_zero == result_greeting2_one == result_greeting2_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Hello, nice to meet you.",
    "print(f\"\\n{greeting3}\")",
    "print(f\"  Zero-shot: {result_greeting3_zero}\")",
    "print(f\"  One-shot:  {result_greeting3_one}\")",
    "print(f\"  Few-shot:  {result_greeting3_few}\")",
    "",
    "if result_greeting3_zero == result_greeting3_one == result_greeting3_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Hi there.",
    "print(f\"\\n{greeting4}\")",
    "print(f\"  Zero-shot: {result_greeting4_zero}\")",
    "print(f\"  One-shot:  {result_greeting4_one}\")",
    "print(f\"  Few-shot:  {result_greeting4_few}\")",
    "",
    "if result_greeting4_zero == result_greeting4_one == result_greeting4_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Dear valued customer,",
    "print(f\"\\n{greeting5}\")",
    "print(f\"  Zero-shot: {result_greeting5_zero}\")",
    "print(f\"  One-shot:  {result_greeting5_one}\")",
    "print(f\"  Few-shot:  {result_greeting5_few}\")",
    "",
    "if result_greeting5_zero == result_greeting5_one == result_greeting5_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare results for: Yo!",
    "print(f\"\\n{greeting6}\")",
    "print(f\"  Zero-shot: {result_greeting6_zero}\")",
    "print(f\"  One-shot:  {result_greeting6_one}\")",
    "print(f\"  Few-shot:  {result_greeting6_few}\")",
    "",
    "if result_greeting6_zero == result_greeting6_one == result_greeting6_few:",
    "    print(f\"  All agree\")",
    "else:",
    "    print(f\"  DISAGREEMENT\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkZcXXfJhaqL"
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. Which greeting showed the biggest difference between zero-shot and few-shot? Why was it ambiguous?\n",
    "\n",
    "2. Did adding more examples improve accuracy on edge cases like \"Yo!\" or \"Dear valued customer\"?\n",
    "\n",
    "3. What makes a good few-shot example? Should you show edge cases or clear typical examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDezS6_XhaqM"
   },
   "source": [
    "**About This Task:**\n",
    "Chain-of-Thought prompting asks the model to show its reasoning step-by-step, improving accuracy on complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__QKqe8ShaqN"
   },
   "source": [
    "#### Easy Task 4: Testing Chain-of-Thought\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run direct prompting on simple and tricky problems\n",
    "2. Compare with few-shot CoT to see reasoning improvements\n",
    "3. Test zero-shot CoT on hard problems\n",
    "4. Improve CoT examples to fix errors\n",
    "5. Analyze when step-by-step reasoning prevents mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHP8fcJwhaqO"
   },
   "source": [
    "We test on both simple problems and counter-intuitive ones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S4UF_7RvhaqP"
   },
   "source": [
    "problems = [\n",
    "    (\"If John has 5 apples and gives 2 to Mary, how many does he have?\", 3, \"easy\"),\n",
    "    (\"A ticket costs $15. I buy 3 tickets with a $50 bill. How much change?\", 5, \"easy\"),\n",
    "    (\"A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much is the ball?\", 0.05, \"tricky\"),\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27p0iW6OhaqQ"
   },
   "source": [
    "### Direct Prompting\n",
    "\n",
    "Here we ask for answers directly without reasoning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KTiPXZ3YhaqQ",
    "outputId": "290f3c69-1d23-41f0-d894-0b960c5cd48b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(\"Direct prompting (no reasoning):\")\n",
    "\n",
    "for question, correct, difficulty in problems:\n",
    "    prompt = f\"{question}\\nAnswer:\"\n",
    "    answer = generate_text(prompt, temperature=0, max_tokens=30)\n",
    "\n",
    "    print(f\"\\n[{difficulty.upper()}] {question}\")\n",
    "    print(f\"Model: {answer.strip()}\")\n",
    "    print(f\"Correct: {correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Direct prompting: If John has 5 apples and gives 2 to Mary, how many...",
    "problem1_question = \"If John has 5 apples and gives 2 to Mary, how many does he have?\"",
    "problem1_correct = 3",
    "problem1_difficulty = \"easy\"",
    "",
    "prompt_problem1_direct = f\"{problem1_question}\\nAnswer:\"",
    "answer_problem1_direct = generate_text(prompt_problem1_direct, temperature=0, max_tokens=30)",
    "",
    "print(f\"\\n[{problem1_difficulty.upper()}] {problem1_question}\")",
    "print(f\"Model: {answer_problem1_direct.strip()}\")",
    "print(f\"Correct: {problem1_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Direct prompting: A ticket costs $15. I buy 3 tickets with a $50 bil...",
    "problem2_question = \"A ticket costs $15. I buy 3 tickets with a $50 bill. How much change?\"",
    "problem2_correct = 5",
    "problem2_difficulty = \"easy\"",
    "",
    "prompt_problem2_direct = f\"{problem2_question}\\nAnswer:\"",
    "answer_problem2_direct = generate_text(prompt_problem2_direct, temperature=0, max_tokens=30)",
    "",
    "print(f\"\\n[{problem2_difficulty.upper()}] {problem2_question}\")",
    "print(f\"Model: {answer_problem2_direct.strip()}\")",
    "print(f\"Correct: {problem2_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Direct prompting: A bat and ball cost $1.10 total. The bat costs $1 ...",
    "problem3_question = \"A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much is the ball?\"",
    "problem3_correct = 0.05",
    "problem3_difficulty = \"tricky\"",
    "",
    "prompt_problem3_direct = f\"{problem3_question}\\nAnswer:\"",
    "answer_problem3_direct = generate_text(prompt_problem3_direct, temperature=0, max_tokens=30)",
    "",
    "print(f\"\\n[{problem3_difficulty.upper()}] {problem3_question}\")",
    "print(f\"Model: {answer_problem3_direct.strip()}\")",
    "print(f\"Correct: {problem3_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how direct prompting might fail on the tricky problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot CoT\n\nYour task: Improve the prompt by adding a third example showing careful algebra."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot CoT: If John has 5 apples and gives 2 to Mary, how many...",
    "prompt_problem1_fewcot = f\"\"\"Solve step-by-step.",
    "",
    "Q: Roger has 5 balls. He buys 2 cans with 3 balls each. How many balls does he have?",
    "A: Roger starts with 5 balls.",
    "He buys 2 cans, each has 3 balls.",
    "New balls: 2 × 3 = 6",
    "Total: 5 + 6 = 11",
    "Answer: 11",
    "",
    "Q: A cafe had 23 apples. They used 20 for lunch and bought 6 more. How many now?",
    "A: Start with 23 apples.",
    "After using 20: 23 - 20 = 3",
    "After buying 6: 3 + 6 = 9",
    "Answer: 9",
    "",
    "# SOLUTION: Added algebra example for tricky problems",
    "Q: A pen and notebook cost $3 total. The notebook costs $2 more than the pen. How much is the pen?",
    "A: Let pen cost = x",
    "Then notebook = x + 2",
    "Together: x + (x + 2) = 3",
    "Simplify: 2x + 2 = 3",
    "Subtract 2: 2x = 1",
    "Divide by 2: x = 0.50",
    "Answer: $0.50",
    "",
    "Q: {problem1_question}",
    "A:\"\"\"",
    "",
    "answer_problem1_fewcot = generate_text(prompt_problem1_fewcot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem1_difficulty.upper()}] {problem1_question}\")",
    "print(f\"Reasoning: {answer_problem1_fewcot}\")",
    "print(f\"Correct: {problem1_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot CoT: A ticket costs $15. I buy 3 tickets with a $50 bil...",
    "prompt_problem2_fewcot = f\"\"\"Solve step-by-step.",
    "",
    "Q: Roger has 5 balls. He buys 2 cans with 3 balls each. How many balls does he have?",
    "A: Roger starts with 5 balls.",
    "He buys 2 cans, each has 3 balls.",
    "New balls: 2 × 3 = 6",
    "Total: 5 + 6 = 11",
    "Answer: 11",
    "",
    "Q: A cafe had 23 apples. They used 20 for lunch and bought 6 more. How many now?",
    "A: Start with 23 apples.",
    "After using 20: 23 - 20 = 3",
    "After buying 6: 3 + 6 = 9",
    "Answer: 9",
    "",
    "# SOLUTION: Added algebra example for tricky problems",
    "Q: A pen and notebook cost $3 total. The notebook costs $2 more than the pen. How much is the pen?",
    "A: Let pen cost = x",
    "Then notebook = x + 2",
    "Together: x + (x + 2) = 3",
    "Simplify: 2x + 2 = 3",
    "Subtract 2: 2x = 1",
    "Divide by 2: x = 0.50",
    "Answer: $0.50",
    "",
    "Q: {problem2_question}",
    "A:\"\"\"",
    "",
    "answer_problem2_fewcot = generate_text(prompt_problem2_fewcot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem2_difficulty.upper()}] {problem2_question}\")",
    "print(f\"Reasoning: {answer_problem2_fewcot}\")",
    "print(f\"Correct: {problem2_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Few-shot CoT: A bat and ball cost $1.10 total. The bat costs $1 ...",
    "prompt_problem3_fewcot = f\"\"\"Solve step-by-step.",
    "",
    "Q: Roger has 5 balls. He buys 2 cans with 3 balls each. How many balls does he have?",
    "A: Roger starts with 5 balls.",
    "He buys 2 cans, each has 3 balls.",
    "New balls: 2 × 3 = 6",
    "Total: 5 + 6 = 11",
    "Answer: 11",
    "",
    "Q: A cafe had 23 apples. They used 20 for lunch and bought 6 more. How many now?",
    "A: Start with 23 apples.",
    "After using 20: 23 - 20 = 3",
    "After buying 6: 3 + 6 = 9",
    "Answer: 9",
    "",
    "# SOLUTION: Added algebra example for tricky problems",
    "Q: A pen and notebook cost $3 total. The notebook costs $2 more than the pen. How much is the pen?",
    "A: Let pen cost = x",
    "Then notebook = x + 2",
    "Together: x + (x + 2) = 3",
    "Simplify: 2x + 2 = 3",
    "Subtract 2: 2x = 1",
    "Divide by 2: x = 0.50",
    "Answer: $0.50",
    "",
    "Q: {problem3_question}",
    "A:\"\"\"",
    "",
    "answer_problem3_fewcot = generate_text(prompt_problem3_fewcot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem3_difficulty.upper()}] {problem3_question}\")",
    "print(f\"Reasoning: {answer_problem3_fewcot}\")",
    "print(f\"Correct: {problem3_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how showing reasoning steps helps catch mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot CoT\n\nHere we use the phrase \"Let's think step-by-step\" to trigger reasoning without examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot CoT: If John has 5 apples and gives 2 to Mary, how many...",
    "prompt_problem1_zerocot = f\"{problem1_question}\\n\\nLet's think step-by-step:\"",
    "answer_problem1_zerocot = generate_text(prompt_problem1_zerocot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem1_difficulty.upper()}] {problem1_question}\")",
    "print(f\"Reasoning: {answer_problem1_zerocot}\")",
    "print(f\"Correct: {problem1_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot CoT: A ticket costs $15. I buy 3 tickets with a $50 bil...",
    "prompt_problem2_zerocot = f\"{problem2_question}\\n\\nLet's think step-by-step:\"",
    "answer_problem2_zerocot = generate_text(prompt_problem2_zerocot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem2_difficulty.upper()}] {problem2_question}\")",
    "print(f\"Reasoning: {answer_problem2_zerocot}\")",
    "print(f\"Correct: {problem2_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Zero-shot CoT: A bat and ball cost $1.10 total. The bat costs $1 ...",
    "prompt_problem3_zerocot = f\"{problem3_question}\\n\\nLet's think step-by-step:\"",
    "answer_problem3_zerocot = generate_text(prompt_problem3_zerocot, temperature=0, max_tokens=150)",
    "",
    "print(f\"\\n[{problem3_difficulty.upper()}] {problem3_question}\")",
    "print(f\"Reasoning: {answer_problem3_zerocot}\")",
    "print(f\"Correct: {problem3_correct}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how a simple phrase triggers step-by-step reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeGTKgJjhaqW"
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. Did direct prompting get the bat-and-ball problem wrong? What's the common wrong answer ($0.10)?\n",
    "\n",
    "2. Compare few-shot CoT vs zero-shot CoT on the tricky problem. Which caught the mistake better?\n",
    "\n",
    "3. What type of problems benefit most from CoT? When is direct prompting good enough?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}