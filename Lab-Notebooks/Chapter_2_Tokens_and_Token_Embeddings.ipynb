{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_a9QvUFVCUR"
      },
      "source": [
        "<h1>Chapter 2 - Tokens and Token Embeddings</h1>\n",
        "<i>Exploring tokens and embeddings as an integral part of building LLMs</i>\n",
        "\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
        "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
        "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter02/Chapter%202%20-%20Tokens%20and%20Token%20Embeddings.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is for Chapter 2 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
        "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l2QWMTfVaC2"
      },
      "source": [
        "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Zarh4gvVaC4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade transformers==4.41.2 sentence-transformers==3.0.1 gensim==4.3.2 scikit-learn==1.5.0 accelerate==0.31.0 peft==0.11.1 scipy==1.10.1 numpy==1.26.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQHfpqT_t9-K"
      },
      "source": [
        "# Downloading and Running An LLM\n",
        "\n",
        "The first step is to load our model onto the GPU for faster inference. Note that we load the model and tokenizer separately and keep them as such so that we can explore them separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "1b0e0532ffb14b73a5004b9e22eeeff0",
            "99ad4131e9c141a1a26cca828125af21",
            "f35d5f2531ab413da5d6233bed5075f4",
            "7b9a5d4b274f4ba5bb02999308731428",
            "ba9ebf12ff2644ffbe74da1433267475",
            "e5509d36762c4573a1a9b431cf099eea",
            "63710177aeeb48409a9537fc4c0e084f",
            "2e7da05c1ccc43bcaab1347eaa8ffb28",
            "c2e8e4222f6844529bcc702be9e842b1",
            "d168a618a1ae49b192b8caf4975e8b3f",
            "9f251b58f01a4f9a86f410f806a3d7fe",
            "bc08928901db42baa1527d9faf7eeeb7",
            "92066a31e3ef4422a91d09b3b08e9252",
            "c3b91019c45540588f34bb37d4d8b1a8",
            "f09d0f9281e1401595731551c8aaa5ae",
            "ecc3ffed06574af1bcc134d71e6ce2e6",
            "7e114587cde04e64a0becd85c8a70db2",
            "4a02532ae43c4744b27519d90833eb3e",
            "0a5c347e97044bb0b47db0663fed6e6a",
            "5c693052c9b84161a56e9d3673f75886",
            "f60998deeaf54eb6bdfff16ee0b770bc",
            "b88b41074f2147dca2fd63f12a0eee41",
            "af65551424ea46d2acbde61d2354514d",
            "30b0136365e24692aee8181013eaa933",
            "b7e148e0a54f4c19a0b51b760cf56227",
            "cadd7037cf7b4eacb0aba79b2e47e31e",
            "524abd8dc4a948858026c1912b33a7f6",
            "2d3fd92a815e4df2879c6814a8c55241",
            "f9b45543ff1541bbb8fac0d153089a32",
            "331d2e42278546bab630388afe0168f5",
            "08ece0e6f6ff4a0fb07803efb22b5600",
            "5c7643461c4a48b6b6e389dbe4093a66",
            "9594a830ae3a42098c6b2b68ab737b53",
            "a92d62c3432242939f1915c091387606",
            "2448dd0abd23472798d9517661a5d316",
            "972de0c0ca7647ee8a9fe07a819bef94",
            "1cd324c8bbcd4762a2fffe76a2d4a568",
            "2a00e7c7dd50425e8447c2bb0f1ac325",
            "a5d9ae4da6eb41b995dc8a2ee2db11b7",
            "9c730b81ce054c7cb672defb32dd2959",
            "0ef2269f1c294decbdf6677bd758b3b6",
            "14a9d5dacec446ad9ff4db107b4eca7e",
            "80915239d7154e9b9e6a1016c9781189",
            "370ad85302e84dfd820884ab44d3f693",
            "1ab8da531ec244a28d54655545d2e8be",
            "7f90526493f343afb3a4e93cf3a8d2f4",
            "35ff96961db94a7b934a7ed54faa8137",
            "9edd231803184404a9530c0f3149746f",
            "77ac749e34d74f909e6009f09aa4d917",
            "02c61a5dfdd4400dbc68ffa3acd19751",
            "116bb9e05ec840db940ad213d1fc4004",
            "1933525267ec40dab79dc76510091c2b",
            "b2f273640b70426b9f40c513124be381",
            "9d8bfcd2f28647ee9090d7b3f43c3df9",
            "3a3da21989e24df8b59b955352417a32",
            "c683a7bccd124385b8ba79c5a2b5c7e2",
            "f50f8b34088040358262f6975a53cf2e",
            "6403d57aae084660a439d7a8d10a1cb8",
            "f2d63e5e46e9400cb1013197f6f14355",
            "fa879f89629f4073ae825be8da1f653b",
            "bb2402adc0ab429bb04045ee4b56ae0a",
            "ddc9c238196a4905897f5571a7cb484f",
            "0aaa5dd67b2d40daae7ff43e400f7e43",
            "8bafce2832694a91af1cf4c0d1c3a3dc",
            "3eacd151de3f437fa282255b722d3f65",
            "d500588be8a04afda3799e6d173b1bc3",
            "ba411754d7b742dfb88385c6414d1143",
            "d6b6ff3dec4644878d52044a3643ba2a",
            "9c205fab59e14df0bbcdf8f9ee9ebce1",
            "8a789f1804a6429883bc2fbd88b79b39",
            "f411d86e72b44df9bab2b9ebad036d72",
            "bc0b9f22c697420eaf1096bfab9002cd",
            "6b9da2928765414094406ae4bc0d1a88",
            "6e1659ba4aaa4178bc259b221048ab34",
            "80ef2e8730af465eae431b2091207b13",
            "b67da4185a8141b5a5c2ec425df77c6f",
            "8d47609f98304d688dfa459f756592ce",
            "af97d1fdeff24c47bf1cb5b7ba4f6194",
            "268074c40b814e70b4cc39990bba4e7d",
            "90c1bc7e931d4fcdb8dd9c968f78ef08",
            "8a32e96ceba040f6ba2e009fa97e031c",
            "bf9d84a2f879490ab53cb958d47e8e61",
            "a84c7c2571b7474ebec7a014a3b07419",
            "a34f3aedfd294047bf80ea2893e0e8b3",
            "95d4d31f7b6d456b97d6729b9b363e59",
            "480b7a301b414ef5b42490606f7d69d0",
            "44ce9788016c4cef8446d3c6db745bb9",
            "4bf3002d151d419785c23e0a07b6356e",
            "00baed7bc6e14590b863b374c80ab009",
            "14f225a9f4854c3a912b51b47fa1e49e",
            "ef52433c18d549ffb3df671271a9db69",
            "fff713f411724456b294e67513c92a50",
            "23f7f5765dea4556a837fd8ca948b771",
            "aa1c49568a4e449bbbcb1a03d57c0126",
            "ec91b1a77d364fff8ac69805dda44db4",
            "7a4dce13a73841458f1cc7fca7066d93",
            "07cbcc33705f46638a09fc6448e4d6f3",
            "b731f076dfe14d53a9a587af2c6cd533",
            "c8d76a0593d84434bb6a99d1466eb586",
            "00e4fc869680433aa8b15aff6e5911cf",
            "4bea66e549444e05b5d4dc47fa084665",
            "2362525fddee437d8360bc54727588a9",
            "d1bae2e37a014b8aa0bc3ddefc98aeee",
            "dcad09619f3e409ca532f65f495bca95",
            "096412391f9944bc9b91cc4e9f613a58",
            "5ae6cece77c14aac866fbaec1e842861",
            "d2864291a6fa4969847a4e94d9207158",
            "35b1fe1500aa44a4bba102263c8b4130",
            "dc97d820920c4020bda266f8ad18f42c",
            "a0a8fd2fd4b24fc288adf7ef344da919",
            "3d18dd1064f44bfca2b1802b4693d58a",
            "37f725d0d4ba4d30884dd565a8162c21",
            "ab3fdd549dbb4f7cb63bb343f620ea78",
            "4a0e1058194d44cf996584155b718a9d",
            "f48552952ec7438faa61f9fa057098b4",
            "35d040953b4e4d0ba72eeb0622d63acf",
            "63028d2800c2488ca4f51eb5f5f6dbc5",
            "14ae6fc7cd494a2da0ba5f5d4fbfe040",
            "519e946f30544f088cd59bf7996a9339",
            "4dde27fcccdd43c0b02bc7b29bc5f469",
            "e40a1a33002d43d8984ddb5032cba312",
            "8d9e9616da254bd7ac8ddc2234c6bd83",
            "5b22460a855a47da92218277de2a0109",
            "0736c805fb7a4c8d8b8c81869d508785",
            "b28a823dd3bd46b483b1195347b27a42",
            "c24fde1d136c46b9abd3ef76b975fc26",
            "3d5f832997ec421aaed8ae77a8f1a6de",
            "41b0eefb6e864d93843b0d0746f34992",
            "aba2aa7bef9a4a8da593e08c43b520c4",
            "8f4ae28aeb4049c7bfcd8bc93a5c0954",
            "a9429632e3034e47a5605230a232ec42",
            "4d5a3f0cbc59466083af3eb842e8cafd"
          ]
        },
        "id": "jjU8NBHnwA4j",
        "outputId": "cd17d989-4c59-44d8-cc60-4ee82f023119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b0e0532ffb14b73a5004b9e22eeeff0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": ["`torch_dtype` is deprecated! Use `dtype` instead!\n"]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["model.safetensors.index.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc08928901db42baa1527d9faf7eeeb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af65551424ea46d2acbde61d2354514d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a92d62c3432242939f1915c091387606"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ab8da531ec244a28d54655545d2e8be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c683a7bccd124385b8ba79c5a2b5c7e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba411754d7b742dfb88385c6414d1143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer_config.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af97d1fdeff24c47bf1cb5b7ba4f6194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00baed7bc6e14590b863b374c80ab009"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00e4fc869680433aa8b15aff6e5911cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d18dd1064f44bfca2b1802b4693d58a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d9e9616da254bd7ac8ddc2234c6bd83"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iVl5yePuq3B",
        "outputId": "e515d3c5-b4d2-4f7e-dd4a-a9fe8c5fec84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|> Subject: Heartfelt Apologies for the Gardening Mishap\n",
            "\n",
            "\n",
            "Dear\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# Generate the text\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=20\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(tokenizer.decode(generation_output[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmzgbbdKuvHt",
        "outputId": "d806a7a8-d3a9-499e-fd9a-f08c114b6952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
            "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
            "           372,  9559, 29889, 32001]], device='cuda:0')\n"
          ]
        }
      ],
      "source": ["print(input_ids)"]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4vsjbxwu1K1",
        "outputId": "3c17687a-ded3-4c6f-ff25-5b004fff8623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write\n",
            "an\n",
            "email\n",
            "apolog\n",
            "izing\n",
            "to\n",
            "Sarah\n",
            "for\n",
            "the\n",
            "trag\n",
            "ic\n",
            "garden\n",
            "ing\n",
            "m\n",
            "ish\n",
            "ap\n",
            ".\n",
            "Exp\n",
            "lain\n",
            "how\n",
            "it\n",
            "happened\n",
            ".\n",
            "<|assistant|>\n"
          ]
        }
      ],
      "source": ["for id in input_ids[0]:\n", "   print(tokenizer.decode(id))"]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9wRZ3J3u4z1",
        "outputId": "4624c89a-cd8d-42e7-a7e3-25c4d41d532a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
              "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
              "           372,  9559, 29889, 32001,  3323,   622, 29901, 17778, 29888,  2152,\n",
              "          6225, 11763,   363,   278, 19906,   292,   341,   728,   481,    13,\n",
              "            13,    13, 29928,   799]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": ["generation_output"]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QlHLof3u8A3",
        "outputId": "8216bf08-ad31-4837-c746-ab8f3b40cb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ["Sub\n", "ject\n", "Subject\n", ":\n"]
        }
      ],
      "source": [
        "print(tokenizer.decode(3323))\n",
        "print(tokenizer.decode(622))\n",
        "print(tokenizer.decode([3323, 622]))\n",
        "print(tokenizer.decode(29901))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9nRducW48bd"
      },
      "source": ["# Comparing Trained LLM Tokenizers\n"]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7W0xFIVo5A0S"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gcc3JjwX5DK-"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "ðŸŽµ é¸Ÿ\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs: \"       \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "f100e6a44ad3473996b0045a7863920b",
            "5665fb71be67450c92ec8961805a036b",
            "6c029204f07f475088dd276739cbbda9",
            "6108fc568b144d808e3d13d067ae0650",
            "74a585a6933747f884c19996e319ea59",
            "50bae72678d2437e9ee908d12bd78435",
            "6424fc87b97f4ef2bf3b6d2ae5d04ad3",
            "f1a04e6667f8473c839b0c7962a1bf25",
            "965d76d6d10e450e9ae6380f31152772",
            "a4ffbb1d9e474436bb9c26763ad406d5",
            "624d559fde8041398ebed5f2dfa867aa",
            "929ef63e356246b5bfa6f74b4b967c7a",
            "595396b85ba043cba180b8bd04ef9f39",
            "fc91b5ba984c484cba1fefa38a52ff95",
            "7dbfaaf1180e44c3a2b4d24807d38cb6",
            "f0d4b2b44a7a42fd8286f3bf0c2a7c3e",
            "9f9bb5b33139496b894c8e3be0a48d38",
            "076a9169819a4eb681c90d434661a1c9",
            "2b7ecb3eb8da4c72872633ed30a7a4f8",
            "d466beb68957424b8c19d7727eac2aa2",
            "3085eab4bf53456fb15fb8f9a242252f",
            "7cbe67ac416b4b53806012f7ca6e54a3",
            "daff237a3b7f40798ea5992d74ac85ea",
            "232ea616bc964bdca7a6bba4152b6c22",
            "fd793abee2064ca3b8697ead10a71960",
            "49b1f82317d547de8b71ef5b394a7e10",
            "e8b65d8f670f42f0afddda9e1500c388",
            "78d36f33b2414682bde2bd21fd45ecf7",
            "356d9d3357fc45fa979aa7272ff05a53",
            "9083bc33094b421ab1b31c966f95fcee",
            "87578abb20d448579a07ceb5cc1e4224",
            "b66507fe47d2413e9a56f9c23b70f08f",
            "c5adbee1d14b4a45b533060a226af30d",
            "437c4a7b341442eab312f4bf34a0b230",
            "8474619b7e1148179df0ebd28feab424",
            "989961061caf414f93a65d1522493a9b",
            "702529f6aa2e44a585d70da3f6caffbf",
            "712b8d7842414a5087d9f463f2479e51",
            "f9a117cf122b45428aa99127cfbe0123",
            "f5d12f9391a74fb5b56cc69013d8f6a5",
            "e4f5f20a090640f7903069e9b678feb5",
            "fbe4fc45aa5f47788e79e9b71d8e0b29",
            "40e74662c8154e7989bd9479826c5929",
            "4fb6505aa32c4917b04017910b538333"
          ]
        },
        "id": "fCDGSXP75Hv-",
        "outputId": "850a830f-d290-4d6e-95ea-86f49e7aade0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f100e6a44ad3473996b0045a7863920b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "929ef63e356246b5bfa6f74b4b967c7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daff237a3b7f40798ea5992d74ac85ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "437c4a7b341442eab312f4bf34a0b230"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98menglish\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195mcapital\u001b[0m \u001b[0;30;48;2;166;216;84m##ization\u001b[0m \u001b[0;30;48;2;255;217;47m[UNK]\u001b[0m \u001b[0;30;48;2;102;194;165m[UNK]\u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_\u001b[0m \u001b[0;30;48;2;231;138;195mtoken\u001b[0m \u001b[0;30;48;2;166;216;84m##s\u001b[0m \u001b[0;30;48;2;255;217;47mfalse\u001b[0m \u001b[0;30;48;2;102;194;165mnone\u001b[0m \u001b[0;30;48;2;252;141;98meli\u001b[0m \u001b[0;30;48;2;141;160;203m##f\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m>\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98melse\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195mtwo\u001b[0m \u001b[0;30;48;2;166;216;84mtab\u001b[0m \u001b[0;30;48;2;255;217;47m##s\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m\"\u001b[0m \u001b[0;30;48;2;141;160;203m\"\u001b[0m \u001b[0;30;48;2;231;138;195mthree\u001b[0m \u001b[0;30;48;2;166;216;84mtab\u001b[0m \u001b[0;30;48;2;255;217;47m##s\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m\"\u001b[0m \u001b[0;30;48;2;141;160;203m\"\u001b[0m \u001b[0;30;48;2;231;138;195m12\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m*\u001b[0m \u001b[0;30;48;2;252;141;98m50\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m600\u001b[0m \u001b[0;30;48;2;166;216;84m[SEP]\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"bert-base-uncased\")"]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "f4c325acd10841c582d4b68adef1a271",
            "cb472b8af61d428d9e1968f99f1ab613",
            "ee7b9598c634441c90886705a6117472",
            "e3ce1d2b616544ca92828e59176236fb",
            "3f73997e3cd74f4c8a77e19a3dc893e3",
            "89105df69cc34287a017578077a639a9",
            "fce2546afc2b4fc597b492e6c1e4fc9b",
            "d91b8c36cc974095a0be63b0bf0c05d4",
            "126f76421856471694d4bcef496dfcea",
            "c1e4eb2c77b84dba9beccfe5ecf22098",
            "6146576c30a44d4f8d0179d0e75d39ab",
            "f03904ce52d8432eb2ea1eff6a51af8b",
            "dc051edaed824af1bb9119e1d8caa3b9",
            "6c69685afd644514a88f9e8f3e4348b1",
            "d182456602d142b48776c1d06f143547",
            "291844351c5d4d46916d1b1d7a0d2f77",
            "6b08ff049d75410e8f30c1c6358a0e2e",
            "81b353d6a2374b59ae1b2113cd89b7d0",
            "ecc49c26e341445da19375c2821dc5a8",
            "f2400ce199304445843bf2097d88770e",
            "2e5684425a4646f88d4e511f01940885",
            "518e82b4de174948acd0cf314dc76594",
            "192eda7a66444e69882ba99b856f1e98",
            "d3c5e6dbf7ee4d93b5f06aa8ac842c38",
            "a53d5b020b954e7894ac6a1254c012d3",
            "c35b5616e99d43bf95f328c41e7102c5",
            "2a768294ce134bf4a1e878e06b196147",
            "97974a5a2d0a417788d29a73e4c3f9a8",
            "b7a6bbf9ebcc4923a1e3d3d9ba0e35ad",
            "b4298e8fe5d5481e8cde88fdf44ac367",
            "8abfd5b1892a4c64b5a37b1193200bac",
            "60372c428f094624b7b3f946706ef24b",
            "076fa22bdb9149f481509a47d3b55cca",
            "de03bd6f90274c1ab72fcffddc2ba3c8",
            "97ccd546f988402fa93536ad101c837e",
            "d1ec6a7dda46403eba0fcc4742f8ae02",
            "6d7314e5925b4c00a04d10f2583c7a1a",
            "f09e4371fd1441068f8df851f6f4bb2a",
            "2b63ba62f43e40a097d90f78e7792406",
            "0906873ccd2944f1ba46af9ccc9e810b",
            "8b7c1c326f7c40b2a28902a36b74d4cb",
            "3b44378475f3433699af013c06855c30",
            "0f247c04cdb9469ca6bfa452d25cf0fa",
            "1808d600a18647d18d22d39bb5a666f0"
          ]
        },
        "id": "0Ay_NX3K5HyP",
        "outputId": "54a92590-727c-4377-dec0-5de037fa342b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4c325acd10841c582d4b68adef1a271"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f03904ce52d8432eb2ea1eff6a51af8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "192eda7a66444e69882ba99b856f1e98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de03bd6f90274c1ab72fcffddc2ba3c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195mCA\u001b[0m \u001b[0;30;48;2;166;216;84m##PI\u001b[0m \u001b[0;30;48;2;255;217;47m##TA\u001b[0m \u001b[0;30;48;2;102;194;165m##L\u001b[0m \u001b[0;30;48;2;252;141;98m##I\u001b[0m \u001b[0;30;48;2;141;160;203m##Z\u001b[0m \u001b[0;30;48;2;231;138;195m##AT\u001b[0m \u001b[0;30;48;2;166;216;84m##ION\u001b[0m \u001b[0;30;48;2;255;217;47m[UNK]\u001b[0m \u001b[0;30;48;2;102;194;165m[UNK]\u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_\u001b[0m \u001b[0;30;48;2;231;138;195mtoken\u001b[0m \u001b[0;30;48;2;166;216;84m##s\u001b[0m \u001b[0;30;48;2;255;217;47mF\u001b[0m \u001b[0;30;48;2;102;194;165m##als\u001b[0m \u001b[0;30;48;2;252;141;98m##e\u001b[0m \u001b[0;30;48;2;141;160;203mNone\u001b[0m \u001b[0;30;48;2;231;138;195mel\u001b[0m \u001b[0;30;48;2;166;216;84m##if\u001b[0m \u001b[0;30;48;2;255;217;47m=\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98m>\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195melse\u001b[0m \u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47mtwo\u001b[0m \u001b[0;30;48;2;102;194;165mta\u001b[0m \u001b[0;30;48;2;252;141;98m##bs\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195m\"\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47mThree\u001b[0m \u001b[0;30;48;2;102;194;165mta\u001b[0m \u001b[0;30;48;2;252;141;98m##bs\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195m\"\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m12\u001b[0m \u001b[0;30;48;2;102;194;165m.\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m*\u001b[0m \u001b[0;30;48;2;231;138;195m50\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m600\u001b[0m \u001b[0;30;48;2;102;194;165m[SEP]\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"bert-base-cased\")"]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "6ff391dfd6944740a81c1b12d88d0fba",
            "246d95b1fc9f40d0b8c430a355811e46",
            "98fe8bbf39b6478d80ad6cd1df2faa95",
            "7cce0465b63b406b9c3091787c1a0b77",
            "e23b62891c354e47aa7b2166cbeb7ca0",
            "b092f17b77bb4b558ed7ef303817a47a",
            "e4fa46868951444a98db09e048d0535a",
            "685740b95a2543699746050162bb288a",
            "131c4ee368e645f1a16daa1b292d3c65",
            "e26a8aba1c0043789c77bdff2ba628f6",
            "12eeafcb07f84893893899c13b6ede7c",
            "4b3473f6dc994145b878fa27a631f9a6",
            "1b8a58b5ab4d40baa10a9f6a6992e022",
            "6887655bfaac4cdfbcc336301917d26a",
            "a7b9d5158f154e8ca6aceb4bec44d07e",
            "a9d7b3ec8b4a4dd48122bd68cf348a13",
            "f1618d4edf034bf58afec7b7f79dab45",
            "f8baf4f1381f41d991e6fabd488b5717",
            "cedfe3dec1ab4082a769a164e8366c11",
            "4aa4cc61dbf04965bb794077ba27c035",
            "c4ba9c99275548748536f31b67ec8da3",
            "3d7ffde568de4333bceaaf4b7e9b15c4",
            "4019a39bb1fb47fdad7d2cb40761b56f",
            "2ded285bee5c45ce905de573b43d5ce4",
            "70839cf1e52b4582be1b558d250b8727",
            "35ef0e10e14d44e0bdc2bdd3eddb42ab",
            "89ce52707eac4fe88caa451e7bb7f5ea",
            "c4c3ac49eaff4269b1789d02de952da0",
            "ece6c00179164dedbee78a3fa31fc51c",
            "b822e67a1f2d45a4afb6331a4a8bb2f7",
            "ad27f2cac4584a819988bed070fccdb4",
            "b47ebf9170cf49038a7dd845bc99d5fd",
            "bbf789679371484f9e270a5842e20af7",
            "83b48f5cd4dc4eef8105d451cc733bec",
            "d60a0e994ea3499aa70aedb706ae5ba5",
            "5f355f05be094813939f0ee0b07c83b0",
            "4fabf457f80b4535b8631c5c1e8b1b46",
            "3aa481bfecaf42d4a95e52a4ea1b0d44",
            "b0ada5e7c9a54a16b7f58e1fe51e51a6",
            "3c6eb2cddfbb497f98ecfb0f3abc75cb",
            "b6bc223a202445be85d2dd4886862804",
            "8fd36852bd844b5bb00d7ed3b8659a86",
            "51aff6b87e02499daa06320211dc03c2",
            "3173b231281f4e08b0b74f92612fc9f8",
            "42e3c9b1f0bc4fa792cd9d9a4f2e39fe",
            "6c2f20eb3a164cfcb1cb208d55c27504",
            "3bb492e091ec4d7096eb6917080a5ec4",
            "3af083c1f73143eabc04c48841d76701",
            "bf1036b8b2b94f4c951c843b8d5fafc2",
            "084e6dd0b1de4fdc863f842a88562118",
            "7f158021ad0d4492976104ef9cd5aa02",
            "93d0b0d828a74211a0d257a72ec9829a",
            "9d0f46e416e045c2ab117ead7393b45b",
            "a2c38267671e43ea8636dd9a73b5ff14",
            "81c161171eda43a9bf036984bc5684ef"
          ]
        },
        "id": "K_k5QduY5H0u",
        "outputId": "0f5e25c0-8f3e-45da-9f71-a3ee9e820cb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ff391dfd6944740a81c1b12d88d0fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b3473f6dc994145b878fa27a631f9a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4019a39bb1fb47fdad7d2cb40761b56f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83b48f5cd4dc4eef8105d451cc733bec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42e3c9b1f0bc4fa792cd9d9a4f2e39fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAP\u001b[0m \u001b[0;30;48;2;166;216;84mITAL\u001b[0m \u001b[0;30;48;2;255;217;47mIZ\u001b[0m \u001b[0;30;48;2;102;194;165mATION\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m  \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m\n",
            "\u001b[0m \u001b[0;30;48;2;231;138;195mshow\u001b[0m \u001b[0;30;48;2;166;216;84m_\u001b[0m \u001b[0;30;48;2;255;217;47mt\u001b[0m \u001b[0;30;48;2;102;194;165mok\u001b[0m \u001b[0;30;48;2;252;141;98mens\u001b[0m \u001b[0;30;48;2;141;160;203m False\u001b[0m \u001b[0;30;48;2;231;138;195m None\u001b[0m \u001b[0;30;48;2;166;216;84m el\u001b[0m \u001b[0;30;48;2;255;217;47mif\u001b[0m \u001b[0;30;48;2;102;194;165m ==\u001b[0m \u001b[0;30;48;2;252;141;98m >=\u001b[0m \u001b[0;30;48;2;141;160;203m else\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m two\u001b[0m \u001b[0;30;48;2;255;217;47m tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\"\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \"\u001b[0m \u001b[0;30;48;2;255;217;47m Three\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\u001b[0m \u001b[0;30;48;2;141;160;203m \"\u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m\n",
            "\u001b[0m \u001b[0;30;48;2;255;217;47m12\u001b[0m \u001b[0;30;48;2;102;194;165m.\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m*\u001b[0m \u001b[0;30;48;2;231;138;195m50\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m600\u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"gpt2\")"]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "b4cbdf1916f44e379f9d797570d1ea51",
            "6561ddefe89e45499c6065db2bde56f7",
            "f34d15e4b0e7412c8464e9aa7d37e430",
            "05d8c1699c034f6791f5ffcc26051c11",
            "a3bf2d39caf1426a9be3a8c511255ba2",
            "6e5c471da49f45168f7182460b96393d",
            "405bfa8f60a14e428df30664d62d2cc5",
            "a5e7a3e433d74adeaf412169091dcb08",
            "6fe24c82c77d4e2a9a33beb08c1fc374",
            "da152e7dde054ee191e04b9fe56f888b",
            "9c6df17ed1344093a19596ee4128e752",
            "dc1ac59a4fc74f878add22bbe7ecf1ca",
            "922185f92cbc411a9f7f2847bdba9b1f",
            "f8356f7304e44c8eb3f1f2fe6afc6166",
            "9979b730d3c7451dabeea2928638c400",
            "c5a9e31bff3940cbb6b91a2a8102fb5e",
            "c219f2ecf5684e3398efdb77aef0fc2b",
            "54283a8bde284b68bb9ccf3f8b57de52",
            "a48387cf2b5541899ffa94805828759b",
            "ad01fd43ac3945a395cdbff315087e2b",
            "dba7f8ba4e6c4789ae335734482ca904",
            "688337d86fe3498eb8e165086e5946b4",
            "3f3e7df308954fc481e09d85782ce3a1",
            "e20e4b5cb1fc4ec5824b1361dce9cb80",
            "c07f33165b3f462dbd4eaaed737d9869",
            "0bd32345441e44469f702706fbf8b8fd",
            "8fbf59e27c5d41cf9f6555998204484d",
            "a701601ac7f147e683178700c9ec7256",
            "2105b74f08334fff9850615fddc7a7eb",
            "a13e261cd406457791b6f72f4dfb70cf",
            "ef571fe90ab649e88d7dce907b758ca9",
            "56caa7866a8d44688aa8a21bff823e16",
            "4e1b184923ba421884954bd26776efa5",
            "40e2622c6473442f922c876789463f50",
            "7d0e7f88483d46f99feabfdc4edd4f2c",
            "397573565a314a17b09e615183f1f805",
            "3fdb5787e119483091676683c324ab3e",
            "2e827675d13d41039c4c23fce164a03c",
            "1f09d6fdf4294a5d98ca3474505f138c",
            "53af33fcc5b74bb783c7c7b2494225f5",
            "988eebb0802d4b588b2866d14394247f",
            "d7576c9176b146499f3b43ce200308f6",
            "431110d0e58e4c73bb185bf45faa00da",
            "e04cdbc5d5d9463bba2535dc041dbbf2"
          ]
        },
        "id": "EJn5nf3c5H2_",
        "outputId": "82bb015f-f106-4902-ba05-cf2da5f97035"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer_config.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4cbdf1916f44e379f9d797570d1ea51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc1ac59a4fc74f878add22bbe7ecf1ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f3e7df308954fc481e09d85782ce3a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["special_tokens_map.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40e2622c6473442f922c876789463f50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165mEnglish\u001b[0m \u001b[0;30;48;2;252;141;98mand\u001b[0m \u001b[0;30;48;2;141;160;203mCA\u001b[0m \u001b[0;30;48;2;231;138;195mPI\u001b[0m \u001b[0;30;48;2;166;216;84mTAL\u001b[0m \u001b[0;30;48;2;255;217;47mIZ\u001b[0m \u001b[0;30;48;2;102;194;165mATION\u001b[0m \u001b[0;30;48;2;252;141;98m\u001b[0m \u001b[0;30;48;2;141;160;203m<unk>\u001b[0m \u001b[0;30;48;2;231;138;195m\u001b[0m \u001b[0;30;48;2;166;216;84m<unk>\u001b[0m \u001b[0;30;48;2;255;217;47mshow\u001b[0m \u001b[0;30;48;2;102;194;165m_\u001b[0m \u001b[0;30;48;2;252;141;98mto\u001b[0m \u001b[0;30;48;2;141;160;203mken\u001b[0m \u001b[0;30;48;2;231;138;195ms\u001b[0m \u001b[0;30;48;2;166;216;84mFal\u001b[0m \u001b[0;30;48;2;255;217;47ms\u001b[0m \u001b[0;30;48;2;102;194;165me\u001b[0m \u001b[0;30;48;2;252;141;98mNone\u001b[0m \u001b[0;30;48;2;141;160;203m\u001b[0m \u001b[0;30;48;2;231;138;195me\u001b[0m \u001b[0;30;48;2;166;216;84ml\u001b[0m \u001b[0;30;48;2;255;217;47mif\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98m=\u001b[0m \u001b[0;30;48;2;141;160;203m>\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84melse\u001b[0m \u001b[0;30;48;2;255;217;47m:\u001b[0m \u001b[0;30;48;2;102;194;165mtwo\u001b[0m \u001b[0;30;48;2;252;141;98mtab\u001b[0m \u001b[0;30;48;2;141;160;203ms\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165mThree\u001b[0m \u001b[0;30;48;2;252;141;98mtab\u001b[0m \u001b[0;30;48;2;141;160;203ms\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165m12.\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m*\u001b[0m \u001b[0;30;48;2;231;138;195m50\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m600\u001b[0m \u001b[0;30;48;2;102;194;165m\u001b[0m \u001b[0;30;48;2;252;141;98m</s>\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"google/flan-t5-small\")"]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "5a5e40d4696b4b39adf1a97a6523442e",
            "42d1866dfcdb47c7807d968cc1fe76e0",
            "4394c656c82c48e6879749d54b46b38d",
            "e9009153d68c4254b1719bfcc68a70f0",
            "4c6c1c9c3ad34b7a9a5b4c859e96de55",
            "a38260c096514c8ea575e1645c81bfb7",
            "53c8daa4cc814bccb88533c2705cfe71",
            "4db7a1f5e35d4319964132925dcf67e3",
            "fa80e186fe43412793d8d0eca9d30977",
            "476dcdb001584b84b5973e7fa2a26c38",
            "af1d23da896841168fd9d16ed207d7b4",
            "d63c1b3e2a2b440c889fab4b4295c58d",
            "5db88608af4541b9b11e0a98cd9be75c",
            "138a65203530407991e46d5e958f68b7",
            "f9b62a5bf20b44279dce06d3f738b42d",
            "d974ca13f44d406597950d0dad2985ca",
            "c4317936b60544d6a892b17087ef99f5",
            "e2788e6a91484479ad55aa3af3fceacf",
            "55dfb98b2a924810bac669b2acdc10f8",
            "3c4cd733c04f42edb92010de223461af",
            "90bcbaa04ad04c65986072e574b49c1c",
            "ee5776b64dc24e599431cc1a1478dd4a",
            "5dd06e73660749cfbd854df1f5ee78d3",
            "4ce06321656a45529a79963d88151f53",
            "c81bf15b2521441ab0302724af828191",
            "3a8def5e9bad453d9cfd9d95ae87b943",
            "9ce21d77e6a248fa8433ec4476885e85",
            "71da746ca6774e7daf0f8a4615829edd",
            "fbaaa6a5a3394e10b98358697d48078b",
            "1d83134627a3424982e7774c88c6f3ee",
            "113597551c5a49d9afab5c052925b9ce",
            "7f56cff475744bed8c46b542cb582a8b",
            "50597ba11da149f3bc8ab4a017eb9103",
            "9aa2e30a2b544c78b92fada8302ef29d",
            "9074129d9b72417e846609124162eeeb",
            "9a762791599141d0a7f0af30f96ca974",
            "683384c3d6dc486b85bf45877794efbb",
            "8e60ad32afaa4c15861e7a50dd1c7e0a",
            "004fd7ae1e2f4a41b220a6828b200f09",
            "859512e6a4734239ac4f008d52a21051",
            "188a6a2848374828bf13c2f57f973412",
            "7fb0ac0ef4ef4b6facc0d97307e4c217",
            "9d71573c3a7a4db5a75f2bde82a5e28d",
            "ede384f4230041ab89009338ef4b931b",
            "23c842b7c2bf426fa542da7ec6255fff",
            "e1e84df8a6734c2684a56acaf4a1d91f",
            "45fb3f23e6b04d1c8caf05150d4eb5c2",
            "c0995159d30846a58d692fd0cb059d40",
            "b7a74ff584c649f5a1859c315192ae58",
            "c8849ffc00bd4abbb32b7432b8fdaa23",
            "7fe16e5813e7479491c3d86da22b2f7d",
            "a17372ea86ac420f96160f7d577e4447",
            "44e2d67a87a446c2a29ac97c095b4eed",
            "75e70f2059db4360b1700a40dfd01e71",
            "aed7ab1ffa484848ad9906580c8bed78"
          ]
        },
        "id": "1ymhAsTg5H5e",
        "outputId": "8504d261-03f9-4ec0-e6ab-88c893cb72f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a5e40d4696b4b39adf1a97a6523442e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["vocab.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d63c1b3e2a2b440c889fab4b4295c58d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["merges.txt: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dd06e73660749cfbd854df1f5ee78d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9aa2e30a2b544c78b92fada8302ef29d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23c842b7c2bf426fa542da7ec6255fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAPITAL\u001b[0m \u001b[0;30;48;2;166;216;84mIZATION\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m  \u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_tokens\u001b[0m \u001b[0;30;48;2;231;138;195m False\u001b[0m \u001b[0;30;48;2;166;216;84m None\u001b[0m \u001b[0;30;48;2;255;217;47m elif\u001b[0m \u001b[0;30;48;2;102;194;165m ==\u001b[0m \u001b[0;30;48;2;252;141;98m >=\u001b[0m \u001b[0;30;48;2;141;160;203m else\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m two\u001b[0m \u001b[0;30;48;2;255;217;47m tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\"\u001b[0m \u001b[0;30;48;2;252;141;98m   \u001b[0m \u001b[0;30;48;2;141;160;203m \"\u001b[0m \u001b[0;30;48;2;231;138;195m Three\u001b[0m \u001b[0;30;48;2;166;216;84m tabs\u001b[0m \u001b[0;30;48;2;255;217;47m:\u001b[0m \u001b[0;30;48;2;102;194;165m \"\u001b[0m \u001b[0;30;48;2;252;141;98m      \u001b[0m \u001b[0;30;48;2;141;160;203m \"\n",
            "\u001b[0m \u001b[0;30;48;2;231;138;195m12\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m*\u001b[0m \u001b[0;30;48;2;252;141;98m50\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m600\u001b[0m \u001b[0;30;48;2;166;216;84m\n",
            "\u001b[0m "
          ]
        }
      ],
      "source": [
        "# The official is `tiktoken` but this the same tokenizer on the HF platform\n",
        "show_tokens(text, \"Xenova/gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "2ab3d8d9da0440a78b2db8a2c73abf41",
            "152ee2339a2a40f19d88850131e680d6",
            "b97f7be2670d4ce9890aa60cf54daf8c",
            "61deb57c2ca442618ca594c3b7076016",
            "7b51da0e1f1440f5a32fe26787c50832",
            "81d3c396d0234e2d812087d4078b7790",
            "9641fe4a8e4047079bcf31c2a9abd607",
            "eb895a1a6fb84c278b8a6b727efd01ff",
            "13f3396c4d724ddab1c7171aa8c19f78",
            "6eb539e62ccd48f1b512d2f2908e8d1c",
            "0288fb56c2a64ad78abc715e5681d1d4",
            "ee83a0dcf21a4ed8aa94b992fe128579",
            "c57bc3e9eeae4db9b2a66dc16495f204",
            "db42f65741004538b05371875528dfb8",
            "703f601b6da141709efed7aed0d565b2",
            "9bda416caa28400ab1c85919b4e5cf4c",
            "48cf0cf63a9441d5a8d457cdf09a7e37",
            "94f41e087d9444708a67af77ac2b9932",
            "92af7b2f359c44759e5982898bcc739d",
            "f7667dca541c47228289245e3acbcc64",
            "53aea35fdf1c4597b5916310be479077",
            "4f4330be261740579af85a0b081df2b1",
            "2e78c283561c4ce8965f4c9fe8cf3c8b",
            "dab04d49810c413286092a8effe9247e",
            "69fcd5a5fbe740b8b4b020fca4efab46",
            "1d0dccbec453455ca4bc7e7c6c5ef9fa",
            "bd91306d947e4e3eba1228e4cc3c00c0",
            "b6e99f5a07a24ef5a1a64967c2cf624f",
            "b4dc452b2de84d5cb646f36d0a5ca2da",
            "5148564bc3e74f22b52f911f7522e3da",
            "37881327b22c45b2ac90b1146be37d62",
            "88b5b7531cfe4593b8ed5a684ed4f263",
            "a5431b3a9e7041ed90fb1b0b243f2eea",
            "081c097084fe4b0ea97e4b26e3986151",
            "37b26eb710c74eb1b31fc9b8ec6427ff",
            "52a686d0dd414d558bd0ea5b6d5149fb",
            "aec80b1ca9db495d82a93669168432ad",
            "b8a37c6b348844cbac0fe77794fc01a3",
            "26000c0bd9d44ebe976e2c3db2d6c441",
            "4f1a52b796e546b38a13e45d73344ae6",
            "568bceb81daf49179cc1c66ed240b024",
            "38fa340d41164e339d7952735784c2f4",
            "3fbdd54cba224775905601fc80659875",
            "6e57dbbec895498e89fe484489cbdd15",
            "5008c04ee5654110b4e93af3b996d409",
            "03cf44c3a22f47deaeb74d045ee457d7",
            "34363421e32449f48d4f09312c1aa500",
            "eb5d7d65234346b1b51bbf04b5c7a6d1",
            "48458562dc764b25b7a5b01eeb1d373f",
            "419ec8d333da4ae99474fa05fefd4bdd",
            "1a02cbd0922a40bab080bdc80875369b",
            "48f6297c51f348f7ba08b7c6e321f93e",
            "21eacb2db39e4e7dac0e286b63976f03",
            "8f483273b553445998f965cb7dadec71",
            "f4aadbb94efc4e85abd0c9499e6a06a8"
          ]
        },
        "id": "3_vAyeTy5H7_",
        "outputId": "1ea12932-37b6-4ed5-b7cb-dc3c0796ca2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer_config.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab3d8d9da0440a78b2db8a2c73abf41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["vocab.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee83a0dcf21a4ed8aa94b992fe128579"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["merges.txt: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e78c283561c4ce8965f4c9fe8cf3c8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "081c097084fe4b0ea97e4b26e3986151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5008c04ee5654110b4e93af3b996d409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAPITAL\u001b[0m \u001b[0;30;48;2;166;216;84mIZATION\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_\u001b[0m \u001b[0;30;48;2;231;138;195mtokens\u001b[0m \u001b[0;30;48;2;166;216;84m False\u001b[0m \u001b[0;30;48;2;255;217;47m None\u001b[0m \u001b[0;30;48;2;102;194;165m elif\u001b[0m \u001b[0;30;48;2;252;141;98m ==\u001b[0m \u001b[0;30;48;2;141;160;203m >=\u001b[0m \u001b[0;30;48;2;231;138;195m else\u001b[0m \u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47m two\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\"\u001b[0m \u001b[0;30;48;2;141;160;203m   \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m Three\u001b[0m \u001b[0;30;48;2;255;217;47m tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m \"\u001b[0m \u001b[0;30;48;2;141;160;203m      \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m\n",
            "\u001b[0m \u001b[0;30;48;2;255;217;47m1\u001b[0m \u001b[0;30;48;2;102;194;165m2\u001b[0m \u001b[0;30;48;2;252;141;98m.\u001b[0m \u001b[0;30;48;2;141;160;203m0\u001b[0m \u001b[0;30;48;2;231;138;195m*\u001b[0m \u001b[0;30;48;2;166;216;84m5\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98m6\u001b[0m \u001b[0;30;48;2;141;160;203m0\u001b[0m \u001b[0;30;48;2;231;138;195m0\u001b[0m \u001b[0;30;48;2;166;216;84m\n",
            "\u001b[0m "
          ]
        }
      ],
      "source": [
        "# You need to request access before being able to use this tokenizer\n",
        "show_tokens(text, \"bigcode/starcoder2-15b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "3cdd2e40af9740b18abfe00af12335b3",
            "ca0ad2808b06423cb4bb7e25abac5bae",
            "a325715f88ae4a00be86866294d02f8d",
            "48b139fc88c04e379687b3ae5d0b7b56",
            "deedc52164274e66b78e983489fce07d",
            "a1181738849a42c3ac8d111cbe9de000",
            "12807e1b10854afcb770604485c51558",
            "1e83fa4f139a4995bfa3a7395509e793",
            "803cff3366a74ebd871e672f27e5a24c",
            "b824e73c617a49eaa719c63382667df2",
            "9971e8f0f9d1497ca25b5d7a25d34d5c",
            "7a07af2d8d4a421abb8c421c4b5eb640",
            "6d24a14fce8e45b5ac065644e4b26be3",
            "67bcf4e58d6e46d68ea78fc4a756b188",
            "1bdb7d5badb04908acf9724ce2df0173",
            "09dcaf5c12804a6d882dd6f65a543d45",
            "952c8fd9ea6942fb8dbda24060fe95b6",
            "b62d01f3f56d46a6954b56a01b48c7e5",
            "ffa549b9f49e461fb1f0e5e9c52bdc53",
            "621d96bb5c7b43c480f027898170ed02",
            "bf6d32a5000741879509efd84fb74bb9",
            "56b13b270c664a96a7f4cdd24d2ce940",
            "74ef5e1073ba4cbd9eb8de744819bc6a",
            "f8484ae3891a415eb8a5d431c59eb030",
            "2976f6dd779346d191846f4a97cb5949",
            "4f85705d861b4b85aaf0c4d4300bd524",
            "3b6ab51ee12745feaba4c5fe32a616f1",
            "9ee42b0039434e25b05f970b50c373e6",
            "c2643acd0203417ab0e6355caff26cf1",
            "2ecad4a8b9ac42e5bae909d538015c38",
            "6ea8428271c8475ca94cbe6e4fa1544d",
            "0c42ac7fd5a341379233ac7de161067e",
            "03c661a4752b4de9900f1e92cb614a77"
          ]
        },
        "id": "KeWcUdxY6I3u",
        "outputId": "2ae5d6fc-e227-4816-e1b0-ceb23b7c8663"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cdd2e40af9740b18abfe00af12335b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a07af2d8d4a421abb8c421c4b5eb640"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74ef5e1073ba4cbd9eb8de744819bc6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAP\u001b[0m \u001b[0;30;48;2;166;216;84mITAL\u001b[0m \u001b[0;30;48;2;255;217;47mIZATION\u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m  \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m\n",
            "\u001b[0m \u001b[0;30;48;2;231;138;195mshow\u001b[0m \u001b[0;30;48;2;166;216;84m_\u001b[0m \u001b[0;30;48;2;255;217;47mtokens\u001b[0m \u001b[0;30;48;2;102;194;165m False\u001b[0m \u001b[0;30;48;2;252;141;98m None\u001b[0m \u001b[0;30;48;2;141;160;203m elif\u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m==\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m>\u001b[0m \u001b[0;30;48;2;252;141;98m=\u001b[0m \u001b[0;30;48;2;141;160;203m else\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m two\u001b[0m \u001b[0;30;48;2;255;217;47m t\u001b[0m \u001b[0;30;48;2;102;194;165mabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\u001b[0m \u001b[0;30;48;2;141;160;203m\"\u001b[0m \u001b[0;30;48;2;231;138;195m    \u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m Three\u001b[0m \u001b[0;30;48;2;102;194;165m t\u001b[0m \u001b[0;30;48;2;252;141;98mabs\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m       \u001b[0m \u001b[0;30;48;2;102;194;165m\"\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203m1\u001b[0m \u001b[0;30;48;2;231;138;195m2\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m*\u001b[0m \u001b[0;30;48;2;252;141;98m5\u001b[0m \u001b[0;30;48;2;141;160;203m0\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84m6\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m0\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"facebook/galactica-1.3b\")"]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__QNj2Cohzz2",
        "outputId": "7286bf87-c1e7-401f-ccd2-622b6964704a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;48;2;102;194;165m\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203mEnglish\u001b[0m \u001b[0;30;48;2;231;138;195mand\u001b[0m \u001b[0;30;48;2;166;216;84mC\u001b[0m \u001b[0;30;48;2;255;217;47mAP\u001b[0m \u001b[0;30;48;2;102;194;165mIT\u001b[0m \u001b[0;30;48;2;252;141;98mAL\u001b[0m \u001b[0;30;48;2;141;160;203mIZ\u001b[0m \u001b[0;30;48;2;231;138;195mATION\u001b[0m \u001b[0;30;48;2;166;216;84m\n",
            "\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203mshow\u001b[0m \u001b[0;30;48;2;231;138;195m_\u001b[0m \u001b[0;30;48;2;166;216;84mto\u001b[0m \u001b[0;30;48;2;255;217;47mkens\u001b[0m \u001b[0;30;48;2;102;194;165mFalse\u001b[0m \u001b[0;30;48;2;252;141;98mNone\u001b[0m \u001b[0;30;48;2;141;160;203melif\u001b[0m \u001b[0;30;48;2;231;138;195m==\u001b[0m \u001b[0;30;48;2;166;216;84m>=\u001b[0m \u001b[0;30;48;2;255;217;47melse\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98mtwo\u001b[0m \u001b[0;30;48;2;141;160;203mtabs\u001b[0m \u001b[0;30;48;2;231;138;195m:\"\u001b[0m \u001b[0;30;48;2;166;216;84m  \u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165mThree\u001b[0m \u001b[0;30;48;2;252;141;98mtabs\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195m\"\u001b[0m \u001b[0;30;48;2;166;216;84m     \u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m \u001b[0;30;48;2;252;141;98m1\u001b[0m \u001b[0;30;48;2;141;160;203m2\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m \u001b[0;30;48;2;255;217;47m*\u001b[0m \u001b[0;30;48;2;102;194;165m5\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m6\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m\n",
            "\u001b[0m "
          ]
        }
      ],
      "source": ["show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tu7OY4HvBEm"
      },
      "source": [
        "# Contextualized Word Embeddings From a Language Model (Like BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "3388a0231c9a4fda99ed43da0f82cada",
            "d83bfb1cc9b24527b5acb9e3769f2a1e",
            "5281c734a90d4062afd2f08c1fe5d6f3",
            "e64acf9a27e3496181315fdbeffcf239",
            "ac1806d36d5e4cde8c2ee7534d2455fa",
            "4f687ee0a7bc4a5db9475e1ba445da6c",
            "c115dde101974750b66a148a788b584b",
            "51ab17da23d944b6ac4606d76bd94004",
            "86929bd1be714c1a88983b4e020ca175",
            "1caa12086c924fb780dbb8bdff550225",
            "0696490d73c14982aa9604af78fec56e",
            "5f44aa726b704766a227cc1103b38192",
            "07bcfd0ac22b4012a6611b3c498c4e83",
            "5fc8cf54c2384e049c02eb37dec7c9d9",
            "2a573627fb72442dbfb9d248340b516d",
            "12ab4874a58f439fa8c25219f316ec27",
            "c3c0260c3b56497b82040a039b612bfd",
            "081f52a363804a2d9bc5e7317374bab2",
            "c71bed31be2c4824b3453c6abccaf692",
            "47d031a44ae848acadf487c91d85be34",
            "1db8bd60d14d4ed99da9d31707806a00",
            "363c1899f442482fac6f2cfa934df206",
            "5c1fb7bb37364e81bf10719c9f3e981e",
            "a2302ae1c7a24c8ba5ca38a9b8a35047",
            "fbd18dfa5f264226a5e368c2c5cd7897",
            "abe511abd67c4217ab1ee76e2d30e94b",
            "6299f73dd1be4513936ded3ca656606f",
            "1ff1080cc5434b21a940e15a5578c4da",
            "56b50aa402b9445492f8018efbc2761b",
            "f8a2bad652174eb2ac043e86b67a09a0",
            "f2cb9c5c767543959a633ee347b741cc",
            "195b3043d5e54c448cd926c32b396e1c",
            "20252cd97b974bdf9d227ee94602771d",
            "2704f9e951dd474fac8432abfd75ad85",
            "39bd88c61ba24cdb82ee0708a07dfa83",
            "a5c59d82092a4a72b7016b27933b2818",
            "a38c3ef3f6ae437f8bb928ec2c1584c3",
            "914568c3debf434c8df46474c6a017b3",
            "4beae4d4a75c4ef79dc006a4454fd434",
            "9638fa0e023a4e279081d1ee797a6cf4",
            "01d64e65aefe494aa04935364727951b",
            "b8506feaabf64a61a61e9cf644cfc1fa",
            "fed3923c94894eb39328a8d9e7db0d54",
            "c11d939bdca34c6face4805a37bb600d",
            "2f414255225a4bf1b466dfd845adde33",
            "e517f900b0a749fc82c23e127ec5ad99",
            "ef50375fb9f34494a2e516ff48e2f491",
            "de170d634ad74de8a86dd9b017ef83ce",
            "ffd7a91753ec4b1989496ed3c412d032",
            "bb9eaebae01645f4b57083dadaa824ea",
            "ca1c97a349d84450a0b91a87d62c04da",
            "a502e91915a4417ba47ce1ef2cd22744",
            "50743383718044f1b1c71f9839cae7f6",
            "4e775228373945d4ad13a3046da82ff6",
            "1e6610d6f1c14cfa9251711bd39a66e7",
            "6ddc66bac3b44211a9b6213175ae669a",
            "0a939efa1f264af195047da87081f404",
            "a15dd0f215ec4bc78ab6645b009381c4",
            "cd64cee45e7a494da7bb408b3dfa0b79",
            "ad2aa30bef1c491b9fa220bbf2219600",
            "06f687eeac824f278cafe584b14f8629",
            "313d1db4e8204ebdaaf2349b8078ef19",
            "1ff6d598bc1d40b3bd2bc7b19adf9211",
            "dd8bc8cb91e7400e9788b4a69eab4625",
            "fc097aa9d01d4ae69e33f17bd25f5cb5",
            "5b2a8035fafb480eb268bd0d20cd956b",
            "2b961d5e4624452397c27d2d7556b60a",
            "6f45a78bba734788a163f256029254e8",
            "01dc833e49d7428b9641ad70250e142b",
            "d90745c502b24ac8a150fad111b7f79f",
            "aaf47619bfca420d929bd46d0115ee38",
            "06835994277e4f84856b90d9d80e8b4e",
            "c9af5ffd9d614b08bd1fc5c739872f61",
            "1a2c63a8495f41148a51716a9b0b7d5c",
            "081c2868f19e46a7a05796e239a97274",
            "e89aa6236ac74262b96062ff3cef7a06",
            "5d705f9a0ec34c45b2f9a4d6d4a905a2"
          ]
        },
        "id": "nsjz-VsYu9bB",
        "outputId": "99c210bd-c97f-4963-e281-4bc4d8826a57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3388a0231c9a4fda99ed43da0f82cada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f44aa726b704766a227cc1103b38192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["vocab.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c1fb7bb37364e81bf10719c9f3e981e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["merges.txt: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2704f9e951dd474fac8432abfd75ad85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f414255225a4bf1b466dfd845adde33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ddc66bac3b44211a9b6213175ae669a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b961d5e4624452397c27d2d7556b60a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Load a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "# Load a language model\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer('Hello world', return_tensors='pt')\n",
        "\n",
        "# Process the tokens\n",
        "output = model(**tokens)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQly_KcbvDce",
        "outputId": "8e095879-4e63-4fe0-953a-e7dec75913e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ["torch.Size([1, 4, 384])"]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": ["output.shape"]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GcRrpPV0kVj",
        "outputId": "f2c54041-77ca-4134-a55d-90c20f216f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ["[CLS]\n", "Hello\n", " world\n", "[SEP]\n"]
        }
      ],
      "source": [
        "for token in tokens['input_ids'][0]:\n",
        "    print(tokenizer.decode(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8oHVC7B0lkk",
        "outputId": "14d7a964-17b0-4f2b-eece-b89b87b29d6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.4816,  0.0861, -0.1819,  ..., -0.0612, -0.3911,  0.3017],\n",
              "         [ 0.1898,  0.3208, -0.2315,  ...,  0.3714,  0.2478,  0.8048],\n",
              "         [ 0.2071,  0.5036, -0.0485,  ...,  1.2175, -0.2292,  0.8582],\n",
              "         [-3.4278,  0.0645, -0.1427,  ...,  0.0658, -0.4367,  0.3834]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": ["output"]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdEDuLWa0r4L"
      },
      "source": ["# Text Embeddings (For Sentences and Whole Documents)"]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "52426c3fe9114c17bf355a73d5ea706a",
            "0c8ad65f63bf44beb56c9286f2bfd1a2",
            "adf34e2e5e2243c28d4ab94dd14690da",
            "8417ba88277f405abb4bfaee0b70e628",
            "db2bf00661f2460aa5be77888fd8bf55",
            "008eeded431040a295074734679d64a4",
            "b19d6f2c11a845cea86e6bcab1bb8847",
            "c5825adfdb774735ba44f7a1e4bdf83c",
            "dfc56e2c3eed4896b2d50f9255cebbd0",
            "791a54b337d94bf4a258c50838b37ff5",
            "fe1385033a164ecfbac0fd53298ec35c",
            "a216679079f54afda100004d84fed2f5",
            "f8225e4ac7874c769014c42d6eb8d7a4",
            "7da2e18cb6fa4623970e57b90ad5865e",
            "9a1d751951bb4223af2d546de369c5a4",
            "60086148ba7e478d8976d4b6daf0e95c",
            "de18b61e0e324930bf69193fbb3cf4d0",
            "938ca4bf96f9486f88dedd243dea6743",
            "62db0d20e1374b9cb17f9f924fe7569a",
            "60f94797f11c4163a03b554d7d45e395",
            "bf3af4370bfa470fbc868ec8b2964efc",
            "cff1e08e7d6a4572945157959b7750cc",
            "5d860f0c99ae46419e5a6bcb23127241",
            "19cee048155d4a01bcbc8f911cb5b3ea",
            "7dd87fe9ff7841ed923c13bdc5dc6727",
            "1f5722ac7d3b4d6c9b3b612229eb4c1f",
            "d8d943ca3960400a8fd80d452bef587a",
            "efafde5bffd74e63adfadeec9869eb6f",
            "796e043bdb2348ffbbf04c00735c19d9",
            "cf589194fc04440c9f8d9dc0f9b2ffd8",
            "97b8b64cf5834885807b9cb9185da5da",
            "3c4b16d720794bf7af1518470119ad29",
            "4756afb6d9044cc2bc174e7b9239433b",
            "ba6b680d9a6c4807b5069f1d660b6c35",
            "8b7ac632453141c69e4a7cea31ceb050",
            "086e33f25f79483891c216cfd2c4b330",
            "ceb372048d25470abaf16a779464e549",
            "5cf530f5a65e4309b3fb43b44ce1e570",
            "17ae86d8b89b4d36b20cb29fb40347f4",
            "94d3b0dfd7b348ae87523a7ffb47566e",
            "94af4e69fb11433ab8a82c39bece6957",
            "6dabe54ee784481883fe2ba6d3f8fb4d",
            "9fa8b4c353904e7aaaadd5964b29a1de",
            "a6aa9105ade242538de25149049e4a4d",
            "3a72ab8058d4418ab5e6238337192c0a",
            "d92dee5cf96248798d0b35ab66495014",
            "69463692e2e84749b2f7b7992611a1f9",
            "d96ccff6b09f4329bc428e87f2f6a1da",
            "79b693984f0040eb9d92d19ed8a71711",
            "397436f688f04f719cf29b9a6ca0aa7c",
            "b51c0ec3ab424ee9a25ceaca99cfe841",
            "c9fdbd97162843c8bc25593605341979",
            "73a6ac8dc63d4c409c3ecba16c8b2ce4",
            "24f1513e2eb84b129939d36dca0b65b3",
            "21be3cf387c743e8b4f0f63d3d771122",
            "49fc7ea9703e43d99b1c94301b2c4e79",
            "42919f80623e48e28df1ad1f30b2fa24",
            "6101547986d640d4b4b8b2d5055144a4",
            "2d1d03afbae34cbd98ed16ee2b850942",
            "0c176d95873544ed804ab386ae3e0331",
            "a205df7073904cf288e7e51c69e8bfc1",
            "2666efa2c49f43e1a325cc0cdb4c50de",
            "66b90605be5b4b16b89f05dccf1e0194",
            "7b945946867643aeb1eb8f0cdbacbf35",
            "295dec0803b74307a06bb6718c7c9222",
            "9ba40b730c784e00bf84b11ab2aad1fa",
            "3f833ce65bc24fc1967b1cfc2805668f",
            "6ef9e93aac3b4ba1b95e36e2f803eec8",
            "3721af21491741f3bdb184597075f126",
            "d99f68ab012d4a35b01775a6c6a51eb1",
            "0f0ff9beac224d7ba7ef02bddfd6430f",
            "e62f635403a442d4a7575256b11efe2e",
            "7ce2252258e84a16a61532f5d53ef2c1",
            "cc4fcec756f04179a600ae27be1d0691",
            "394bfca19e484b749d5e1b2b33611e23",
            "2f520cfe25e54f5ea17cb899e518849f",
            "e3f5326636c346b79ef6b84a68b1cf1f",
            "28e6e11e3391440e9f786d3f9bbce112",
            "5fea17243b0847069f674b1b8e05e387",
            "2a8579257d534f6184e77e19290963c9",
            "f1b2e0d0553e43e392f1ab40ecefca45",
            "3ef0c5a21f284341a8b1de5907a47589",
            "8ab0c79fc98244a28df848c52df21276",
            "ccfe6cde9a1b47268f34518562d9ec04",
            "042d39e81ba84366ab81e5d2f6517f7f",
            "55be6ecf7bfb4100bad02c50f25277bc",
            "8f1e29bec3ef483ebc6ea1508f9ad7e8",
            "8e71c1b7a58c4af7a76aaa877e40efe2",
            "474b465bada8497ea1674cebd2fa0f79",
            "ee11d7901c6643328fb428b58d271149",
            "74205594f58c4c77bfb986aa5ab37960",
            "743de37b234f4b9e99069a71bf08fcdb",
            "f3cf2e8846494f049b628769c2845a5d",
            "1cd26861a41a418c88d73fbd906ed0fe",
            "0489b23abc76431291509e43d2027538",
            "d0f1c641af5b4aa483e11631cef98e32",
            "59a6b52184194e4fafb9b85252c56c52",
            "bb6befff873647839ca0a0c9bfb6935e",
            "877e8e0220884e2190b2a19745e706eb",
            "38be07b138894a59a160bed4a2f63d55",
            "8bd974bd73af41f79bf00fd359ca59fb",
            "b28aaab466d54cafb8620dd16774ed14",
            "7fa55294532b4371bd17d91bdb2249d8",
            "2454b51d11bd4a058014216399951c10",
            "803f6fda65814cdca7a6303f7a75db74",
            "40bc82416b374347a3e05920c172ab2d",
            "be0a6fa800984e5ba47893ae483f9857",
            "4e3ef213ae9b469a8f82e98b5538a993",
            "e166dfab6ee548e5a8fce09544e40ee5",
            "2a057816cf734400b8dc5fb4559e4572",
            "7a674a7dafbc4c878358f84d52bacedf",
            "43c7d088e2934d7d8814d462a091f404",
            "869fdb5c4be948f3a7e1d13452421d2f",
            "4a8bf06ce7b845039d00232883f69ea6",
            "fa2d9212e987453db753ccd9d490d227",
            "f7f0e5b348f249679f812928e2cb85bf",
            "b3a0712b77404950a9ab677190c2c641",
            "aa93b2e18fc644e197d5881aea45c845",
            "d9c97d1f2e304b88917543e1e7e5d881",
            "ffec2a8e382e4a7eb4b50daada5f56d3",
            "0fd2498588894c2487248781f68c8423"
          ]
        },
        "id": "TQHWioIc0pQ8",
        "outputId": "3ada8127-a5ce-42db-abaa-163e09a0f7cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52426c3fe9114c17bf355a73d5ea706a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a216679079f54afda100004d84fed2f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["README.md: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d860f0c99ae46419e5a6bcb23127241"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba6b680d9a6c4807b5069f1d660b6c35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a72ab8058d4418ab5e6238337192c0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49fc7ea9703e43d99b1c94301b2c4e79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f833ce65bc24fc1967b1cfc2805668f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["vocab.txt: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28e6e11e3391440e9f786d3f9bbce112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "474b465bada8497ea1674cebd2fa0f79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38be07b138894a59a160bed4a2f63d55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a674a7dafbc4c878358f84d52bacedf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load model\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Convert text to text embeddings\n",
        "vector = model.encode(\"Best movie ever!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDwfmBiC0uER",
        "outputId": "6f613f17-b1a1-4ca5-8ebd-4c34c233447c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ["(768,)"]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": ["vector.shape"]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnuGRjo80yKj"
      },
      "source": ["# Word Embeddings Beyond LLMs\n"]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the gensim section with this:\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def get_word_embedding(word):\n",
        "    \"\"\"Get embedding for a single word\"\"\"\n",
        "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        # Use mean pooling to get word representation\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings[0]\n",
        "\n",
        "def find_similar_words(target_word, word_list):\n",
        "    \"\"\"Find most similar words from a list\"\"\"\n",
        "    target_emb = get_word_embedding(target_word)\n",
        "    similarities = []\n",
        "\n",
        "    for word in word_list:\n",
        "        word_emb = get_word_embedding(word)\n",
        "        sim = F.cosine_similarity(target_emb.unsqueeze(0),\n",
        "                                 word_emb.unsqueeze(0))\n",
        "        similarities.append((word, sim.item()))\n",
        "\n",
        "    return sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# replaces the gensim king/queen example\n",
        "word_list = [\"king\", \"queen\", \"prince\", \"princess\", \"man\", \"woman\",\n",
        "             \"throne\", \"crown\", \"ruler\", \"emperor\", \"servant\"]\n",
        "\n",
        "similar_to_king = find_similar_words(\"king\", word_list)\n",
        "print(\"Words similar to 'king':\")\n",
        "for word, score in similar_to_king[:9]:\n",
        "    print(f\"  {word}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "c9be0779b89b4ffd95711fb2354ad314",
            "15c583bf5ebc4501952a280a735637ef",
            "705335268ec94ec18ae8d8c5d0ca4c3e",
            "16f9e321a6e242539e7d017ce0c26cae",
            "61d93016f80c416e9514cf6f7c375ea7",
            "7bdc5952129c443e9e72ef80e2f2c491",
            "8d76d3c6dece44c381af421ab1783c64",
            "9081e07fa6a54a1d9c60aa3499733b4c",
            "0fdd2fd773d34c63a471b67d014ae41c",
            "3c0efff76b49425db4bf89d05fe5dbab",
            "de566ed7b3504d6581b47186d9d37aef",
            "b5269e76b8794bdca0cfa64fea6820ec",
            "130b1bc5bf0c430b9bfb29a8fa0382d1",
            "fb74c4796be94dba88e253800677d1b1",
            "ac98da329f8a419f9c3d3d702d49f784",
            "3e2192b47f6341d4a0b4c9e3a3873462",
            "dfaf4ba974a9453f98483961c896972c",
            "29d3aa5818b24ce9991ea2a742c0f640",
            "e0a4a83b7a894134be325728667f6864",
            "8a58ba58534644bfbf182b40d8c155f4",
            "f13659c6ecec4bcb9c5379afdd8eda5a",
            "82e3234efa7b41399c338dd9a479d0aa",
            "aa58e846291541fb853f462a558a5282",
            "beceec95c21b4d8592a8421a1bcc65af",
            "c8d6e6bbaaaf426b8dc0fef588a21578",
            "4a1d887662864c1388fc4494c6409c15",
            "af9fb9c3497d40ab9471484eca62c37b",
            "d46ded97aa7e4211a43aada7e6d1df74",
            "7e1f9a90eb9d4004acd023ca6d328aca",
            "7c3db2cb3bf549f795cf96e31accac3d",
            "a7bedc79924d406a8414aacddba22f43",
            "8a0b79bb464c4317bc3312e4c5009439",
            "8e4743a95fc8445d948906c951c8e91a",
            "3cc482c9e1a64f47a04be0fd995321f9",
            "7fed376846eb499fb993d6e7db924479",
            "641f4481482a4b639ac7259ed61144ac",
            "d4a94a7ba129489fbf5905e5b2df3f1d",
            "12d98070901a44238456e5d18ae1f378",
            "2726a4eab0d94f7198d8ad3778c53939",
            "0847de1507f94dae8809d99f14b7ee97",
            "35980702f3084b39bda45140d8cbd097",
            "a20334215beb4a8ea22d5b4102f981fc",
            "f03361ea66ad44cbbf74389626a773d5",
            "375aa4cce1644a26bdf3f3999fefd658",
            "8ff7d9975edc4216b0b298c8d6e5e5eb",
            "f2986ec7549544b8bd4a568cb4eab2af",
            "f936d85ad9644ec08e43abcfa94c50c0",
            "1ec9e6eebede47d795a5a095d96c4675",
            "1b0e77147f2948cab6fdbdc4c2adbec1",
            "fdab5e8669ca4cd8bcd81be2fff6bfef",
            "b978b18d2724474b9846948a4e4b9b94",
            "b547d8ba826e43fcb59aa80c9885c6df",
            "a9261e849d1d40b69e68a407f4570213",
            "7875dc7b663644eeb959a6af06d78f27",
            "0af5118531e2493e90e409112cedbbc2",
            "25fba936bb8e4dce9c88210c5a37759b",
            "23efc7239d8942cd9eb17d57cb224722",
            "4314f26a2daa4a5bb434b61943e78856",
            "d306dee1111f4091ad4f52dae07b2c36",
            "4966d76445e1466e9bd6f2d4fc18abde",
            "acf646485bb847e29436d60a8fe0bcdb",
            "b0bea21d7d074923a40e8ea714830ee8",
            "86426e6e98854d52be940bbe618d4b69",
            "eb187f6decef45fa99f60d187bfa8487",
            "1080e3f1d75d42029ad85318ad9375f3",
            "b9b0acaab5274217b9eacd05c73846c6"
          ]
        },
        "id": "bU1XVrnzXT5V",
        "outputId": "9a82ff8f-294c-4162-f7ad-bd5042755fd2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9be0779b89b4ffd95711fb2354ad314"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5269e76b8794bdca0cfa64fea6820ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa58e846291541fb853f462a558a5282"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["vocab.txt: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cc482c9e1a64f47a04be0fd995321f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ff7d9975edc4216b0b298c8d6e5e5eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25fba936bb8e4dce9c88210c5a37759b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'king':\n",
            "  king: 1.0000\n",
            "  queen: 0.6807\n",
            "  throne: 0.6611\n",
            "  prince: 0.5884\n",
            "  princess: 0.4843\n",
            "  crown: 0.4721\n",
            "  emperor: 0.4697\n",
            "  servant: 0.3985\n",
            "  ruler: 0.3564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sKgNdnwe0vfK"
      },
      "outputs": [],
      "source": [
        "# import gensim.downloader as api\n",
        "\n",
        "# # Download embeddings (66MB, glove, trained on wikipedia, vector size: 50)\n",
        "# # Other options include \"word2vec-google-news-300\"\n",
        "# # More options at https://github.com/RaRe-Technologies/gensim-data\n",
        "# model = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "u_vj5NVn01aD"
      },
      "outputs": [],
      "source": ["# model.most_similar([model['king']], topn=11)"]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSgyKKS4xUx"
      },
      "source": ["# Recommending songs by embeddings"]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3dJdWzT67nDL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from urllib import request\n",
        "\n",
        "# Get the playlist dataset file\n",
        "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
        "\n",
        "# Parse the playlist dataset file. Skip the first two lines as\n",
        "# they only contain metadata\n",
        "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
        "\n",
        "# Remove playlists with only one song\n",
        "playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]\n",
        "\n",
        "# Load song metadata\n",
        "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
        "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
        "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
        "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
        "songs_df = songs_df.set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3zirG-lo3H8",
        "outputId": "5c5a44c7-fedd-4d5b-eee0-ec252c6929a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Playlist #1:\n",
            "  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '2', '42', '43', '44', '45', '46', '47', '48', '20', '49', '8', '50', '51', '52', '53', '54', '55', '56', '57', '25', '58', '59', '60', '61', '62', '3', '63', '64', '65', '66', '46', '47', '67', '2', '48', '68', '69', '70', '57', '50', '71', '72', '53', '73', '25', '74', '59', '20', '46', '75', '76', '77', '59', '20', '43'] \n",
            "\n",
            "Playlist #2:\n",
            "  ['78', '79', '80', '3', '62', '81', '14', '82', '48', '83', '84', '17', '85', '86', '87', '88', '74', '89', '90', '91', '4', '73', '62', '92', '17', '53', '59', '93', '94', '51', '50', '27', '95', '48', '96', '97', '98', '99', '100', '57', '101', '102', '25', '103', '3', '104', '105', '106', '107', '47', '108', '109', '110', '111', '112', '113', '25', '63', '62', '114', '115', '84', '116', '117', '118', '119', '120', '121', '122', '123', '50', '70', '71', '124', '17', '85', '14', '82', '48', '125', '47', '46', '72', '53', '25', '73', '4', '126', '59', '74', '20', '43', '127', '128', '129', '13', '82', '48', '130', '131', '132', '133', '134', '135', '136', '137', '59', '46', '138', '43', '20', '139', '140', '73', '57', '70', '141', '3', '1', '74', '142', '143', '144', '145', '48', '13', '25', '146', '50', '147', '126', '59', '20', '148', '149', '150', '151', '152', '56', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '60', '176', '51', '177', '178', '179', '180', '181', '182', '183', '184', '185', '57', '186', '187', '188', '189', '190', '191', '46', '192', '193', '194', '195', '196', '197', '198', '25', '199', '200', '49', '201', '100', '202', '203', '204', '205', '206', '207', '32', '208', '209', '210']\n"
          ]
        }
      ],
      "source": [
        "print( 'Playlist #1:\\n ', playlists[0], '\\n')\n",
        "print( 'Playlist #2:\\n ', playlists[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Turn\n",
        "\n",
        "Learn tokens and embeddings step-by-step. Each task provides a working example, your task is to modify and extend it."
      ],
      "metadata": {
        "id": "gmXgJKjqjGD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: See how different text types get tokenized\n",
        "# EXAMPLE PROVIDED - Run this first to see how it works:\n",
        "\n",
        "def analyze_tokens(text, tokenizer):\n",
        "    \"\"\"Analyze how text is tokenized and display results\"\"\"\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "    token_ids = tokens.input_ids[0].tolist()\n",
        "\n",
        "    print(f\"Original text: {text}\")\n",
        "    print(f\"Number of tokens: {len(token_ids)}\")\n",
        "    print(f\"Tokens per character: {len(token_ids)/len(text):.2f}\")\n",
        "    print(\"Individual tokens:\")\n",
        "    for i, token_id in enumerate(token_ids):\n",
        "        decoded = tokenizer.decode(token_id)\n",
        "        print(f\"  {i}: '{decoded}' (ID: {token_id})\")\n",
        "    print(\"-\" * 50)\n",
        "    return token_ids\n",
        "\n",
        "# Example usage:\n",
        "example_text = \"Hello World! 2024\"\n",
        "example_ids = analyze_tokens(example_text, tokenizer)\n",
        "\n",
        "# YOUR TURN:\n",
        "# 1. Change example_text to include: your name, an email address, and a price (e.g., $19.99)\n",
        "# 2. Run the analysis and observe how special characters and numbers are tokenized\n",
        "# 3. Try adding an emoji and see what happens\n",
        "\n",
        "your_text = \"YOUR_TEXT_HERE\"  # Modify this\n",
        "# your_ids = analyze_tokens(your_text, tokenizer)\n"
      ],
      "metadata": {
        "id": "_QhrfUzDj5rF",
        "outputId": "7918c760-702e-483a-d937-2f0536f73c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Hello World! 2024\n",
            "Number of tokens: 7\n",
            "Tokens per character: 0.41\n",
            "Individual tokens:\n",
            "  0: '[CLS]' (ID: 101)\n",
            "  1: 'hello' (ID: 7592)\n",
            "  2: 'world' (ID: 2088)\n",
            "  3: '!' (ID: 999)\n",
            "  4: '202' (ID: 16798)\n",
            "  5: '##4' (ID: 2549)\n",
            "  6: '[SEP]' (ID: 102)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions to consider:\n",
        "After running the example, answer these questions\n",
        "\n",
        "  Q1: Looking at your tokenization results, identify whether this tokenizer uses  word, subword, or character-level tokenization. Give an example to suport your answer. (Refer to Figure 2-6 in the chapter for tokenization types)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  Q2: See the special token at the beginning (token ID 1). Based on Chapter 2's\n",
        "  discussion of special tokens, what is `<s>` for?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  Q3: Calculate the compression ratio (characters/tokens). How does this compare to the ~4:1 ratio mentioned for English text in the chapter?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  Q4: Your email address was likely tokenized differently than regular words. Why is this be problematic for a model trained primarily on formal text?\n",
        "  Recall the \"unknown token\" problem discussed in the chapter."
      ],
      "metadata": {
        "id": "5K8U4ByI1EV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Compare how the same concept is tokenized in different forms\n",
        "# Building on Task 1's analyze_tokens function\n",
        "\n",
        "# EXAMPLE PROVIDED:\n",
        "texts_to_compare = {\n",
        "    \"lowercase\": \"artificial intelligence\",\n",
        "    \"uppercase\": \"ARTIFICIAL INTELLIGENCE\",\n",
        "    \"camelCase\": \"ArtificialIntelligence\",\n",
        "    \"with_symbols\": \"artificial-intelligence\",\n",
        "    \"with_numbers\": \"artificial1 intelligence2\"\n",
        "}\n",
        "\n",
        "print(\"Comparing tokenization patterns:\\n\")\n",
        "token_counts = {}\n",
        "\n",
        "for label, text in texts_to_compare.items():\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "    count = len(tokens.input_ids[0])\n",
        "    token_counts[label] = count\n",
        "    print(f\"{label:15} -> {count} tokens: {text}\")\n",
        "\n",
        "# Find most efficient\n",
        "most_efficient = min(token_counts, key=token_counts.get)\n",
        "print(f\"\\nMost token-efficient: {most_efficient} with {token_counts[most_efficient]} tokens\")\n",
        "\n",
        "# YOUR TURN:\n",
        "# 1. Replace \"artificial intelligence\" with a different two-word concept (e.g., \"machine learning\", \"data science\")\n",
        "# 2. Add three more variations: snake_case, with dots (.), and abbreviated form\n",
        "# 3. Identify which formatting is most token-efficient for your chosen concept\n",
        "\n",
        "your_concept_variations = {\n",
        "    \"lowercase\": \"YOUR_CONCEPT_HERE\",\n",
        "    \"uppercase\": \"YOUR_CONCEPT_IN_CAPS\",\n",
        "    # Add more variations here\n",
        "}\n",
        "\n",
        "# Analyze your variations using the same pattern as above\n"
      ],
      "metadata": {
        "id": "OeLnnOs8j9rF",
        "outputId": "5ca15bd0-c989-4b66-e774-12bf89d61110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing tokenization patterns:\n",
            "\n",
            "lowercase       -> 4 tokens: artificial intelligence\n",
            "uppercase       -> 4 tokens: ARTIFICIAL INTELLIGENCE\n",
            "camelCase       -> 6 tokens: ArtificialIntelligence\n",
            "with_symbols    -> 5 tokens: artificial-intelligence\n",
            "with_numbers    -> 6 tokens: artificial1 intelligence2\n",
            "\n",
            "Most token-efficient: lowercase with 4 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions to consider:\n",
        "\n",
        "\n",
        "Q1: The chapter mentions that GPT-4 has a vocabulary of ~100,000 tokens while BERT has ~30,000. Based on your results, which formatting (uppercase, camelCase, etc.) would benefit more from a larger vocabulary? Why?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q2: Notice how \"ARTIFICIAL INTELLIGENCE\" requires different tokens than \"artificial intelligence\". Referring to the chapter's BERT cased vs uncased discussion, what are the trade-offs of preserving capitalization in tokenization?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q3: The chapter shows \"CAPITALIZATION\" being split into 2 tokens by GPT-4 but 8 tokens by BERT. Based on your experiments, predict how many tokens your concept would need in each tokenizer and explain why.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q4: If you were designing a tokenizer for a code completion system (not natural language), which variation pattern would you prioritize optimizing for? Consider that code often uses camelCase, snake_case, and special symbols."
      ],
      "metadata": {
        "id": "5TyRqeWy2Okz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 3: Find patterns in tokenization by examining multiple examples\n",
        "# Building on Tasks 1 & 2\n",
        "\n",
        "# EXAMPLE PROVIDED:\n",
        "def find_token_patterns(word_list, tokenizer):\n",
        "    \"\"\"Find common patterns in how words are tokenized\"\"\"\n",
        "    patterns = {\n",
        "        \"single_token\": [],\n",
        "        \"multiple_tokens\": [],\n",
        "        \"starts_with_space\": [],\n",
        "        \"contains_special\": []\n",
        "    }\n",
        "\n",
        "    for word in word_list:\n",
        "        tokens = tokenizer(word, return_tensors=\"pt\")\n",
        "        token_ids = tokens.input_ids[0].tolist()\n",
        "        decoded_tokens = [tokenizer.decode(tid) for tid in token_ids]\n",
        "\n",
        "        # Categorize based on tokenization pattern\n",
        "        if len(token_ids) == 3:  # Accounting for special tokens\n",
        "            patterns[\"single_token\"].append(word)\n",
        "        else:\n",
        "            patterns[\"multiple_tokens\"].append(word)\n",
        "\n",
        "        # Check for space prefix (common in many tokenizers)\n",
        "        for decoded in decoded_tokens:\n",
        "            if decoded.startswith(\" \") or decoded.startswith(\"Ä \"):\n",
        "                patterns[\"starts_with_space\"].append(word)\n",
        "                break\n",
        "\n",
        "    return patterns\n",
        "\n",
        "# Example word list - technology terms\n",
        "tech_words = [\"computer\", \"algorithm\", \"cryptocurrency\", \"AI\", \"blockchain\",\n",
        "              \"machine\", \"learning\", \"neural\", \"network\", \"GPU\"]\n",
        "\n",
        "patterns = find_token_patterns(tech_words, tokenizer)\n",
        "\n",
        "print(\"Tokenization Patterns Found:\")\n",
        "for pattern_type, words in patterns.items():\n",
        "    if words:  # Only print non-empty patterns\n",
        "        print(f\"\\n{pattern_type}:\")\n",
        "        print(f\"  {', '.join(words[:5])}\")  # Show first 5 examples\n",
        "\n",
        "# YOUR TURN:\n",
        "# 1. Create your own word list with 10-15 words from a different domain\n",
        "#    (e.g., medical terms, cooking terms, sports terms)\n",
        "# 2. Add a new pattern category: \"contains_number\" or \"all_uppercase\"\n",
        "# 3. Analyze which types of words in your domain require more tokens\n",
        "\n",
        "your_domain_words = [\n",
        "    # Add your domain-specific words here\n",
        "]\n",
        "\n",
        "# your_patterns = find_token_patterns(your_domain_words, tokenizer)\n"
      ],
      "metadata": {
        "id": "S4-zBffwkXSs",
        "outputId": "a3b80163-9977-445b-fa2e-fb4bf1e28e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization Patterns Found:\n",
            "\n",
            "single_token:\n",
            "  computer, algorithm, AI, machine, learning\n",
            "\n",
            "multiple_tokens:\n",
            "  cryptocurrency, blockchain, GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions to consider:\n",
        "\n",
        "Q1: The chapter discusses how subword tokenization handles new/unknown words by breaking them into known pieces. Which words in your domain list demonstrate this behavior? How does this relate to the OOV (out-of-vocabulary) problem mentioned?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q2: Compare your results to Figure 2-3 from the chapter (GPT-4 tokenizer example). Do you see similar patterns with partial words?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q3: The chapter mentions training data influences tokenization. Based on your domain-specific words, what can you infer about the training data used for this tokenizer?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q4: If specialized domain terms (medical, legal, etc.) often require multiple tokens,\n",
        "  what implications does this have for:\n",
        "  a) API costs (charged per token)?\n",
        "  b) Context window limitations?\n",
        "  c) Model understanding of domain-specific concepts?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q5: The chapter discusses byte-fallback tokenization. Is there any words that might trigger byte-level encoding? What would be the trade-off?"
      ],
      "metadata": {
        "id": "P8etJZzy3NiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Extract and analyze relationships between token embeddings\n",
        "# Building on previous tasks, now working with embeddings\n",
        "\n",
        "# EXAMPLE PROVIDED:\n",
        "from transformers import AutoModel\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Load a model for embeddings (using smaller model for speed)\n",
        "embed_model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
        "\n",
        "def get_token_embeddings(text, tokenizer, model):\n",
        "    \"\"\"Get embeddings for each token in text\"\"\"\n",
        "    tokens = tokenizer(text, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)[0]\n",
        "\n",
        "    # Get individual tokens for labels\n",
        "    token_ids = tokens.input_ids[0].tolist()\n",
        "    token_labels = [tokenizer.decode(tid) for tid in token_ids]\n",
        "\n",
        "    return output[0], token_labels  # Return first batch item\n",
        "\n",
        "def analyze_embedding_similarity(text_pairs, tokenizer, model):\n",
        "    \"\"\"Compare embeddings between pairs of related texts\"\"\"\n",
        "\n",
        "    for pair_name, (text1, text2) in text_pairs.items():\n",
        "        emb1, labels1 = get_token_embeddings(text1, tokenizer, model)\n",
        "        emb2, labels2 = get_token_embeddings(text2, tokenizer, model)\n",
        "\n",
        "        # Calculate average embedding for each text\n",
        "        avg_emb1 = emb1.mean(dim=0)\n",
        "        avg_emb2 = emb2.mean(dim=0)\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        similarity = F.cosine_similarity(avg_emb1.unsqueeze(0),\n",
        "                                        avg_emb2.unsqueeze(0))\n",
        "\n",
        "        print(f\"\\n{pair_name}:\")\n",
        "        print(f\"  Text 1: {text1}\")\n",
        "        print(f\"  Text 2: {text2}\")\n",
        "        print(f\"  Similarity: {similarity.item():.4f}\")\n",
        "\n",
        "# Example: Comparing related concepts\n",
        "example_pairs = {\n",
        "    \"synonyms\": (\"happy\", \"joyful\"),\n",
        "    \"antonyms\": (\"happy\", \"sad\"),\n",
        "    \"related\": (\"dog\", \"puppy\"),\n",
        "    \"unrelated\": (\"happy\", \"computer\")\n",
        "}\n",
        "\n",
        "analyze_embedding_similarity(example_pairs, tokenizer, embed_model)\n",
        "\n",
        "# YOUR TURN:\n",
        "# 1. Create 4 new text pairs testing different relationships:\n",
        "#    - Two technical terms from the same field\n",
        "#    - Same word in different contexts (e.g., \"bank\" as financial vs river)\n",
        "#    - Two words in different languages (if supported by tokenizer)\n",
        "#    - A word and its definition\n",
        "# 2. Identify which relationship types have highest/lowest similarity\n",
        "\n",
        "your_pairs = {\n",
        "    \"technical_related\": (\"YOUR_TERM1\", \"YOUR_TERM2\"),\n",
        "    # Add more pairs here\n",
        "}\n",
        "\n",
        "# analyze_embedding_similarity(your_pairs, tokenizer, embed_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "UH7OB2iVk1X5",
        "outputId": "76e1e4d0-bbfc-448c-8f2c-4cf0763c82ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "synonyms:\n",
            "  Text 1: happy\n",
            "  Text 2: joyful\n",
            "  Similarity: 0.7765\n",
            "\n",
            "antonyms:\n",
            "  Text 1: happy\n",
            "  Text 2: sad\n",
            "  Similarity: 0.7143\n",
            "\n",
            "related:\n",
            "  Text 1: dog\n",
            "  Text 2: puppy\n",
            "  Similarity: 0.8345\n",
            "\n",
            "unrelated:\n",
            "  Text 1: happy\n",
            "  Text 2: computer\n",
            "  Similarity: 0.8413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q1: The chapter explains that contextualized embeddings (like from BERT) differ from static embeddings (like Word2Vec). Based on your similarity scores, provide evidence that these are contextualized embeddings. (Hint: Would \"bank\" have the same embedding in different contexts with static embeddings?)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q2: Figure 2-9 shows how token embeddings are processed. Your embedding dimension is 384.The chapter mentions GPT models can have 768 or more dimensions. What trade-offs exist between embedding dimension size and model performance?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q3: Your synonyms showed high similarity while antonyms showed lower similarity.How does this validate the chapter's claim that embeddings \"capture meanings and patterns in language\"?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q4: You calculated average embeddings by taking the mean. The chapter also mentions using [CLS] tokens for sentence representation. What are potential advantages/disadvantages of each approach?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Q5: If embedding similarity doesn't always match human intuition about word relationships, what does this tell us about what the model has \"learned\" during training?"
      ],
      "metadata": {
        "id": "f_CbM-vL4DZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Combine techniques from Challenges 1-4 into a comprehensive analysis\n",
        "# This brings together tokenization, pattern finding, and embedding analysis\n",
        "\n",
        "# EXAMPLE PROVIDED:\n",
        "def comprehensive_text_analysis(text, reference_text, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Perform complete analysis combining all previous techniques:\n",
        "    1. Basic tokenization stats (Task 1)\n",
        "    2. Pattern comparison (Task 2)\n",
        "    3. Token pattern discovery (Task 3)\n",
        "    4. Embedding similarity (Task 4)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"TEXT ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1: Basic tokenization (from Task 1)\n",
        "    print(\"\\n1. TOKENIZATION STATISTICS:\")\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "    token_ids = tokens.input_ids[0].tolist()\n",
        "    print(f\"   Text length: {len(text)} characters\")\n",
        "    print(f\"   Token count: {len(token_ids)} tokens\")\n",
        "    print(f\"   Compression ratio: {len(text)/len(token_ids):.2f} chars/token\")\n",
        "\n",
        "    # Step 2: Compare variations (from Task 2)\n",
        "    print(\"\\n2. FORMAT VARIATIONS:\")\n",
        "    variations = {\n",
        "        \"original\": text,\n",
        "        \"uppercase\": text.upper(),\n",
        "        \"lowercase\": text.lower(),\n",
        "        \"no_spaces\": text.replace(\" \", \"\")\n",
        "    }\n",
        "\n",
        "    for var_name, var_text in variations.items():\n",
        "        var_tokens = tokenizer(var_text, return_tensors=\"pt\")\n",
        "        print(f\"   {var_name:12} -> {len(var_tokens.input_ids[0])} tokens\")\n",
        "\n",
        "    # Step 3: Find patterns (from Task 3)\n",
        "    print(\"\\n3. TOKEN PATTERNS:\")\n",
        "    words = text.split()\n",
        "    long_words = [w for w in words if len(w) > 5]\n",
        "    short_words = [w for w in words if len(w) <= 3]\n",
        "\n",
        "    if long_words:\n",
        "        print(f\"   Long words (>5 chars): {', '.join(long_words[:3])}\")\n",
        "    if short_words:\n",
        "        print(f\"   Short words (â‰¤3 chars): {', '.join(short_words[:3])}\")\n",
        "\n",
        "    # Step 4: Embedding similarity (from Task 4)\n",
        "    print(\"\\n4. SEMANTIC SIMILARITY:\")\n",
        "    if reference_text:\n",
        "        emb1, _ = get_token_embeddings(text, tokenizer, model)\n",
        "        emb2, _ = get_token_embeddings(reference_text, tokenizer, model)\n",
        "\n",
        "        avg_emb1 = emb1.mean(dim=0)\n",
        "        avg_emb2 = emb2.mean(dim=0)\n",
        "\n",
        "        similarity = F.cosine_similarity(avg_emb1.unsqueeze(0),\n",
        "                                        avg_emb2.unsqueeze(0))\n",
        "        print(f\"   Similarity to reference: {similarity.item():.4f}\")\n",
        "        print(f\"   Reference: '{reference_text[:50]}...'\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    return {\n",
        "        \"char_count\": len(text),\n",
        "        \"token_count\": len(token_ids),\n",
        "        \"compression\": len(text)/len(token_ids),\n",
        "        \"similarity\": similarity.item() if reference_text else None\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "example_text = \"Artificial intelligence is transforming how we work and live\"\n",
        "reference = \"Machine learning is changing our daily lives\"\n",
        "\n",
        "results = comprehensive_text_analysis(example_text, reference, tokenizer, embed_model)\n",
        "\n",
        "# YOUR TURN - FINAL TASK:\n",
        "# 1. Choose a paragraph (3-4 sentences) about any technical topic\n",
        "# 2. Create a reference text that is:\n",
        "#    a) A paraphrase of your paragraph\n",
        "#    b) On the same topic but different viewpoint\n",
        "#    c) A simplified explanation of the same concept\n",
        "# 3. Run the comprehensive analysis on all three variations\n",
        "# 4. Add one new metric to the analysis function that combines at least 2 techniques\n",
        "#    (e.g., find the most semantically important token by combining embedding magnitude\n",
        "#     with token frequency, or identify tokens that change meaning most when context changes)\n",
        "\n",
        "your_paragraph = \"\"\"\n",
        "YOUR PARAGRAPH HERE\n",
        "\"\"\"\n",
        "\n",
        "your_reference_paraphrase = \"\"\"\n",
        "YOUR PARAPHRASE HERE\n",
        "\"\"\"\n",
        "\n",
        "# Run comprehensive analysis\n",
        "# your_results = comprehensive_text_analysis(your_paragraph, your_reference_paraphrase, tokenizer, embed_model)\n",
        "\n",
        "# BONUS: Create your own analysis metric\n",
        "def your_custom_metric(text, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Create a new metric combining multiple techniques.\n",
        "    Example: Find tokens that are both rare and semantically important\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "TwpRb9Cmk_H8",
        "outputId": "d25cdd5f-233a-47aa-da63-3c2f37d01d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TEXT ANALYSIS\n",
            "============================================================\n",
            "\n",
            "1. TOKENIZATION STATISTICS:\n",
            "   Text length: 60 characters\n",
            "   Token count: 11 tokens\n",
            "   Compression ratio: 5.45 chars/token\n",
            "\n",
            "2. FORMAT VARIATIONS:\n",
            "   original     -> 11 tokens\n",
            "   uppercase    -> 11 tokens\n",
            "   lowercase    -> 11 tokens\n",
            "   no_spaces    -> 17 tokens\n",
            "\n",
            "3. TOKEN PATTERNS:\n",
            "   Long words (>5 chars): Artificial, intelligence, transforming\n",
            "   Short words (â‰¤3 chars): is, how, we\n",
            "\n",
            "4. SEMANTIC SIMILARITY:\n",
            "   Similarity to reference: 0.7789\n",
            "   Reference: 'Machine learning is changing our daily lives...'\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions to Consider:\n",
        "\n",
        "**Token Count:**\n",
        "- Looking at your results, which text format used the most tokens? Which used the least? Why do you think this happened?\n",
        "\n",
        "**Compression Patterns:**\n",
        "- Your compression ratio shows how many characters become one token. Is it more efficient than the example text? What makes text more or less \"compressible\"?\n",
        "\n",
        "**Similarity Results:**\n",
        "- Look at your similarity score between the original and reference text. Is it higher or lower than you expected? What words might be causing the similarity or difference?\n",
        "\n",
        "**Connecting to Chapter 2 Concepts:**\n",
        "- The chapter mentions that spaces are often included in tokens (like \"Ä \" in GPT-2). Can you spot evidence of this in your tokenization results?\n",
        "\n",
        "**Pattern Recognition:**\n",
        "- Notice how uppercase vs lowercase affects token count. Based on what you learned about BERT cased/uncased in the chapter, why does capitalization matter so much?\n",
        "\n",
        "**Practical Application:**\n",
        "- If you were sending this text to an API that charges per token:\n",
        "  - Which format would be cheapest to send?\n",
        "  - Could you rewrite it to use fewer tokens while keeping the same meaning?\n",
        "\n",
        "**Your Custom Metric Ideas:**\n",
        "Instead of creating complex code, describe in words:\n",
        "- What would be useful to measure that combines two techniques? (Example: \"Finding words that are both long AND have low similarity to other words\")\n",
        "- Why would this metric be helpful for understanding text?\n",
        "\n",
        "**Summary:**\n",
        "Based on all your experiments:\n",
        "- Name one surprising thing you discovered about tokenization\n",
        "- Name one way tokenization could affect a chatbot's responses\n",
        "- If you had to explain tokenization to a friend, what's the most important thing they should know?"
      ],
      "metadata": {
        "id": "PqUoYgss4wiP"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
