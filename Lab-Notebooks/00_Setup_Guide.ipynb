{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Guide: API Configuration for ADS 525\n",
    "\n",
    "This notebook covers account creation and API setup for OpenAI and HuggingFace. Complete these steps before working on course notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OpenAI API Setup\n",
    "\n",
    "OpenAI provides access to GPT models (GPT-3.5, GPT-4) through their API. You will need this for text generation and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create an OpenAI Account\n",
    "\n",
    "1. Go to https://platform.openai.com/signup\n",
    "2. Sign up with email or Google/Microsoft account\n",
    "3. Verify your email address\n",
    "4. Add payment method (required for API access)\n",
    "\n",
    "**Note:** OpenAI provides $5 in free credits for new accounts. After that, you pay per token used.\n",
    "\n",
    "**Pricing:** https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate API Key\n",
    "\n",
    "1. Log in to https://platform.openai.com\n",
    "2. Click your profile icon (top-right) > **API keys**\n",
    "3. Click **Create new secret key**\n",
    "4. Name your key (e.g., \"ADS525\")\n",
    "5. Copy the key immediately (you cannot view it again)\n",
    "6. Store it securely\n",
    "\n",
    "**Direct link:** https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Install OpenAI Library\n",
    "\n",
    "Run this cell to install the OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Configure API Key\n",
    "\n",
    "**Option A: Direct in Code (for testing only)**\n",
    "\n",
    "Replace `YOUR_API_KEY_HERE` with your actual key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Environment Variable (recommended)**\n",
    "\n",
    "Set your API key as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "# Client will automatically use the environment variable\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option C: Google Colab Secrets (best for Colab)**\n",
    "\n",
    "1. In Colab, click the key icon (ðŸ”‘) in the left sidebar\n",
    "2. Click **Add new secret**\n",
    "3. Name: `OPENAI_API_KEY`\n",
    "4. Value: Your API key\n",
    "5. Toggle on notebook access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "from google.colab import userdata\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Your Setup\n",
    "\n",
    "Run this cell to verify your API key works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say 'API setup successful'\"}],\n",
    "        max_tokens=10\n",
    "    )\n",
    "    print(\"Success:\", response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Documentation\n",
    "\n",
    "- **API Reference:** https://platform.openai.com/docs/api-reference\n",
    "- **Quickstart Guide:** https://platform.openai.com/docs/quickstart\n",
    "- **Python Library:** https://github.com/openai/openai-python\n",
    "- **Usage Dashboard:** https://platform.openai.com/usage\n",
    "- **Rate Limits:** https://platform.openai.com/docs/guides/rate-limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. HuggingFace Setup\n",
    "\n",
    "HuggingFace hosts thousands of pre-trained models and datasets. Most models are free to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a HuggingFace Account\n",
    "\n",
    "1. Go to https://huggingface.co/join\n",
    "2. Sign up with email or Google/GitHub account\n",
    "3. Verify your email address\n",
    "\n",
    "**Note:** Account creation is free. No payment method required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Access Token\n",
    "\n",
    "An access token allows you to:\n",
    "- Download private models\n",
    "- Access gated models (like Llama)\n",
    "- Upload models/datasets\n",
    "- Avoid rate limits\n",
    "\n",
    "**Steps:**\n",
    "1. Log in to https://huggingface.co\n",
    "2. Click your profile picture > **Settings**\n",
    "3. Go to **Access Tokens** in the left sidebar\n",
    "4. Click **New token**\n",
    "5. Name: \"ADS525\"\n",
    "6. Role: **Read** (sufficient for this course)\n",
    "7. Click **Generate**\n",
    "8. Copy the token\n",
    "\n",
    "**Direct link:** https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Install HuggingFace Libraries\n",
    "\n",
    "Run this cell to install required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sentence-transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Authenticate with HuggingFace\n",
    "\n",
    "**Option A: Login via Terminal (one-time)**\n",
    "\n",
    "Run this once to store credentials permanently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# This will prompt for your token\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Environment Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option C: Google Colab Secrets (best for Colab)**\n",
    "\n",
    "1. In Colab, click the key icon (ðŸ”‘)\n",
    "2. Click **Add new secret**\n",
    "3. Name: `HF_TOKEN`\n",
    "4. Value: Your token\n",
    "5. Toggle on notebook access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=userdata.get('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Your Setup\n",
    "\n",
    "Run this cell to verify access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "try:\n",
    "    # Load a small model\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    result = classifier(\"HuggingFace setup successful\")\n",
    "    print(\"Success:\", result)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Documentation\n",
    "\n",
    "- **Models Hub:** https://huggingface.co/models\n",
    "- **Datasets Hub:** https://huggingface.co/datasets\n",
    "- **Transformers Library:** https://huggingface.co/docs/transformers\n",
    "- **Datasets Library:** https://huggingface.co/docs/datasets\n",
    "- **Sentence Transformers:** https://www.sbert.net/\n",
    "- **Hub API:** https://huggingface.co/docs/huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Google Colab Specific Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU\n",
    "\n",
    "Most course notebooks require a GPU for reasonable runtime.\n",
    "\n",
    "**Steps:**\n",
    "1. Go to **Runtime** > **Change runtime type**\n",
    "2. **Hardware accelerator:** Select **GPU**\n",
    "3. **GPU type:** Select **T4** (free tier)\n",
    "4. Click **Save**\n",
    "\n",
    "Verify GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent Storage (Optional)\n",
    "\n",
    "Mount Google Drive to save models and data between sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print(\"Drive mounted at /content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Errors\n",
    "\n",
    "**Error:** `AuthenticationError: Incorrect API key`\n",
    "- Check your API key is correct (no extra spaces)\n",
    "- Verify key has not been revoked at https://platform.openai.com/api-keys\n",
    "\n",
    "**Error:** `RateLimitError: Rate limit exceeded`\n",
    "- You are making too many requests\n",
    "- Add delays between API calls: `import time; time.sleep(1)`\n",
    "- Check rate limits: https://platform.openai.com/account/rate-limits\n",
    "\n",
    "**Error:** `InsufficientQuotaError: You exceeded your current quota`\n",
    "- Your free credits are exhausted\n",
    "- Add payment method at https://platform.openai.com/account/billing\n",
    "\n",
    "**Error:** `InvalidRequestError: max_tokens is too large`\n",
    "- Reduce `max_tokens` parameter\n",
    "- Check model limits: https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Errors\n",
    "\n",
    "**Error:** `OSError: [Errno 403] Forbidden`\n",
    "- Model requires authentication\n",
    "- Run `huggingface-cli login` or use token\n",
    "\n",
    "**Error:** `OSError: [Errno 404] Model not found`\n",
    "- Check model name spelling\n",
    "- Verify model exists: https://huggingface.co/models\n",
    "\n",
    "**Error:** `OutOfMemoryError: CUDA out of memory`\n",
    "- Model is too large for available GPU memory\n",
    "- Use a smaller model\n",
    "- Reduce batch size\n",
    "- Use `device=\"cpu\"` instead of GPU\n",
    "\n",
    "**Error:** `RepositoryNotFoundError`\n",
    "- Check repository name\n",
    "- Model may be private (requires authentication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Python Errors\n",
    "\n",
    "**Error:** `ModuleNotFoundError: No module named 'X'`\n",
    "- Run `!pip install X`\n",
    "- Restart runtime after installation\n",
    "\n",
    "**Error:** `RuntimeError: CUDA error: device-side assert triggered`\n",
    "- Usually an indexing error in model code\n",
    "- Try running on CPU to get better error message: `device=\"cpu\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Cost Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Cost Tips\n",
    "\n",
    "- Use `gpt-3.5-turbo` instead of `gpt-4` (20x cheaper)\n",
    "- Set `max_tokens` to limit response length\n",
    "- Cache results to avoid repeated API calls\n",
    "- Monitor usage: https://platform.openai.com/usage\n",
    "- Set usage limits: https://platform.openai.com/account/limits\n",
    "\n",
    "**Example pricing (as of 2024):**\n",
    "- GPT-3.5-turbo: $0.0015 per 1K tokens\n",
    "- GPT-4: $0.03 per 1K tokens (input)\n",
    "\n",
    "**Estimate tokens:** ~750 words = 1000 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace (Free)\n",
    "\n",
    "- All public models and datasets are free\n",
    "- No API costs\n",
    "- Only costs are compute (your GPU/CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Libraries\n",
    "\n",
    "- **transformers:** Pre-trained models (BERT, GPT, etc.)\n",
    "- **datasets:** Access to 10,000+ datasets\n",
    "- **sentence-transformers:** Sentence embeddings\n",
    "- **openai:** OpenAI API client\n",
    "- **langchain:** Framework for LLM applications\n",
    "- **tiktoken:** OpenAI tokenizer\n",
    "\n",
    "Install all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sentence-transformers openai langchain tiktoken accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Resources\n",
    "\n",
    "- **HuggingFace Forums:** https://discuss.huggingface.co/\n",
    "- **OpenAI Community:** https://community.openai.com/\n",
    "- **Stack Overflow:** https://stackoverflow.com/questions/tagged/transformers\n",
    "- **Course GitHub:** https://github.com/hemekci/ADS525"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup Complete\n",
    "\n",
    "If both test cells ran successfully, you are ready to start the course notebooks. Refer back to this guide if you encounter authentication or API issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
